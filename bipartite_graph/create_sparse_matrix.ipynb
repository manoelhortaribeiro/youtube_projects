{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pickle\n",
    "import math\n",
    "import scipy\n",
    "import glob\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import zstandard as zstd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from scipy.sparse import dok_matrix\n",
    "\n",
    "scriptpath = \"../\"\n",
    "sys.path.append(os.path.abspath(scriptpath))\n",
    "from helpers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set of channels that we consider\n",
    "with open(\"/dlabdata1/youtube_large/jouven/channels_more_10k.pkl\",'rb') as f:\n",
    "    channels_id = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set of duplicate users\n",
    "duplicate_users = dict_occurent_users()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helpers dictionarries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dictionnary mapping the video_id to the channel_id\n",
    "vid_to_channels = pd.read_pickle(\"/dlabdata1/youtube_large/id_to_channel_mapping.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Channels that are in set_crawler dataset and also in which the language is in english\n",
    "dict_channel_ind, dict_ind_channel, channels_id = filtered_channels_index_id_mapping()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dictionnary mapping the channel index to the total number of comments in this channel\n",
    "with open(\"/dlabdata1/youtube_large/jouven/comments_per_channel_id.pkl\", 'rb') as f:\n",
    "    channels_idx_to_nb_comments = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the bipartite graph between the users and the channels using sparse matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tf_idf_weight_occurences(graph_dict, user_idx, user_channels_occurences, nb_users):\n",
    "    max_freq = max(user_channels_occurences.values())\n",
    "    for channel in set(user_channels_occurences.keys()):\n",
    "        tf = user_channels_occurences[channel] / max_freq\n",
    "        idf = math.log(nb_users / channels_idx_to_nb_comments[channel])\n",
    "        graph_dict[(channel, user_idx)] = tf * idf\n",
    "        \n",
    "def update_user_channel_occurences(users_channels, channel_idx):\n",
    "    if channel_idx in users_channels:\n",
    "        users_channels[channel_idx] += 1\n",
    "    else:\n",
    "        users_channels[channel_idx] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(graph_dict)  32234357\n",
      "32234357\n",
      "32234357\n",
      "line number: 100000000 time: 492.20108222961426\n",
      "len(graph_dict)  32221994\n",
      "32221994\n",
      "32221994\n",
      "line number: 200000000 time: 504.52183866500854\n"
     ]
    }
   ],
   "source": [
    "# Adjust chunk_size as necessary -- defaults to 16,384 if not specific\n",
    "reader = Zreader(\"/dlabdata1/youtube_large/youtube_comments.ndjson.zst\", chunk_size=16384)\n",
    "\n",
    "# PARAMETERS\n",
    "\n",
    "# Dictionnary containing channel, user tuple\n",
    "graph_dict = {}\n",
    "# Dictionarray counting the numbers of comments of a given user on channels\n",
    "user_channels_occurences = {}\n",
    "\n",
    "user = ''\n",
    "begin_time = time.time()\n",
    "# Numbers of channels\n",
    "nb_channels = len(channels_id)\n",
    "# Numbers of users\n",
    "nb_users = 406925230\n",
    "# Users idx\n",
    "user_idx = -1\n",
    "# Indices used for prints\n",
    "idx = 1\n",
    "nb = 1\n",
    "\n",
    "dir_1 = '/dlabdata1/youtube_large/jouven/sparse_matrix_construction/sparse_matrices_bipartite'\n",
    "check_directory(dir_1)\n",
    "\n",
    "# Read each line from the reader\n",
    "for line in reader.readlines():\n",
    "    line_split = line.replace('\"', '').split(',')\n",
    "    if len(line_split) == 9:\n",
    "        author_id = line_split[0]\n",
    "        if vid_to_channels.get(line_split[2]) in channels_id:\n",
    "            channel_idx = dict_channel_ind[vid_to_channels[line_split[2]]]\n",
    "            \n",
    "            if author_id == user:\n",
    "                if author_id in duplicate_users:\n",
    "                    if duplicate_users[author_id] <= 1:\n",
    "                        update_user_channel_occurences(user_channels_occurences)\n",
    "                else:\n",
    "                    update_user_channel_occurences(user_channels_occurences)\n",
    "            else:\n",
    "                if len(user_channels_occurences) > 0:\n",
    "                    tf_idf_weight_occurences(graph_dict, user_idx, user_channels_occurences, nb_users)\n",
    "                \n",
    "                user_channels_occurences = {}\n",
    "                \n",
    "                if author_id in duplicate_users:\n",
    "                    duplicate_users[author_id] += 1\n",
    "                    if duplicate_users[author_id] <= 1:\n",
    "                        user_idx += 1\n",
    "                        update_user_channel_occurences(user_channels_occurences)\n",
    "                        \n",
    "                else:\n",
    "                    user_idx += 1\n",
    "                    update_user_channel_occurences(user_channels_occurences)\n",
    "                    \n",
    "                    \n",
    "\n",
    "    if idx % 75000000 == 0:\n",
    "        # For space requirements every 75 millions line create a dok matrix and\n",
    "        # update it with the graph_dict dictionnary and then save it into csr format and then release memory\n",
    "        graph_matrix = dok_matrix((nb_channels, nb_users), np.uint16)\n",
    "        dict.update(graph_matrix, graph_dict)\n",
    "        graph_dict = {}\n",
    "        # Save sparse matrix\n",
    "        scipy.sparse.save_npz('/dlabdata1/youtube_large/jouven/sparse_matrix_construction/sparse_matrices_bipartite/matrice' + str(nb) + '.npz', graph_matrix.tocsr())\n",
    "        with open(\"/dlabdata1/youtube_large/jouven/sparse_matrix_construction/idx_bip.pkl\",'wb') as f:\n",
    "             pickle.dump([idx], f)\n",
    "        f.close()\n",
    "        graph_matrix = []\n",
    "        nb += 1\n",
    "        print('line number: ' + str(idx) + ' time: ' + str(time.time() - begin_time))\n",
    "        begin_time = time.time()\n",
    "\n",
    "    user = line_split[0]\n",
    "    idx += 1\n",
    "    \n",
    "\n",
    "graph_matrix = dok_matrix((nb_channels, nb_users), np.uint16)\n",
    "dict.update(graph_matrix, graph_dict)\n",
    "graph_dict = {}\n",
    "# Save sparse matrix\n",
    "scipy.sparse.save_npz('/dlabdata1/youtube_large/jouven/sparse_matrix_construction/sparse_matrices_bipartite/matrice' + str(nb) + '.npz', graph_matrix.tocsc())\n",
    "graph_matrix = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "graph = dok_matrix((nb_channels, nb_users)).tocsr()\n",
    "path = '/dlabdata1/youtube_large/jouven/sparse_matrix_construction/sparse_matrices_bipartite_correct/'\n",
    "files = glob.glob(path + '*.npz')\n",
    "for file in files: \n",
    "    graph += scipy.sparse.load_npz(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save the final sparse matrix\n",
    "scipy.sparse.save_npz('/dlabdata1/youtube_large/jouven/final_embedding_sparse_matrix/sparse_matrix_bipartite.npz', graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
