{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import random\n",
    "import scipy.sparse\n",
    "import sys\n",
    "import time\n",
    "\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.mllib.clustering import LDA, LDAModel\n",
    "from pyspark.mllib.linalg import Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = SparkConf().setMaster(\"local[12]\").setAll([\n",
    "                                   ('spark.executor.memory', '16g'),  # find\n",
    "                                   ('spark.driver.memory','8g'), # your\n",
    "                                   ('spark.driver.maxResultSize', '4G') # setup\n",
    "                                  ])\n",
    "# create the session\n",
    "spark = SparkSession.builder.config(conf=conf).getOrCreate()\n",
    "\n",
    "# create the context\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = scipy.sparse.load_npz('/dlabdata1/youtube_large/olam/matrices/S_final2.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dict_for_row(row):\n",
    "    ''''''\n",
    "    tmp_dict = {}\n",
    "    for key, value in row:\n",
    "        tmp_dict[key[1]] = value\n",
    "        \n",
    "    return Vectors.sparse(len(tmp_dict), tmp_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 videos processed\n"
     ]
    }
   ],
   "source": [
    "for i in range(S.shape[0]):\n",
    "    \n",
    "    if i % 10000000 == 0:\n",
    "        print(str(i) + ' videos processed')\n",
    "    if i == 500000:\n",
    "        break\n",
    "    \n",
    "    # Data is a list of list of the following elems : index of doc and a bag-of-word sparse Vector\n",
    "    data.append([i, get_dict_for_row(S.getrow(i).todok().items())])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of array : 500000 and first row : [258937, SparseVector(24, {20451: 1.0, 49360: 1.0, 62889: 1.0, 90939: 1.0, 142981: 3.0, 165021: 1.0, 169010: 1.0, 190462: 1.0, 212862: 1.0, 247334: 2.0, 309667: 2.0, 374074: 1.0, 384153: 3.0, 428500: 1.0, 445034: 2.0, 447282: 1.0, 453390: 1.0, 470491: 1.0, 493674: 2.0, 507615: 1.0, 509141: 1.0, 629388: 1.0, 633252: 1.0, 649840: 2.0})]\n"
     ]
    }
   ],
   "source": [
    "print('Length of array : ' + str(len(data)) + ' and first row : ' + str(data[258937]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed('/dlabdata1/youtube_large/olam/list_data_lda_spark', data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "corpus = sc.parallelize(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = LDA.train(corpus, k=20, seed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(sc, '/dlabdata1/youtube_large/olam/lda_sparkModel_500000vid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([618890, 655263, 650755, 39325, 60788],\n",
       "  [0.01591342080221603,\n",
       "   0.01062900727127717,\n",
       "   0.008840857290014758,\n",
       "   0.007208700311898657,\n",
       "   0.00694410222612207]),\n",
       " ([655263, 494551, 423399, 606524, 582861],\n",
       "  [0.011805558715055611,\n",
       "   0.010003007665561966,\n",
       "   0.009368654497465557,\n",
       "   0.008724152988832003,\n",
       "   0.008045816303057063]),\n",
       " ([60953, 50414, 655263, 585888, 118607],\n",
       "  [0.05121343464147456,\n",
       "   0.014160465507474409,\n",
       "   0.01202342934848488,\n",
       "   0.011352127772678682,\n",
       "   0.01000544035185211]),\n",
       " ([587583, 156037, 237158, 558227, 655263],\n",
       "  [0.02260586094214811,\n",
       "   0.009552352188027398,\n",
       "   0.009114894433390077,\n",
       "   0.008541334351027982,\n",
       "   0.00792920881818704]),\n",
       " ([655263, 347101, 60788, 91913, 479998],\n",
       "  [0.011984542545684037,\n",
       "   0.006776620716003611,\n",
       "   0.006500006164804386,\n",
       "   0.005295908138002675,\n",
       "   0.005032335627837785])]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.describeTopics()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "same_model = LDAModel.load(sc, '/dlabdata1/youtube_large/olam/lda_sparkModel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([214313, 389685, 702165, 671629, 420134, 544917],\n",
       " [0.266132635069856,\n",
       "  0.04908022772804397,\n",
       "  0.04380826578831293,\n",
       "  0.04196875751770345,\n",
       "  0.031857012470995164,\n",
       "  0.015664738377080007])"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "same_model.describeTopics()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understand results from LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dictionnary of tokens\n",
    "with open('/dlabdata1/youtube_large/olam/id2word_2.pickle', 'rb') as f:\n",
    "    id2word = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.describeTopics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[618890, 655263, 650755, 39325, 60788]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.describeTopics()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0\n",
      "   prime\n",
      "   game\n",
      "   surf\n",
      "   roblox\n",
      "   news\n",
      " \n",
      "Topic 1\n",
      "   game\n",
      "   onlin\n",
      "   final\n",
      "   gta\n",
      "   part\n",
      " \n",
      "Topic 2\n",
      "   minecraft\n",
      "   mod\n",
      "   game\n",
      "   hack\n",
      "   pokemon\n",
      " \n",
      "Topic 3\n",
      "   hair\n",
      "   hairstyl\n",
      "   madden\n",
      "   tutori\n",
      "   game\n",
      " \n",
      "Topic 4\n",
      "   game\n",
      "   video\n",
      "   news\n",
      "   gopro\n",
      "   laptop\n",
      " \n",
      "Topic 5\n",
      "   video\n",
      "   game\n",
      "   song\n",
      "   khan\n",
      "   music\n",
      " \n",
      "Topic 6\n",
      "   game\n",
      "   song\n",
      "   video\n",
      "   final\n",
      "   full\n",
      " \n",
      "Topic 7\n",
      "   dota\n",
      "   draft\n",
      "   abil\n",
      "   pro\n",
      "   game\n",
      " \n",
      "Topic 8\n",
      "   horizon\n",
      "   forza\n",
      "   game\n",
      "   nba\n",
      "   video\n",
      " \n",
      "Topic 9\n",
      "   war\n",
      "   bindass\n",
      "   game\n",
      "   fail\n",
      "   episod\n",
      " \n",
      "Topic 10\n",
      "   scooter\n",
      "   game\n",
      "   jamaica\n",
      "   motorcycl\n",
      "   uaap\n",
      " \n",
      "Topic 11\n",
      "   game\n",
      "   video\n",
      "   play\n",
      "   music\n",
      "   part\n",
      " \n",
      "Topic 12\n",
      "   muscl\n",
      "   gain\n",
      "   build\n",
      "   workout\n",
      "   fit\n",
      " \n",
      "Topic 13\n",
      "   watch\n",
      "   face\n",
      "   gear\n",
      "   fit\n",
      "   best\n",
      " \n",
      "Topic 14\n",
      "   lol\n",
      "   video\n",
      "   game\n",
      "   surpris\n",
      "   seri\n",
      " \n",
      "Topic 15\n",
      "   watch\n",
      "   pokemon\n",
      "   face\n",
      "   game\n",
      "   gear\n",
      " \n",
      "Topic 16\n",
      "   song\n",
      "   tamil\n",
      "   bhojpuri\n",
      "   hit\n",
      "   politician\n",
      " \n",
      "Topic 17\n",
      "   final\n",
      "   fantasi\n",
      "   hero\n",
      "   game\n",
      "   fortnit\n",
      " \n",
      "Topic 18\n",
      "   pvl\n",
      "   game\n",
      "   cbn\n",
      "   sport\n",
      "   video\n",
      " \n",
      "Topic 19\n",
      "   beat\n",
      "   free\n",
      "   type\n",
      "   instrument\n",
      "   babi\n",
      " \n"
     ]
    }
   ],
   "source": [
    "for i in range(len(model.describeTopics())):\n",
    "    topic_words = model.describeTopics()[i][0]\n",
    "    print('Topic ' + str(i))\n",
    "    for i, id_token in enumerate(topic_words):\n",
    "        print('   ' + id2word[id_token])\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Issue : need to remove tokens of length 1/2 and tokens with another alphabet\n",
    "\n",
    "Hence, save the S_final2 sparse matrix and get the id2word2 dict that map the token_id to the token in the new matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_token_to_remove = []\n",
    "token_to_keep = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def englishAlpha(s):\n",
    "    try:\n",
    "        s.encode(encoding='utf-8').decode('ascii')\n",
    "    except UnicodeDecodeError:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "for token_id, token in id2word.items():\n",
    "    if len(token) < 3 or nonEnglishAlpha(token) or token.isnumeric():\n",
    "        id_token_to_remove.append(token_id)\n",
    "    else:\n",
    "        token_to_keep.append(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81014"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(id_token_to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "663127"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(token_to_keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(token_to_keep) + len(id_token_to_remove) == len(id2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<68638982x744141 sparse matrix of type '<class 'numpy.uint8'>'\n",
       "\twith 1393937498 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_token_to_keep = (np.delete(np.arange(len(id2word)), id_token_to_remove))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = S[:, id_token_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<68638982x663127 sparse matrix of type '<class 'numpy.uint8'>'\n",
       "\twith 1251231562 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_to_keep = set(token_to_keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word_new = {}\n",
    "\n",
    "k = 0\n",
    "for i, token in enumerate(id2word.values()):\n",
    "    if token in token_to_keep:\n",
    "        id2word_new[k] = token\n",
    "        k += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.sparse.save_npz('/dlabdata1/youtube_large/olam/matrices/S_final2.npz', S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/dlabdata1/youtube_large/olam/id2word_2.pickle', 'wb') as f:\n",
    "    pickle.dump(id2word_new, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
