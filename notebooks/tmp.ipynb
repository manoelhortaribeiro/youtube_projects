{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/olam/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import collections\n",
    "import fasttext\n",
    "import json\n",
    "import nltk\n",
    "import pickle\n",
    "import random\n",
    "import scipy.sparse\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import zstandard as zstd\n",
    "\n",
    "from collections import Counter\n",
    "from langdetect import detect\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from scipy.sparse import dok_matrix\n",
    "\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import LongType, StructField, StructType\n",
    "from pyspark.ml.clustering import LDA, LDAModel, LocalLDAModel\n",
    "from pyspark.ml.linalg import Vectors, SparseVector\n",
    "\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove video that have 0 tokens in the new vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = scipy.sparse.load_npz('/dlabdata1/youtube_large/olam/matrices/S_final2.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_with_tokens = []\n",
    "for i in range(S.shape[0]):\n",
    "    if S[i, :].count_nonzero() != 0:\n",
    "        row_with_tokens.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68566847"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(row_with_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<68638982x663127 sparse matrix of type '<class 'numpy.uint8'>'\n",
       "\twith 1251231562 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.sparse.save_npz('/dlabdata1/youtube_large/olam/matrices/S_final3.npz', S[row_with_tokens,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get list of index of relevant videos, from each categorie, each year and each channel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Zreader:\n",
    "\n",
    "    def __init__(self, file, chunk_size=16384):\n",
    "        '''Init method'''\n",
    "        self.fh = open(file,'rb')\n",
    "        self.chunk_size = chunk_size\n",
    "        self.dctx = zstd.ZstdDecompressor()\n",
    "        self.reader = self.dctx.stream_reader(self.fh)\n",
    "        self.buffer = ''\n",
    "\n",
    "\n",
    "    def readlines(self):\n",
    "        '''Generator method that creates an iterator for each line of JSON'''\n",
    "        while True:\n",
    "            chunk = self.reader.read(self.chunk_size).decode(errors=\"ignore\")\n",
    "            if not chunk:\n",
    "                break\n",
    "            lines = (self.buffer + chunk).split(\"\\n\")\n",
    "\n",
    "            for line in lines[:-1]:\n",
    "                yield line\n",
    "\n",
    "            self.buffer = lines[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load set of videos to consider\n",
    "with open('/dlabdata1/youtube_large/olam/filtered10000/idx_vid_to_consider.pickle', 'rb') as f:\n",
    "    idx_vid_to_consider = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_rows = len(idx_vid_to_consider)\n",
    "n_columns = 5\n",
    "\n",
    "columns_names = ['idx', 'channel_id', 'view_counts', 'uploaded_year', 'category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_relevant_infos = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Zreader(\"/dlabdata1/youtube_large/yt_metadata_all.jsonl.zst\", chunk_size=2**28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 1/85\n",
      "Progress: 2/85\n",
      "Progress: 3/85\n",
      "Progress: 4/85\n",
      "Progress: 5/85\n",
      "Progress: 6/85\n",
      "Progress: 7/85\n",
      "Progress: 8/85\n",
      "Progress: 9/85\n",
      "Progress: 10/85\n",
      "Progress: 11/85\n",
      "Progress: 12/85\n",
      "Progress: 13/85\n",
      "Progress: 14/85\n",
      "Progress: 15/85\n",
      "Progress: 16/85\n",
      "Progress: 17/85\n",
      "Progress: 18/85\n",
      "Progress: 19/85\n",
      "Progress: 20/85\n",
      "Progress: 21/85\n",
      "Progress: 22/85\n",
      "Progress: 23/85\n",
      "Progress: 24/85\n",
      "Progress: 25/85\n",
      "Progress: 26/85\n",
      "Progress: 27/85\n",
      "Progress: 28/85\n",
      "Progress: 29/85\n",
      "Progress: 30/85\n",
      "Progress: 31/85\n",
      "Progress: 32/85\n",
      "Progress: 33/85\n",
      "Progress: 34/85\n",
      "Progress: 35/85\n",
      "Progress: 36/85\n",
      "Progress: 37/85\n",
      "Progress: 38/85\n",
      "Progress: 39/85\n",
      "Progress: 40/85\n",
      "Progress: 41/85\n",
      "Progress: 42/85\n",
      "Progress: 43/85\n",
      "Progress: 44/85\n",
      "Progress: 45/85\n",
      "Progress: 46/85\n",
      "Progress: 47/85\n",
      "Progress: 48/85\n",
      "Progress: 49/85\n",
      "Progress: 50/85\n",
      "Progress: 51/85\n",
      "Progress: 52/85\n",
      "Progress: 53/85\n",
      "Progress: 54/85\n",
      "Progress: 55/85\n",
      "Progress: 56/85\n",
      "Progress: 57/85\n",
      "Progress: 58/85\n",
      "Progress: 59/85\n",
      "Progress: 60/85\n",
      "Progress: 61/85\n",
      "Progress: 62/85\n",
      "Progress: 63/85\n",
      "Progress: 64/85\n",
      "Progress: 65/85\n",
      "Progress: 66/85\n",
      "Progress: 67/85\n",
      "Progress: 68/85\n",
      "Progress: 69/85\n",
      "Progress: 70/85\n",
      "Progress: 71/85\n",
      "Progress: 72/85\n",
      "Progress: 73/85\n",
      "Progress: 74/85\n",
      "Progress: 75/85\n",
      "Progress: 76/85\n",
      "Progress: 77/85\n",
      "Progress: 78/85\n",
      "Progress: 79/85\n",
      "Progress: 80/85\n",
      "Progress: 81/85\n",
      "Progress: 82/85\n",
      "Progress: 83/85\n",
      "Progress: 84/85\n",
      "Progress: 85/85\n",
      "1493.3241865634918\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "idx = 0\n",
    "idx_new = 0\n",
    "for line in reader.readlines():\n",
    "    ###start_iter = time.time()\n",
    "    idx += 1\n",
    "    \n",
    "    if idx % 1000000 == 0:\n",
    "        print('Progress: ' + str(int(idx/1000000)) + '/85')\n",
    "        \n",
    "    if idx in idx_vid_to_consider:\n",
    "        \n",
    "        # line is a str dict, video is the dict corresponding to the str dict\n",
    "        video = json.loads(line)\n",
    "        array_vid_relevant_infos = [idx_new + 1]\n",
    "        \n",
    "        array_vid_relevant_infos.append(video['channel_id'])\n",
    "        array_vid_relevant_infos.append(video['view_count'])\n",
    "        array_vid_relevant_infos.append(video['upload_date'][:4])\n",
    "        array_vid_relevant_infos.append(video['categories'])\n",
    "        \n",
    "        array_relevant_infos.append(array_vid_relevant_infos)\n",
    "        \n",
    "        idx_new += 1\n",
    "        \n",
    "print(str(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(array_relevant_infos, columns=columns_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21714294, 5)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>channel_id</th>\n",
       "      <th>view_counts</th>\n",
       "      <th>uploaded_year</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>UCzzzZ3-icktxbC3j7hkWqRw</td>\n",
       "      <td>1888967</td>\n",
       "      <td>2016</td>\n",
       "      <td>Howto &amp; Style</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>UCzzzZ3-icktxbC3j7hkWqRw</td>\n",
       "      <td>1297474</td>\n",
       "      <td>2016</td>\n",
       "      <td>Howto &amp; Style</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>UCzzzZ3-icktxbC3j7hkWqRw</td>\n",
       "      <td>582615</td>\n",
       "      <td>2016</td>\n",
       "      <td>Howto &amp; Style</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>UCzzzZ3-icktxbC3j7hkWqRw</td>\n",
       "      <td>14507</td>\n",
       "      <td>2016</td>\n",
       "      <td>Howto &amp; Style</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>UCzzzZ3-icktxbC3j7hkWqRw</td>\n",
       "      <td>171671</td>\n",
       "      <td>2016</td>\n",
       "      <td>Howto &amp; Style</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   idx                channel_id  view_counts uploaded_year       category\n",
       "0    1  UCzzzZ3-icktxbC3j7hkWqRw      1888967          2016  Howto & Style\n",
       "1    2  UCzzzZ3-icktxbC3j7hkWqRw      1297474          2016  Howto & Style\n",
       "2    3  UCzzzZ3-icktxbC3j7hkWqRw       582615          2016  Howto & Style\n",
       "3    4  UCzzzZ3-icktxbC3j7hkWqRw        14507          2016  Howto & Style\n",
       "4    5  UCzzzZ3-icktxbC3j7hkWqRw       171671          2016  Howto & Style"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21714294"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(idx_vid_to_consider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top5 = df.sort_values(['view_counts'], ascending=False).groupby(['category', 'uploaded_year', 'channel_id']).head(5)\n",
    "df_top10 = df.sort_values(['view_counts'], ascending=False).groupby(['category', 'uploaded_year', 'channel_id']).head(10)                                                                                                                   \n",
    "df_top20 = df.sort_values(['view_counts'], ascending=False).groupby(['category', 'uploaded_year', 'channel_id']).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_idx_relevant_vid_top5 = sorted(df_top5.index.values)\n",
    "sorted_idx_relevant_vid_top10 = sorted(df_top10.index.values)\n",
    "sorted_idx_relevant_vid_top20 = sorted(df_top20.index.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('/dlabdata1/youtube_large/olam/filtered10000/sorted_idx_relevant_vid_top5.pickle', 'wb') as f:\n",
    "    pickle.dump(sorted_idx_relevant_vid_top5, f)\n",
    "f.close()\n",
    "with open('/dlabdata1/youtube_large/olam/filtered10000/sorted_idx_relevant_vid_top10.pickle', 'wb') as f:\n",
    "    pickle.dump(sorted_idx_relevant_vid_top10, f)\n",
    "f.close()\n",
    "with open('/dlabdata1/youtube_large/olam/filtered10000/sorted_idx_relevant_vid_top20.pickle', 'wb') as f:\n",
    "    pickle.dump(sorted_idx_relevant_vid_top20, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3432979"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sorted_idx_relevant_vid_top5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5453143"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sorted_idx_relevant_vid_top10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8116217"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sorted_idx_relevant_vid_top20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11365475"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "7728523 / 68000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17015195513998937"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "7728523 / 45421300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save file to work on hadoop cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = SparkConf().setMaster(\"local[4]\").setAll([('spark.executor.memory', '4g'),('spark.driver.memory','16g'),('spark.driver.maxResultSize', '0')])\n",
    "\n",
    "# create the session\n",
    "spark = SparkSession.builder.config(conf=conf).getOrCreate()\n",
    "\n",
    "# create the context\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dict_for_row(row, S):\n",
    "    '''Construct SparseVector bag-of-word for each row (videos)'''\n",
    "    tmp_dict = {}\n",
    "    for key, value in row:\n",
    "        tmp_dict[key[1]] = value\n",
    "\n",
    "    return SparseVector(S.shape[1], tmp_dict)\n",
    "\n",
    "def remove_zero_rows(M):\n",
    "    '''Function that removes all rows from sparse matrix M that contains only zero.'''\n",
    "    num_nonzeros = np.diff(M.indptr)\n",
    "    return M[num_nonzeros != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Process video for topic modelling...\n",
      "0 videos processed...\n",
      "1000000 videos processed...\n",
      "2000000 videos processed...\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "print('Loading data...')\n",
    "S = scipy.sparse.load_npz('/dlabdata1/youtube_large/olam/data/view10000_sub10000/csr_matrices/S_final_tok100vid.npz')\n",
    "\n",
    "# Load set of videos to consider\n",
    "with open('/dlabdata1/youtube_large/olam/data/view10000_sub10000/sorted_idx_relevant_vid_top20.pickle', 'rb') as f:\n",
    "    sorted_idx_relevant_vid_top = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "# Select videos\n",
    "S = S[sorted_idx_relevant_vid_top,:]\n",
    "S = remove_zero_rows(S)\n",
    "\n",
    "\n",
    "all_data = []\n",
    "\n",
    "print('Process video for topic modelling...')\n",
    "for i in range(S.shape[0]):\n",
    "\n",
    "    if i % 1000000 == 0:\n",
    "        print(str(i) + ' videos processed...')\n",
    "\n",
    "    all_data.append([i, get_dict_for_row(S.getrow(i).todok().items(), S)])\n",
    "    \n",
    "    \n",
    "# Construct dataframe for LDA\n",
    "all_df = spark.createDataFrame(all_data, [\"id\", \"features\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2042687"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the dataframe\n",
    "all_df.write\\\n",
    "        .option('compression', 'gzip')\\\n",
    "        .json('/dlabdata1/youtube_large/olam/data/view10000_sub10000/LDA_models/top20/sparkdf.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df_test = spark.read.json('/dlabdata1/youtube_large/olam/data/view10000_sub10000/LDA_models/top10/sparkdf.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- features: struct (nullable = true)\n",
      " |    |-- indices: array (nullable = true)\n",
      " |    |    |-- element: long (containsNull = true)\n",
      " |    |-- size: long (nullable = true)\n",
      " |    |-- type: long (nullable = true)\n",
      " |    |-- values: array (nullable = true)\n",
      " |    |    |-- element: double (containsNull = true)\n",
      " |-- id: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_df_test.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_collect = all_df_test.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-50cba60a02c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'features'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSparseVector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'indices'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'values'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pyspark/ml/linalg/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, size, *args)\u001b[0m\n\u001b[1;32m    529\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m             \u001b[0;32massert\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m                 \u001b[0;34m\"Index %d is out of the size of vector with size=%d\"\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mamax\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mamax\u001b[0;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2666\u001b[0m     \"\"\"\n\u001b[0;32m-> 2667\u001b[0;31m     return _wrapreduction(a, np.maximum, 'max', axis, None, out,\n\u001b[0m\u001b[1;32m   2668\u001b[0m                           keepdims=keepdims, initial=initial, where=where)\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_wrapreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m     passkwargs = {k: v for k, v in kwargs.items()\n\u001b[0m\u001b[1;32m     75\u001b[0m                   if v is not np._NoValue}\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data = []\n",
    "for row in all_df_test.collect():\n",
    "    features = row['features']\n",
    "    data.append([row['id'], SparseVector(features['size'], features['indices'], features['values'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = spark.createDataFrame(data, ['id', 'features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_test.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LDA(k=10, seed=1)\n",
    "model = lda.fit(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe_topics = model.describeTopics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe_topics.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_test = df_collect[0]['features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(indices=[12768, 12772, 42897, 47518, 55859, 72328, 77508, 78050, 87151, 125552, 136529, 150635, 156780, 161250, 166006], size=166209, type=0, values=[1.0, 1.0, 3.0, 1.0, 1.0, 3.0, 1.0, 1.0, 1.0, 1.0, 3.0, 1.0, 1.0, 2.0, 2.0])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseVector(166209, {12768: 1.0, 12772: 1.0, 42897: 3.0, 47518: 1.0, 55859: 1.0, 72328: 3.0, 77508: 1.0, 78050: 1.0, 87151: 1.0, 125552: 1.0, 136529: 3.0, 150635: 1.0, 156780: 1.0, 161250: 2.0, 166006: 2.0})"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SparseVector(row_test['size'], row_test['indices'], row_test['values'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- features: struct (nullable = true)\n",
      " |    |-- indices: array (nullable = true)\n",
      " |    |    |-- element: long (containsNull = true)\n",
      " |    |-- size: long (nullable = true)\n",
      " |    |-- type: long (nullable = true)\n",
      " |    |-- values: array (nullable = true)\n",
      " |    |    |-- element: double (containsNull = true)\n",
      " |-- id: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_df_test.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|features                                                                                                                                                                                                                                  |\n",
      "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|(416311,[5881,16455,18197,77164,152293,162655,185041,203528,225256,295597,356334,375392,377662,386188],[2.0,1.0,1.0,1.0,2.0,1.0,2.0,1.0,1.0,1.0,1.0,2.0,1.0,3.0])                                                                         |\n",
      "|(416311,[3414,5881,8565,18197,34688,62895,110100,143611,152293,176019,240997,243740,274149,295597,310830,326900,355386,377662,386188,413383,414508],[4.0,2.0,1.0,1.0,6.0,1.0,3.0,1.0,2.0,5.0,1.0,1.0,1.0,2.0,1.0,2.0,2.0,1.0,1.0,1.0,2.0])|\n",
      "|(416311,[71878,110683,138833,233338,274761,329338,364657,404596],[1.0,2.0,1.0,2.0,2.0,2.0,1.0,2.0])                                                                                                                                       |\n",
      "|(416311,[209757,251290,299702],[2.0,2.0,2.0])                                                                                                                                                                                             |\n",
      "|(416311,[71878,191803,211388,273759,374263,400701,402381],[2.0,2.0,2.0,2.0,2.0,2.0,2.0])                                                                                                                                                  |\n",
      "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_df.select('features').show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "S_view1000_sub10000 = scipy.sparse.load_npz('/dlabdata1/youtube_large/olam/filtered/csr_matrices/S_final_tok100vid.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<45421300x166209 sparse matrix of type '<class 'numpy.uint8'>'\n",
       "\twith 473957128 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S_view1000_sub10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<24839929x74362 sparse matrix of type '<class 'numpy.uint8'>'\n",
       "\twith 146450642 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S_view1000_sub100000 = scipy.sparse.load_npz('/dlabdata1/youtube_large/olam/filtered/csr_matrices_100000sub/S_final_tok100vid.npz')\n",
    "S_view1000_sub100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<21714294x65907 sparse matrix of type '<class 'numpy.uint8'>'\n",
       "\twith 109510371 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S_view10000_sub10000 = scipy.sparse.load_npz('/dlabdata1/youtube_large/olam/filtered10000/csr_matrices/S_final_tok100vid.npz')\n",
    "S_view10000_sub10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<15167437x42757 sparse matrix of type '<class 'numpy.uint8'>'\n",
       "\twith 58140783 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S_view10000_sub100000 = scipy.sparse.load_npz('/dlabdata1/youtube_large/olam/filtered10000/csr_matrices_100000sub/S_final_tok100vid.npz')\n",
    "S_view10000_sub100000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Remove duplicates of sparse matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicate_rows(data):\n",
    "    unique_row_indices, unique_columns = [], []\n",
    "    \n",
    "    for row_idx, row in enumerate(data):\n",
    "        \n",
    "        indices = row.indices.tolist()\n",
    "        \n",
    "        if indices not in unique_columns:\n",
    "            \n",
    "            unique_columns.append(indices)\n",
    "            unique_row_indices.append(row_idx)\n",
    "            \n",
    "    return data[unique_row_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows = 10\n",
    "ncolumns = 5\n",
    "\n",
    "S_1 = dok_matrix((nrows, ncolumns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([((0, 0), 1.0), ((1, 0), 1.0)])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S_1.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "S_1[0,0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "S_1[1,0] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[1., 0., 0., 0., 0.],\n",
       "        [2., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S_1.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_duplicate_rows(S_1.tocsr()).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
