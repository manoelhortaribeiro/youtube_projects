{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/olam/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import collections\n",
    "import json\n",
    "import nltk\n",
    "import os\n",
    "import pickle\n",
    "import pyLDAvis\n",
    "import random\n",
    "import scipy.sparse\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import zstandard as zstd\n",
    "\n",
    "\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.ml.clustering import LDA, LDAModel, LocalLDAModel\n",
    "from pyspark.ml.linalg import Vectors, SparseVector\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "from scipy.sparse import dok_matrix\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "s_stemmer = SnowballStemmer(language='english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select  the data\n",
    "\n",
    "### Selection criteria\n",
    "- Not used to train the topic modelling\n",
    "- Video with more than 10'000 views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Zreader:\n",
    "\n",
    "    def __init__(self, file, chunk_size=16384):\n",
    "        '''Init method'''\n",
    "        self.fh = open(file,'rb')\n",
    "        self.chunk_size = chunk_size\n",
    "        self.dctx = zstd.ZstdDecompressor()\n",
    "        self.reader = self.dctx.stream_reader(self.fh)\n",
    "        self.buffer = ''\n",
    "\n",
    "\n",
    "    def readlines(self):\n",
    "        '''Generator method that creates an iterator for each line of JSON'''\n",
    "        while True:\n",
    "            chunk = self.reader.read(self.chunk_size).decode(errors=\"ignore\")\n",
    "            if not chunk:\n",
    "                break\n",
    "            lines = (self.buffer + chunk).split(\"\\n\")\n",
    "\n",
    "            for line in lines[:-1]:\n",
    "                yield line\n",
    "\n",
    "            self.buffer = lines[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load set of videos to consider\n",
    "with open('/dlabdata1/youtube_large/olam/data/view10000_sub10000/idx_vid_to_consider.pickle', 'rb') as f:\n",
    "    idx_vid_to_consider = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load channels\n",
    "df_channelcrawler = pd.read_csv('/dlabdata1/youtube_large/channelcrawler.csv')\n",
    "\n",
    "df_channelcrawler['channel_id'] = df_channelcrawler['link'].apply(lambda x: x.replace('http://www.youtube.com/channel/', ''))\n",
    "\n",
    "# filter the channels\n",
    "df_channelcrawler_100000sub = df_channelcrawler[df_channelcrawler['subscribers'] >= 100000]\n",
    "set_channelcrawler_100000sub = set(df_channelcrawler_100000sub['channel_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 1/85\n",
      "Progress: 2/85\n",
      "Progress: 3/85\n",
      "Progress: 4/85\n",
      "Progress: 5/85\n",
      "Progress: 6/85\n",
      "Progress: 7/85\n",
      "Progress: 8/85\n",
      "Progress: 9/85\n",
      "Progress: 10/85\n",
      "Progress: 11/85\n",
      "Progress: 12/85\n",
      "Progress: 13/85\n",
      "Progress: 14/85\n",
      "Progress: 15/85\n",
      "Progress: 16/85\n",
      "Progress: 17/85\n",
      "Progress: 18/85\n",
      "Progress: 19/85\n",
      "Progress: 20/85\n",
      "Progress: 21/85\n",
      "Progress: 22/85\n",
      "Progress: 23/85\n",
      "Progress: 24/85\n",
      "Progress: 25/85\n",
      "Progress: 26/85\n",
      "Progress: 27/85\n",
      "Progress: 28/85\n",
      "Progress: 29/85\n",
      "Progress: 30/85\n",
      "Progress: 31/85\n",
      "Progress: 32/85\n",
      "Progress: 33/85\n",
      "Progress: 34/85\n",
      "Progress: 35/85\n",
      "Progress: 36/85\n",
      "Progress: 37/85\n",
      "Progress: 38/85\n",
      "Progress: 39/85\n",
      "Progress: 40/85\n",
      "Progress: 41/85\n",
      "Progress: 42/85\n",
      "Progress: 43/85\n",
      "Progress: 44/85\n",
      "Progress: 45/85\n",
      "Progress: 46/85\n",
      "Progress: 47/85\n",
      "Progress: 48/85\n",
      "Progress: 49/85\n",
      "Progress: 50/85\n",
      "Progress: 51/85\n",
      "Progress: 52/85\n",
      "Progress: 53/85\n",
      "Progress: 54/85\n",
      "Progress: 55/85\n",
      "Progress: 56/85\n",
      "Progress: 57/85\n",
      "Progress: 58/85\n",
      "Progress: 59/85\n",
      "Progress: 60/85\n",
      "Progress: 61/85\n",
      "Progress: 62/85\n",
      "Progress: 63/85\n",
      "Progress: 64/85\n",
      "Progress: 65/85\n",
      "Progress: 66/85\n",
      "Progress: 67/85\n",
      "Progress: 68/85\n",
      "Progress: 69/85\n",
      "Progress: 70/85\n",
      "Progress: 71/85\n",
      "Progress: 72/85\n",
      "Progress: 73/85\n",
      "Progress: 74/85\n",
      "Progress: 75/85\n",
      "Progress: 76/85\n",
      "Progress: 77/85\n",
      "Progress: 78/85\n",
      "Progress: 79/85\n",
      "Progress: 80/85\n",
      "Progress: 81/85\n",
      "Progress: 82/85\n",
      "Progress: 83/85\n",
      "Progress: 84/85\n",
      "Progress: 85/85\n"
     ]
    }
   ],
   "source": [
    "reader = Zreader(\"/dlabdata1/youtube_large/yt_metadata_all.jsonl.zst\", chunk_size=2**28)\n",
    "\n",
    "idx = 0\n",
    "array_relevant_infos = []\n",
    "\n",
    "for line in reader.readlines():\n",
    "    ###start_iter = time.time()\n",
    "    idx += 1\n",
    "    \n",
    "    if idx % 1000000 == 0:\n",
    "        print('Progress: ' + str(int(idx/1000000)) + '/85')\n",
    "        \n",
    "    if idx in idx_vid_to_consider:\n",
    "        \n",
    "        # line is a str dict, video is the dict corresponding to the str dict\n",
    "        video = json.loads(line)\n",
    "        \n",
    "        array_vid_relevant_infos = [video['channel_id']]\n",
    "        array_vid_relevant_infos.append(video['view_count'])\n",
    "        array_vid_relevant_infos.append(video['upload_date'][:4])\n",
    "        array_vid_relevant_infos.append(video['categories'])\n",
    "        \n",
    "        array_relevant_infos.append(array_vid_relevant_infos)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the dataframe of all the videos that we will consider\n",
    "\n",
    "column_names = ['channel_id', 'view_counts', 'uploaded_year', 'category']\n",
    "\n",
    "df = pd.DataFrame(array_relevant_infos, columns=column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21714294, 4)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove all the videos that are used for topic modelling\n",
    "\n",
    "Find the video indices in the dataframe such that:\n",
    "- more than 100'000 subscribers\n",
    "- top20 from category/channel/year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channel_id</th>\n",
       "      <th>view_counts</th>\n",
       "      <th>uploaded_year</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21326653</th>\n",
       "      <td>UC0C-w0YjGpqDXGB8IHb662A</td>\n",
       "      <td>4468090305</td>\n",
       "      <td>2017</td>\n",
       "      <td>Music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10648298</th>\n",
       "      <td>UCVp3nfGRxmMadNDuVbJSk8A</td>\n",
       "      <td>4295905423</td>\n",
       "      <td>2015</td>\n",
       "      <td>Music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7977749</th>\n",
       "      <td>UCcdwLMPsaU2ezNSJU1nFoBQ</td>\n",
       "      <td>3838039119</td>\n",
       "      <td>2016</td>\n",
       "      <td>Education</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4655616</th>\n",
       "      <td>UCmfFGTSsfJVu6CGvL8r75qg</td>\n",
       "      <td>3709532958</td>\n",
       "      <td>2014</td>\n",
       "      <td>Music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13575776</th>\n",
       "      <td>UCN1hnUccO4FD5WfM7ithXaw</td>\n",
       "      <td>3055180938</td>\n",
       "      <td>2015</td>\n",
       "      <td>Music</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        channel_id  view_counts uploaded_year   category\n",
       "21326653  UC0C-w0YjGpqDXGB8IHb662A   4468090305          2017      Music\n",
       "10648298  UCVp3nfGRxmMadNDuVbJSk8A   4295905423          2015      Music\n",
       "7977749   UCcdwLMPsaU2ezNSJU1nFoBQ   3838039119          2016  Education\n",
       "4655616   UCmfFGTSsfJVu6CGvL8r75qg   3709532958          2014      Music\n",
       "13575776  UCN1hnUccO4FD5WfM7ithXaw   3055180938          2015      Music"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sub100000 = df[df['channel_id'].isin(set_channelcrawler_100000sub)]\n",
    "df_top20 = df_sub100000.sort_values(['view_counts'], ascending=False).groupby(['category', 'uploaded_year', 'channel_id']).head(20)\n",
    "df_top20.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_remove = set(df_top20.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_vid_to_consider_classifier = []\n",
    "\n",
    "for index in df.index:\n",
    "    if index not in index_to_remove:\n",
    "        idx_vid_to_consider_classifier.append(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/dlabdata1/youtube_large/olam/data/classifier/idx_vid_to_consider_classifier.pickle', 'wb') as f:\n",
    "    pickle.dump(idx_vid_to_consider_classifier, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process the data\n",
    "\n",
    "- Transform every video into BoW, according to the topic model vocabulary\n",
    "- Get the transformed data -> distribution over the topic for each video\n",
    "- Separate into train set and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isEnglishAlpha(s):\n",
    "    try:\n",
    "        s.encode(encoding='utf-8').decode('ascii')\n",
    "    except UnicodeDecodeError:\n",
    "        return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_freq_tokens_per_video(video):\n",
    "    ''''''\n",
    "    \n",
    "    title_tokens = [w for w in tokenizer.tokenize(video['title'].lower()) if not w in stop_words]\n",
    "    tag_tokens = [w for w in tokenizer.tokenize(video['tags'].lower()) if not w in stop_words]\n",
    "    \n",
    "    # We want to keep duplicates !!\n",
    "    tokens_per_video = title_tokens + tag_tokens\n",
    "\n",
    "    # Filter token with length < 3, with non english alphabet since fastext is not 100% accurate and remove numerical token \n",
    "    tokens_keep = []\n",
    "    for token in tokens_per_video:\n",
    "        if len(token) >= 3 and (not token.isnumeric()) and isEnglishAlpha(token):\n",
    "            tokens_keep.append(token)\n",
    "    \n",
    "    \n",
    "    # Stemming\n",
    "    stemmed_tokens_per_video = ([s_stemmer.stem(w) for w in tokens_keep])\n",
    "    \n",
    "    \n",
    "    # Return a Counter object of the tokens\n",
    "    return collections.Counter(tokens_keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_underlying_dict(freq_tokens_per_video, dict_stemmed_tokens, i_vid):\n",
    "    '''Method to fill the underlying dictionnary in order to \n",
    "    update the sparse matrix incrementally by videos'''\n",
    "    \n",
    "    dict_freq_tokens_for_sparse_matrix = {}\n",
    "    \n",
    "    for key in freq_tokens_per_video.keys():\n",
    "        \n",
    "        # Column index in the sparse matrix (one column for each token)\n",
    "        try:\n",
    "            j_token = dict_stemmed_tokens[key]\n",
    "            \n",
    "            # Filling the underlying dict\n",
    "            dict_freq_tokens_for_sparse_matrix[(i_vid % 1000000, j_token)] = freq_tokens_per_video[key]\n",
    "            \n",
    "        except KeyError:\n",
    "            None\n",
    "    \n",
    "    return dict_freq_tokens_for_sparse_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_zero_rows(M):\n",
    "    '''Function that removes all rows from sparse matrix M that contains only zero.'''\n",
    "    num_nonzeros = np.diff(M.indptr)\n",
    "    return M[num_nonzeros != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dictionnary of words\n",
    "with open('/dlabdata1/youtube_large/olam/data/view10000_sub100000/id2word_tok100vid_sub100000.pickle', 'rb') as f:\n",
    "    id2word = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "# Load index of data for classifier\n",
    "with open('/dlabdata1/youtube_large/olam/data/classifier/idx_vid_to_consider_classifier.pickle', 'rb') as f:\n",
    "    idx_vid_to_consider_classifier = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2id = {v: k for k, v in id2word.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_vid_to_consider_sorted = list(idx_vid_to_consider)\n",
    "idx_vid_to_consider_sorted.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_data = set([idx_vid_to_consider_sorted[i] for i in idx_vid_to_consider_classifier])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/dlabdata1/youtube_large/olam/data/classifier/index_data.pickle', 'wb') as f:\n",
    "    pickle.dump(index_data, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load index of data for classifier\n",
    "with open('/dlabdata1/youtube_large/olam/data/classifier/index_data.pickle', 'rb') as f:\n",
    "    index_data = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = list(id2word.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 10000000 videos...\n",
      "Processed 20000000 videos...\n",
      "Processed 30000000 videos...\n",
      "Processed 40000000 videos...\n",
      "Processed 50000000 videos...\n",
      "Processed 60000000 videos...\n",
      "Processed 70000000 videos...\n",
      "Processed 80000000 videos...\n"
     ]
    }
   ],
   "source": [
    "data = dok_matrix((1000000, len(vocab)), dtype=np.uint8)\n",
    "groundtruth = []\n",
    "\n",
    "\n",
    "reader = Zreader(\n",
    "    \"/dlabdata1/youtube_large/yt_metadata_all.jsonl.zst\", chunk_size=2**28)\n",
    "\n",
    "idx = 0\n",
    "i_vid = 0\n",
    "\n",
    "for line in reader.readlines():\n",
    "    ###start_iter = time.time()\n",
    "    idx += 1\n",
    "\n",
    "    if idx % 10000000 == 0:\n",
    "        print('Processed ' + str(idx) + ' videos...')\n",
    "\n",
    "    if i_vid % 1000000 == 0 and i_vid != 0:\n",
    "\n",
    "        file_name = 'data' + str(int(i_vid / 1000000)) + '.npz'\n",
    "        \n",
    "        if not os.path.isfile('/dlabdata1/youtube_large/olam/data/classifier/csr_matrices/' + file_name):\n",
    "            \n",
    "            data = data.tocsr()\n",
    "            scipy.sparse.save_npz(\n",
    "                '/dlabdata1/youtube_large/olam/data/classifier/csr_matrices/' + file_name, data)\n",
    "            data = dok_matrix((1000000, len(vocab)), dtype=np.uint8)\n",
    "\n",
    "    if idx in index_data:\n",
    "\n",
    "        # line is a str dict, video is the dict corresponding to the str dict\n",
    "        video = json.loads(line)\n",
    "\n",
    "        # Get the tokens for each video and theirs number of occurences\n",
    "        freq_tokens_per_video = get_freq_tokens_per_video(video)\n",
    "\n",
    "        # For each video, create a underlying dictionnary for filling the sparse matrix efficiently\n",
    "        dict_freq_tokens_for_sparse_matrix = fill_underlying_dict(\n",
    "            freq_tokens_per_video, word2id, i_vid)\n",
    "\n",
    "        # Need to check that the video contains token from the reduced vocabulary\n",
    "        if dict_freq_tokens_for_sparse_matrix != {}:\n",
    "\n",
    "            # Update the Sparse Matrix\n",
    "            dict.update(data, dict_freq_tokens_for_sparse_matrix)\n",
    "            i_vid += 1\n",
    "\n",
    "            # Get groundtruth values\n",
    "            groundtruth.append(video['categories'])\n",
    "\n",
    "# Save last sparse matrix\n",
    "data = data.tocsr()\n",
    "data = remove_zero_rows(data)\n",
    "scipy.sparse.save_npz(\n",
    "    '/dlabdata1/youtube_large/olam/data/classifier/csr_matrices/data_last.npz', data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get training features for classifier\n",
    "\n",
    "- get full matrix of BoW\n",
    "- process for pyspark\n",
    "- !!! on the cluster, run the model, SAVE the model AND transformed data \n",
    "- transform the data to have k features, which are the distribution over the topics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get full matrix of BoW\n",
    "data = scipy.sparse.load_npz('/dlabdata1/youtube_large/olam/data/classifier/csr_matrices/data1.npz')\n",
    "\n",
    "for i in range(2, 18):\n",
    "    data_next = scipy.sparse.load_npz('/dlabdata1/youtube_large/olam/data/classifier/csr_matrices/data' + str(i) + '.npz')\n",
    "    data = scipy.sparse.vstack([data, data_next])\n",
    "\n",
    "# Add last matrix\n",
    "data_last = scipy.sparse.load_npz('/dlabdata1/youtube_large/olam/data/classifier/csr_matrices/data_last.npz')\n",
    "data = scipy.sparse.vstack([data, data_last])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(groundtruth) == remove_zero_rows(data).shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.sparse.save_npz('/dlabdata1/youtube_large/olam/data/classifier/csr_matrices/data_final.npz', data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/dlabdata1/youtube_large/olam/data/classifier/groundtruth.pickle', 'wb') as f:\n",
    "    pickle.dump(groundtruth, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dict_for_row(row, S):\n",
    "    '''Construct SparseVector bag-of-word for each row (videos)'''\n",
    "    tmp_dict = {}\n",
    "    for key, value in row:\n",
    "        tmp_dict[key[1]] = value\n",
    "\n",
    "    return SparseVector(S.shape[1], tmp_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = scipy.sparse.load_npz('/dlabdata1/youtube_large/olam/data/classifier/csr_matrices/data_final.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process video for topic modelling...\n",
      "0 videos processed...\n",
      "5000000 videos processed...\n",
      "10000000 videos processed...\n",
      "15000000 videos processed...\n"
     ]
    }
   ],
   "source": [
    "# process for pyspark\n",
    "\n",
    "data_spark = []\n",
    "\n",
    "print('Process video for topic modelling...')\n",
    "for i in range(data.shape[0]):\n",
    "\n",
    "    if i % 5000000 == 0:\n",
    "        print(str(i) + ' videos processed...')\n",
    "\n",
    "    data_spark.append([i, get_dict_for_row(data.getrow(i).todok().items(), data)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/dlabdata1/youtube_large/olam/data/classifier/list_data_spark.pickle', 'wb') as f:\n",
    "    pickle.dump(data_spark, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/olam/anaconda3/lib/python3.8/site-packages/pyspark/sql/context.py:75: DeprecationWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "conf = SparkConf().setMaster(\"local[8]\").setAll([('spark.executor.memory', '10g'),('spark.driver.memory','32g'),('spark.driver.maxResultSize', '0')])\n",
    "\n",
    "# create the session\n",
    "spark = SparkSession.builder.config(conf=conf).getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct dataframe for LDA\n",
    "df = spark.createDataFrame(data_spark, [\"id\", \"features\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the spark dataframe\n",
    "#save the dataframe\n",
    "df.write\\\n",
    "        .option('compression', 'gzip')\\\n",
    "        .json('/dlabdata1/youtube_large/olam/data/classifier/sparkdf_data.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get model and/or transformed data!\n",
    "\n",
    "model = LocalLDAModel.load('/dlabdata1/youtube_large/olam/data/classifier/best_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_data = model.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+--------------------+\n",
      "| id|            features|   topicDistribution|\n",
      "+---+--------------------+--------------------+\n",
      "|  0|(42757,[1230,3534...|[3.41848242604404...|\n",
      "|  1|(42757,[851,4683,...|[3.10372866523442...|\n",
      "|  2|(42757,[851,986,4...|[2.92423131538094...|\n",
      "|  3|(42757,[851,986,1...|[3.95298682552134...|\n",
      "|  4|(42757,[851,986,3...|[2.84204946225357...|\n",
      "|  5|(42757,[851,4683,...|[2.55484644367840...|\n",
      "|  6|(42757,[851,986,4...|[3.20200251989183...|\n",
      "|  7|(42757,[851,4683,...|[3.53808319352224...|\n",
      "|  8|(42757,[851,4683,...|[3.53808319352224...|\n",
      "|  9|(42757,[851,2333,...|[0.03949832339932...|\n",
      "| 10|(42757,[851,4683,...|[3.30670318920320...|\n",
      "| 11|(42757,[851,4683,...|[2.92423131538095...|\n",
      "| 12|(42757,[851,4683,...|[3.01130750254167...|\n",
      "| 13|(42757,[851,1044,...|[3.01130750254167...|\n",
      "| 14|(42757,[851,3230,...|[3.01130750254167...|\n",
      "| 15|(42757,[851,1730,...|[0.03535400904659...|\n",
      "| 16|(42757,[851,3663,...|[3.10372866523443...|\n",
      "| 17|(42757,[851,4683,...|[3.66635619908709...|\n",
      "| 18|(42757,[851,4683,...|[3.41848242604404...|\n",
      "| 19|(42757,[851,2766,...|[3.30670318920320...|\n",
      "+---+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transformed_data.show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_videos_in_dataset = transformed_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 500000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iter = int(number_videos_in_dataset / batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_iter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_topic = 125"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Because of the memory issue, we will create a Sparse matrix that contains the distribution over the topics for each video.\n",
    "\n",
    "- For that, we slide the data into 35 batches and for each one, we will create a dok sparse matrix and in the end, we will save all the results in the compressed csc format and in the end we will be able to stack all the \"sub\" sparse matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 35/35\n"
     ]
    }
   ],
   "source": [
    "for k in range(n_iter):\n",
    "    \n",
    "    print('Iteration ' + str(k + 1) + '/' + str(n_iter))\n",
    "    \n",
    "    transformed_data_sub = transformed_data.where(\n",
    "        col(\"id\").between(0 + k * 500000, (k + 1) * 500000 - 1))\n",
    "\n",
    "    # Create sparse matrix\n",
    "    S = dok_matrix((batch_size, n_topic))\n",
    "\n",
    "    for i, topic_dist_one_vid in enumerate(transformed_data_sub.select('topicDistribution').collect()):\n",
    "\n",
    "        dict_topic_dist_one_vid = {}\n",
    "\n",
    "        for j, prob in enumerate(topic_dist_one_vid['topicDistribution']):\n",
    "\n",
    "            dict_topic_dist_one_vid[(i, j)] = prob\n",
    "\n",
    "        # Fill data in to sparse matrix\n",
    "        dict.update(S, dict_topic_dist_one_vid)\n",
    "\n",
    "    filename = 'transformed_data' + str(k) + '.npz'\n",
    "    scipy.sparse.save_npz(\n",
    "        '/dlabdata1/youtube_large/olam/data/classifier/csr_matrices/' + filename, S.tocsr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# last iteration\n",
    "transformed_data_sub = transformed_data.where(\n",
    "    col(\"id\").between(0 + n_iter * 500000, number_videos_in_dataset + 1))\n",
    "\n",
    "S = dok_matrix((number_videos_in_dataset - batch_size * n_iter, n_topic))\n",
    "\n",
    "for i, topic_dist_one_vid in enumerate(transformed_data_sub.select('topicDistribution').collect()):\n",
    "\n",
    "    dict_topic_dist_one_vid = {}\n",
    "\n",
    "    for j, prob in enumerate(topic_dist_one_vid['topicDistribution']):\n",
    "\n",
    "        dict_topic_dist_one_vid[(i, j)] = prob\n",
    "\n",
    "    # Fill data in to sparse matrix\n",
    "    dict.update(S, dict_topic_dist_one_vid)\n",
    "\n",
    "filename = 'transformed_data_last.npz'\n",
    "scipy.sparse.save_npz(\n",
    "    '/dlabdata1/youtube_large/olam/data/classifier/csr_matrices/' + filename, S.tocsr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'transformed_data_last.npz'\n",
    "scipy.sparse.save_npz(\n",
    "    '/dlabdata1/youtube_large/olam/data/classifier/csr_matrices/' + filename, S.tocsr())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the classifier\n",
    "\n",
    "- Train set into train' and validation set, in order to do cross validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = scipy.sparse.load_npz(\n",
    "    '/dlabdata1/youtube_large/olam/data/classifier/csr_matrices/transformed_data0.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 35):\n",
    "    data_next = scipy.sparse.load_npz(\n",
    "        '/dlabdata1/youtube_large/olam/data/classifier/csr_matrices/transformed_data' + str(i) + '.npz')\n",
    "    data = scipy.sparse.vstack([data, data_next])\n",
    "\n",
    "# Add last matrix\n",
    "data_next = scipy.sparse.load_npz(\n",
    "    '/dlabdata1/youtube_large/olam/data/classifier/csr_matrices/transformed_data_last.npz')\n",
    "data = scipy.sparse.vstack([data, data_next])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data features\n",
    "data = scipy.sparse.load_npz(\n",
    "    '/dlabdata1/youtube_large/olam/data/classifier/csr_matrices/transformed_data_final.npz')\n",
    "\n",
    "# Load groundtruth\n",
    "with open('/dlabdata1/youtube_large/olam/data/classifier/groundtruth.pickle', 'rb') as f:\n",
    "    groundtruth = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separate the data for building the model and testing it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load list of shuffled index\n",
    "with open('/dlabdata1/youtube_large/olam/data/classifier/list_suffled_idx.pickle', 'rb') as f:\n",
    "    index = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_model_data_threshold = int(0.8 * len(groundtruth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_model_threshold = int(0.6 * len(groundtruth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_train_idx = np.sort(index[:training_model_threshold])\n",
    "list_val_idx = np.sort(index[training_model_threshold:index_model_data_threshold])\n",
    "list_test_idx = np.sort(index[index_model_data_threshold:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_train_idx) + len(list_val_idx) + len(list_test_idx) == len(groundtruth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "### too much memory consumption\n",
    "# X = data[:index_model_data_threshold]\n",
    "# X_test = data[index_model_data_threshold:]\n",
    "\n",
    "# y = groundtruth[:index_model_data_threshold]\n",
    "# y_test = groundtruth[index_model_data_threshold:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = np.logspace(0, 1, num=10, base=100) / 100\n",
    "alphas_test = [0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time for iter : 5.230132786432902\n",
      "score: 0.35073358812759964\n",
      "\n",
      "time for iter : 6.296019558111826\n",
      "score: 0.29902835078364703\n",
      "\n",
      "time for iter : 7.983751229445139\n",
      "score: 0.2731599832386995\n",
      "\n",
      "time for iter : 8.08760746717453\n",
      "score: 0.2595327084405522\n",
      "\n",
      "time for iter : 8.459673058986663\n",
      "score: 0.24998495420171493\n",
      "\n",
      "time for iter : 8.297085611025492\n",
      "score: 0.24647942381623314\n",
      "\n",
      "time for iter : 7.691592129071553\n",
      "score: 0.2524392473163639\n",
      "\n",
      "time for iter : 6.180642422040304\n",
      "score: 0.2580585014384908\n",
      "\n",
      "time for iter : 5.008745809396108\n",
      "score: 0.30795852421811065\n",
      "\n",
      "time for iter : 4.184794783592224\n",
      "score: 0.3873328439933517\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracies = []\n",
    "\n",
    "for i, alpha in enumerate(alphas):\n",
    "\n",
    "    start = time.time()\n",
    "    clf = SGDClassifier(loss='log', alpha=alpha, max_iter=50, shuffle=True, n_jobs=10, random_state=1)\n",
    "    clf.fit(data[list_train_idx],\n",
    "            y=np.array(groundtruth)[list_train_idx])\n",
    "    \n",
    "    y_pred = clf.predict(data[list_val_idx])\n",
    "    y_gt = np.array(groundtruth)[list_val_idx]\n",
    "    \n",
    "    score = accuracy_score(y_gt, y_pred)\n",
    "    accuracies.append(score)\n",
    "    print('time for iter ' + str() + ': ' + str((time.time() - start) / 60))\n",
    "    print('score: ' + str(score))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time for iter : 2.728762944539388\n",
      "score: 0.5270121294444866\n",
      "\n",
      "time for iter : 2.608687388896942\n",
      "score: 0.5270335029149477\n",
      "\n",
      "time for iter : 2.6261629541714986\n",
      "score: 0.5261884071421139\n",
      "\n",
      "time for iter : 2.636353937784831\n",
      "score: 0.5240769332444647\n",
      "\n",
      "time for iter : 2.7797876954078675\n",
      "score: 0.5053132760186849\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/olam/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:570: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time for iter : 4.567264437675476\n",
      "score: 0.24036014297726818\n",
      "\n",
      "time for iter : 9.345357275009155\n",
      "score: 0.24359203669487403\n",
      "\n",
      "time for iter : 9.68878736893336\n",
      "score: 0.25403578931382725\n",
      "\n",
      "time for iter : 8.74266619682312\n",
      "score: 0.2910329854519786\n",
      "\n",
      "time for iter : 7.858613804976145\n",
      "score: 0.3837508190820094\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracies = []\n",
    "\n",
    "for i, alpha in enumerate(alphas):\n",
    "\n",
    "    start = time.time()\n",
    "    clf = SGDClassifier(loss='hinge', alpha=alpha, max_iter=20, shuffle=True, n_jobs=10, random_state=1)\n",
    "    clf.fit(data[list_train_idx],\n",
    "            y=np.array(groundtruth)[list_train_idx])\n",
    "    \n",
    "    y_pred = clf.predict(data[list_val_idx])\n",
    "    y_gt = np.array(groundtruth)[list_val_idx]\n",
    "    \n",
    "    score = accuracy_score(y_gt, y_pred)\n",
    "    accuracies.append(score)\n",
    "    print('time for iter ' + str() + ': ' + str((time.time() - start) / 60))\n",
    "    print('score: ' + str(score))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_alpha = alphas[np.argmax(accuracies)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.027825594022071246"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.027825594022071246, max_iter=20, n_jobs=10,\n",
       "              random_state=1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = SGDClassifier(loss='hinge', alpha=best_alpha, max_iter=20, shuffle=True, n_jobs=10, random_state=1)\n",
    "clf.fit(data[list_train_idx],\n",
    "        y=np.array(groundtruth)[list_train_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set of the best model: 0.5263785678817267\n"
     ]
    }
   ],
   "source": [
    "Y_pred_train = clf.predict(data[list_train_idx])\n",
    "y_gt_train = np.array(groundtruth)[list_train_idx]\n",
    "\n",
    "score_train = accuracy_score(y_gt_train, Y_pred_train)\n",
    "\n",
    "print('Accuracy on training set of the best model: ' + str(score_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set of the best model: 0.5264752616140908\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(data[list_test_idx])\n",
    "y_gt = np.array(groundtruth)[list_test_idx]\n",
    "\n",
    "score_test = accuracy_score(y_gt, y_pred)\n",
    "\n",
    "print('Accuracy on test set of the best model: ' + str(score_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3555810"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/dlabdata1/youtube_large/olam/data/classifier/results/y_pred.pickle', 'wb') as f:\n",
    "    pickle.dump(y_pred, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/dlabdata1/youtube_large/olam/data/classifier/results/y_gt.pickle', 'wb') as f:\n",
    "    pickle.dump(y_gt, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/dlabdata1/youtube_large/olam/data/classifier/results/y_pred.pickle', 'rb') as f:\n",
    "    y_pred = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "with open('/dlabdata1/youtube_large/olam/data/classifier/results/y_gt.pickle', 'rb') as f:\n",
    "    y_gt = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_pred) == len(y_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       precision    recall  f1-score   support\n",
      "\n",
      "                           0.000     0.000     0.000        52\n",
      "     Autos & Vehicles      0.567     0.634     0.598    115117\n",
      "               Comedy      0.257     0.032     0.058     67846\n",
      "            Education      0.375     0.098     0.155    152130\n",
      "        Entertainment      0.518     0.385     0.442    726320\n",
      "     Film & Animation      0.199     0.043     0.071    136741\n",
      "               Gaming      0.552     0.950     0.698    828637\n",
      "        Howto & Style      0.486     0.536     0.510    215770\n",
      "                Music      0.546     0.757     0.635    400809\n",
      "      News & Politics      0.542     0.683     0.604    199635\n",
      "Nonprofits & Activism      0.021     0.000     0.001     19620\n",
      "       People & Blogs      0.253     0.056     0.092    289254\n",
      "       Pets & Animals      0.126     0.046     0.068     25219\n",
      " Science & Technology      0.540     0.311     0.395    122792\n",
      "                Shows      0.000     0.000     0.000         4\n",
      "               Sports      0.526     0.447     0.483    216902\n",
      "      Travel & Events      0.149     0.027     0.046     38962\n",
      "\n",
      "             accuracy                          0.526   3555810\n",
      "            macro avg      0.333     0.294     0.286   3555810\n",
      "         weighted avg      0.477     0.526     0.471   3555810\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the precision and recall, among other metricss\n",
    "print(classification_report(y_gt, y_pred, digits=3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
