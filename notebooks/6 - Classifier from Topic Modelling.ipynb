{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import json\n",
    "import pickle\n",
    "import pyLDAvis\n",
    "import random\n",
    "import scipy.sparse\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import zstandard as zstd\n",
    "\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select select the data\n",
    "\n",
    "### Selection criteria\n",
    "- Not used to train the topic modelling\n",
    "- Video with more than 10'000 views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Zreader:\n",
    "\n",
    "    def __init__(self, file, chunk_size=16384):\n",
    "        '''Init method'''\n",
    "        self.fh = open(file,'rb')\n",
    "        self.chunk_size = chunk_size\n",
    "        self.dctx = zstd.ZstdDecompressor()\n",
    "        self.reader = self.dctx.stream_reader(self.fh)\n",
    "        self.buffer = ''\n",
    "\n",
    "\n",
    "    def readlines(self):\n",
    "        '''Generator method that creates an iterator for each line of JSON'''\n",
    "        while True:\n",
    "            chunk = self.reader.read(self.chunk_size).decode(errors=\"ignore\")\n",
    "            if not chunk:\n",
    "                break\n",
    "            lines = (self.buffer + chunk).split(\"\\n\")\n",
    "\n",
    "            for line in lines[:-1]:\n",
    "                yield line\n",
    "\n",
    "            self.buffer = lines[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load set of videos to consider\n",
    "with open('/dlabdata1/youtube_large/olam/data/view10000_sub10000/idx_vid_to_consider.pickle', 'rb') as f:\n",
    "    idx_vid_to_consider = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load channels\n",
    "df_channelcrawler = pd.read_csv('/dlabdata1/youtube_large/channelcrawler.csv')\n",
    "\n",
    "df_channelcrawler['channel_id'] = df_channelcrawler['link'].apply(lambda x: x.replace('http://www.youtube.com/channel/', ''))\n",
    "\n",
    "# filter the channels\n",
    "df_channelcrawler_100000sub = df_channelcrawler[df_channelcrawler['subscribers'] >= 100000]\n",
    "set_channelcrawler_100000sub = set(df_channelcrawler_100000sub['channel_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 1/85\n",
      "Progress: 2/85\n",
      "Progress: 3/85\n",
      "Progress: 4/85\n",
      "Progress: 5/85\n",
      "Progress: 6/85\n",
      "Progress: 7/85\n",
      "Progress: 8/85\n",
      "Progress: 9/85\n",
      "Progress: 10/85\n",
      "Progress: 11/85\n",
      "Progress: 12/85\n",
      "Progress: 13/85\n",
      "Progress: 14/85\n",
      "Progress: 15/85\n",
      "Progress: 16/85\n",
      "Progress: 17/85\n",
      "Progress: 18/85\n",
      "Progress: 19/85\n",
      "Progress: 20/85\n",
      "Progress: 21/85\n",
      "Progress: 22/85\n",
      "Progress: 23/85\n",
      "Progress: 24/85\n",
      "Progress: 25/85\n",
      "Progress: 26/85\n",
      "Progress: 33/85\n",
      "Progress: 34/85\n",
      "Progress: 35/85\n",
      "Progress: 36/85\n",
      "Progress: 37/85\n",
      "Progress: 38/85\n",
      "Progress: 39/85\n",
      "Progress: 40/85\n",
      "Progress: 41/85\n",
      "Progress: 42/85\n",
      "Progress: 43/85\n",
      "Progress: 44/85\n",
      "Progress: 45/85\n",
      "Progress: 46/85\n",
      "Progress: 47/85\n",
      "Progress: 48/85\n",
      "Progress: 49/85\n",
      "Progress: 50/85\n",
      "Progress: 51/85\n",
      "Progress: 52/85\n",
      "Progress: 53/85\n",
      "Progress: 54/85\n",
      "Progress: 55/85\n",
      "Progress: 56/85\n",
      "Progress: 57/85\n",
      "Progress: 58/85\n",
      "Progress: 59/85\n",
      "Progress: 60/85\n",
      "Progress: 61/85\n",
      "Progress: 62/85\n",
      "Progress: 63/85\n",
      "Progress: 64/85\n",
      "Progress: 65/85\n",
      "Progress: 66/85\n",
      "Progress: 67/85\n",
      "Progress: 68/85\n",
      "Progress: 69/85\n",
      "Progress: 70/85\n",
      "Progress: 71/85\n",
      "Progress: 72/85\n",
      "Progress: 73/85\n",
      "Progress: 74/85\n",
      "Progress: 75/85\n",
      "Progress: 76/85\n",
      "Progress: 77/85\n",
      "Progress: 78/85\n",
      "Progress: 79/85\n",
      "Progress: 80/85\n",
      "Progress: 81/85\n",
      "Progress: 82/85\n",
      "Progress: 83/85\n",
      "Progress: 84/85\n",
      "Progress: 85/85\n"
     ]
    }
   ],
   "source": [
    "reader = Zreader(\"/dlabdata1/youtube_large/yt_metadata_all.jsonl.zst\", chunk_size=2**28)\n",
    "\n",
    "idx = 0\n",
    "array_relevant_infos = []\n",
    "\n",
    "for line in reader.readlines():\n",
    "    ###start_iter = time.time()\n",
    "    idx += 1\n",
    "    \n",
    "    if idx % 1000000 == 0:\n",
    "        print('Progress: ' + str(int(idx/1000000)) + '/85')\n",
    "        \n",
    "    if idx in idx_vid_to_consider:\n",
    "        \n",
    "        # line is a str dict, video is the dict corresponding to the str dict\n",
    "        video = json.loads(line)\n",
    "        \n",
    "        array_vid_relevant_infos = [video['channel_id']]\n",
    "        array_vid_relevant_infos.append(video['view_count'])\n",
    "        array_vid_relevant_infos.append(video['upload_date'][:4])\n",
    "        array_vid_relevant_infos.append(video['categories'])\n",
    "        \n",
    "        array_relevant_infos.append(array_vid_relevant_infos)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the dataframe of all the videos that we will consider\n",
    "\n",
    "column_names = ['channel_id', 'view_counts', 'uploaded_year', 'category']\n",
    "\n",
    "df = pd.DataFrame(array_relevant_infos, columns=column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove all the videos that are used for topic modelling\n",
    "\n",
    "Find the video indices in the dataframe such that:\n",
    "- more than 100'000 subscribers\n",
    "- top20 from category/channel/year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channel_id</th>\n",
       "      <th>view_counts</th>\n",
       "      <th>uploaded_year</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21326653</th>\n",
       "      <td>UC0C-w0YjGpqDXGB8IHb662A</td>\n",
       "      <td>4468090305</td>\n",
       "      <td>2017</td>\n",
       "      <td>Music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10648298</th>\n",
       "      <td>UCVp3nfGRxmMadNDuVbJSk8A</td>\n",
       "      <td>4295905423</td>\n",
       "      <td>2015</td>\n",
       "      <td>Music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7977749</th>\n",
       "      <td>UCcdwLMPsaU2ezNSJU1nFoBQ</td>\n",
       "      <td>3838039119</td>\n",
       "      <td>2016</td>\n",
       "      <td>Education</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4655616</th>\n",
       "      <td>UCmfFGTSsfJVu6CGvL8r75qg</td>\n",
       "      <td>3709532958</td>\n",
       "      <td>2014</td>\n",
       "      <td>Music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13575776</th>\n",
       "      <td>UCN1hnUccO4FD5WfM7ithXaw</td>\n",
       "      <td>3055180938</td>\n",
       "      <td>2015</td>\n",
       "      <td>Music</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        channel_id  view_counts uploaded_year   category\n",
       "21326653  UC0C-w0YjGpqDXGB8IHb662A   4468090305          2017      Music\n",
       "10648298  UCVp3nfGRxmMadNDuVbJSk8A   4295905423          2015      Music\n",
       "7977749   UCcdwLMPsaU2ezNSJU1nFoBQ   3838039119          2016  Education\n",
       "4655616   UCmfFGTSsfJVu6CGvL8r75qg   3709532958          2014      Music\n",
       "13575776  UCN1hnUccO4FD5WfM7ithXaw   3055180938          2015      Music"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sub100000 = df[df['channel_id'].isin(set_channelcrawler_100000sub)]\n",
    "df_top20 = df_sub100000.sort_values(['view_counts'], ascending=False).groupby(['category', 'uploaded_year', 'channel_id']).head(20)\n",
    "df_top20.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_remove = set(df_top20.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process the data\n",
    "\n",
    "- Transform every video into BoW, according to the topic model vocabulary\n",
    "- Get the transformed data -> distribution over the topic for each video\n",
    "- Separate into train set and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the classifier\n",
    "\n",
    "- Train set into train' and validation set, in order to do cross validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
