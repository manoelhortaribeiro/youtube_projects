{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/olam/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import collections\n",
    "import json\n",
    "import nltk\n",
    "import os\n",
    "import pickle\n",
    "import pyLDAvis\n",
    "import random\n",
    "import scipy.sparse\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import zstandard as zstd\n",
    "\n",
    "\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.ml.clustering import LDA, LDAModel, LocalLDAModel\n",
    "from pyspark.ml.linalg import Vectors, SparseVector\n",
    "from pyspark.sql import SparkSession\n",
    "from scipy.sparse import dok_matrix\n",
    "\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "s_stemmer = SnowballStemmer(language='english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select select the data\n",
    "\n",
    "### Selection criteria\n",
    "- Not used to train the topic modelling\n",
    "- Video with more than 10'000 views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Zreader:\n",
    "\n",
    "    def __init__(self, file, chunk_size=16384):\n",
    "        '''Init method'''\n",
    "        self.fh = open(file,'rb')\n",
    "        self.chunk_size = chunk_size\n",
    "        self.dctx = zstd.ZstdDecompressor()\n",
    "        self.reader = self.dctx.stream_reader(self.fh)\n",
    "        self.buffer = ''\n",
    "\n",
    "\n",
    "    def readlines(self):\n",
    "        '''Generator method that creates an iterator for each line of JSON'''\n",
    "        while True:\n",
    "            chunk = self.reader.read(self.chunk_size).decode(errors=\"ignore\")\n",
    "            if not chunk:\n",
    "                break\n",
    "            lines = (self.buffer + chunk).split(\"\\n\")\n",
    "\n",
    "            for line in lines[:-1]:\n",
    "                yield line\n",
    "\n",
    "            self.buffer = lines[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load set of videos to consider\n",
    "with open('/dlabdata1/youtube_large/olam/data/view10000_sub10000/idx_vid_to_consider.pickle', 'rb') as f:\n",
    "    idx_vid_to_consider = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load channels\n",
    "df_channelcrawler = pd.read_csv('/dlabdata1/youtube_large/channelcrawler.csv')\n",
    "\n",
    "df_channelcrawler['channel_id'] = df_channelcrawler['link'].apply(lambda x: x.replace('http://www.youtube.com/channel/', ''))\n",
    "\n",
    "# filter the channels\n",
    "df_channelcrawler_100000sub = df_channelcrawler[df_channelcrawler['subscribers'] >= 100000]\n",
    "set_channelcrawler_100000sub = set(df_channelcrawler_100000sub['channel_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 1/85\n",
      "Progress: 2/85\n",
      "Progress: 3/85\n",
      "Progress: 4/85\n",
      "Progress: 5/85\n",
      "Progress: 6/85\n",
      "Progress: 7/85\n",
      "Progress: 8/85\n",
      "Progress: 9/85\n",
      "Progress: 10/85\n",
      "Progress: 11/85\n",
      "Progress: 12/85\n",
      "Progress: 13/85\n",
      "Progress: 14/85\n",
      "Progress: 15/85\n",
      "Progress: 16/85\n",
      "Progress: 17/85\n",
      "Progress: 18/85\n",
      "Progress: 19/85\n",
      "Progress: 20/85\n",
      "Progress: 21/85\n",
      "Progress: 22/85\n",
      "Progress: 23/85\n",
      "Progress: 24/85\n",
      "Progress: 25/85\n",
      "Progress: 26/85\n",
      "Progress: 27/85\n",
      "Progress: 28/85\n",
      "Progress: 29/85\n",
      "Progress: 30/85\n",
      "Progress: 31/85\n",
      "Progress: 32/85\n",
      "Progress: 33/85\n",
      "Progress: 34/85\n",
      "Progress: 35/85\n",
      "Progress: 36/85\n",
      "Progress: 37/85\n",
      "Progress: 38/85\n",
      "Progress: 39/85\n",
      "Progress: 40/85\n",
      "Progress: 41/85\n",
      "Progress: 42/85\n",
      "Progress: 43/85\n",
      "Progress: 44/85\n",
      "Progress: 45/85\n",
      "Progress: 46/85\n",
      "Progress: 47/85\n",
      "Progress: 48/85\n",
      "Progress: 49/85\n",
      "Progress: 50/85\n",
      "Progress: 51/85\n",
      "Progress: 52/85\n",
      "Progress: 53/85\n",
      "Progress: 54/85\n",
      "Progress: 55/85\n",
      "Progress: 56/85\n",
      "Progress: 57/85\n",
      "Progress: 58/85\n",
      "Progress: 59/85\n",
      "Progress: 60/85\n",
      "Progress: 61/85\n",
      "Progress: 62/85\n",
      "Progress: 63/85\n",
      "Progress: 64/85\n",
      "Progress: 65/85\n",
      "Progress: 66/85\n",
      "Progress: 67/85\n",
      "Progress: 68/85\n",
      "Progress: 69/85\n",
      "Progress: 70/85\n",
      "Progress: 71/85\n",
      "Progress: 72/85\n",
      "Progress: 73/85\n",
      "Progress: 74/85\n",
      "Progress: 75/85\n",
      "Progress: 76/85\n",
      "Progress: 77/85\n",
      "Progress: 78/85\n",
      "Progress: 79/85\n",
      "Progress: 80/85\n",
      "Progress: 81/85\n",
      "Progress: 82/85\n",
      "Progress: 83/85\n",
      "Progress: 84/85\n",
      "Progress: 85/85\n"
     ]
    }
   ],
   "source": [
    "reader = Zreader(\"/dlabdata1/youtube_large/yt_metadata_all.jsonl.zst\", chunk_size=2**28)\n",
    "\n",
    "idx = 0\n",
    "array_relevant_infos = []\n",
    "\n",
    "for line in reader.readlines():\n",
    "    ###start_iter = time.time()\n",
    "    idx += 1\n",
    "    \n",
    "    if idx % 1000000 == 0:\n",
    "        print('Progress: ' + str(int(idx/1000000)) + '/85')\n",
    "        \n",
    "    if idx in idx_vid_to_consider:\n",
    "        \n",
    "        # line is a str dict, video is the dict corresponding to the str dict\n",
    "        video = json.loads(line)\n",
    "        \n",
    "        array_vid_relevant_infos = [video['channel_id']]\n",
    "        array_vid_relevant_infos.append(video['view_count'])\n",
    "        array_vid_relevant_infos.append(video['upload_date'][:4])\n",
    "        array_vid_relevant_infos.append(video['categories'])\n",
    "        \n",
    "        array_relevant_infos.append(array_vid_relevant_infos)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the dataframe of all the videos that we will consider\n",
    "\n",
    "column_names = ['channel_id', 'view_counts', 'uploaded_year', 'category']\n",
    "\n",
    "df = pd.DataFrame(array_relevant_infos, columns=column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21714294, 4)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove all the videos that are used for topic modelling\n",
    "\n",
    "Find the video indices in the dataframe such that:\n",
    "- more than 100'000 subscribers\n",
    "- top20 from category/channel/year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channel_id</th>\n",
       "      <th>view_counts</th>\n",
       "      <th>uploaded_year</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21326653</th>\n",
       "      <td>UC0C-w0YjGpqDXGB8IHb662A</td>\n",
       "      <td>4468090305</td>\n",
       "      <td>2017</td>\n",
       "      <td>Music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10648298</th>\n",
       "      <td>UCVp3nfGRxmMadNDuVbJSk8A</td>\n",
       "      <td>4295905423</td>\n",
       "      <td>2015</td>\n",
       "      <td>Music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7977749</th>\n",
       "      <td>UCcdwLMPsaU2ezNSJU1nFoBQ</td>\n",
       "      <td>3838039119</td>\n",
       "      <td>2016</td>\n",
       "      <td>Education</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4655616</th>\n",
       "      <td>UCmfFGTSsfJVu6CGvL8r75qg</td>\n",
       "      <td>3709532958</td>\n",
       "      <td>2014</td>\n",
       "      <td>Music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13575776</th>\n",
       "      <td>UCN1hnUccO4FD5WfM7ithXaw</td>\n",
       "      <td>3055180938</td>\n",
       "      <td>2015</td>\n",
       "      <td>Music</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        channel_id  view_counts uploaded_year   category\n",
       "21326653  UC0C-w0YjGpqDXGB8IHb662A   4468090305          2017      Music\n",
       "10648298  UCVp3nfGRxmMadNDuVbJSk8A   4295905423          2015      Music\n",
       "7977749   UCcdwLMPsaU2ezNSJU1nFoBQ   3838039119          2016  Education\n",
       "4655616   UCmfFGTSsfJVu6CGvL8r75qg   3709532958          2014      Music\n",
       "13575776  UCN1hnUccO4FD5WfM7ithXaw   3055180938          2015      Music"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sub100000 = df[df['channel_id'].isin(set_channelcrawler_100000sub)]\n",
    "df_top20 = df_sub100000.sort_values(['view_counts'], ascending=False).groupby(['category', 'uploaded_year', 'channel_id']).head(20)\n",
    "df_top20.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_remove = set(df_top20.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_vid_to_consider_classifier = []\n",
    "\n",
    "for index in df.index:\n",
    "    if index not in index_to_remove:\n",
    "        idx_vid_to_consider_classifier.append(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'index_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-9144e96a72fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'index_data' is not defined"
     ]
    }
   ],
   "source": [
    "len(index_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/dlabdata1/youtube_large/olam/data/classifier/idx_vid_to_consider_classifier.pickle', 'wb') as f:\n",
    "    pickle.dump(idx_vid_to_consider_classifier, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process the data\n",
    "\n",
    "- Transform every video into BoW, according to the topic model vocabulary\n",
    "- Get the transformed data -> distribution over the topic for each video\n",
    "- Separate into train set and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isEnglishAlpha(s):\n",
    "    try:\n",
    "        s.encode(encoding='utf-8').decode('ascii')\n",
    "    except UnicodeDecodeError:\n",
    "        return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_freq_tokens_per_video(video):\n",
    "    ''''''\n",
    "    \n",
    "    title_tokens = [w for w in tokenizer.tokenize(video['title'].lower()) if not w in stop_words]\n",
    "    tag_tokens = [w for w in tokenizer.tokenize(video['tags'].lower()) if not w in stop_words]\n",
    "    \n",
    "    # We want to keep duplicates !!\n",
    "    tokens_per_video = title_tokens + tag_tokens\n",
    "\n",
    "    # Filter token with length < 3, with non english alphabet since fastext is not 100% accurate and remove numerical token \n",
    "    tokens_keep = []\n",
    "    for token in tokens_per_video:\n",
    "        if len(token) >= 3 and (not token.isnumeric()) and isEnglishAlpha(token):\n",
    "            tokens_keep.append(token)\n",
    "    \n",
    "    \n",
    "    # Stemming\n",
    "    stemmed_tokens_per_video = ([s_stemmer.stem(w) for w in tokens_keep])\n",
    "    \n",
    "    \n",
    "    # Return a Counter object of the tokens\n",
    "    return collections.Counter(tokens_keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_underlying_dict(freq_tokens_per_video, dict_stemmed_tokens, i_vid):\n",
    "    '''Method to fill the underlying dictionnary in order to \n",
    "    update the sparse matrix incrementally by videos'''\n",
    "    \n",
    "    dict_freq_tokens_for_sparse_matrix = {}\n",
    "    \n",
    "    for key in freq_tokens_per_video.keys():\n",
    "        \n",
    "        # Column index in the sparse matrix (one column for each token)\n",
    "        try:\n",
    "            j_token = dict_stemmed_tokens[key]\n",
    "            \n",
    "            # Filling the underlying dict\n",
    "            dict_freq_tokens_for_sparse_matrix[(i_vid % 1000000, j_token)] = freq_tokens_per_video[key]\n",
    "            \n",
    "        except KeyError:\n",
    "            None\n",
    "    \n",
    "    return dict_freq_tokens_for_sparse_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_zero_rows(M):\n",
    "    '''Function that removes all rows from sparse matrix M that contains only zero.'''\n",
    "    num_nonzeros = np.diff(M.indptr)\n",
    "    return M[num_nonzeros != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dictionnary of words\n",
    "with open('/dlabdata1/youtube_large/olam/data/view10000_sub100000/id2word_tok100vid_sub100000.pickle', 'rb') as f:\n",
    "    id2word = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "# Load index of data for classifier\n",
    "with open('/dlabdata1/youtube_large/olam/data/classifier/idx_vid_to_consider_classifier.pickle', 'rb') as f:\n",
    "    idx_vid_to_consider_classifier = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2id = {v: k for k, v in id2word.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_vid_to_consider_sorted = list(idx_vid_to_consider)\n",
    "idx_vid_to_consider_sorted.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_data = set([idx_vid_to_consider_sorted[i] for i in idx_vid_to_consider_classifier])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/dlabdata1/youtube_large/olam/data/classifier/index_data.pickle', 'wb') as f:\n",
    "    pickle.dump(index_data, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = list(id2word.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1000000 videos...\n",
      "Processed 2000000 videos...\n",
      "Processed 3000000 videos...\n",
      "Processed 4000000 videos...\n",
      "Processed 5000000 videos...\n",
      "Processed 6000000 videos...\n",
      "Processed 7000000 videos...\n",
      "Processed 8000000 videos...\n",
      "Processed 9000000 videos...\n",
      "Processed 10000000 videos...\n",
      "Processed 11000000 videos...\n",
      "Processed 12000000 videos...\n",
      "Processed 13000000 videos...\n",
      "Processed 14000000 videos...\n",
      "Processed 15000000 videos...\n",
      "Processed 16000000 videos...\n",
      "Processed 17000000 videos...\n",
      "Processed 18000000 videos...\n",
      "Processed 19000000 videos...\n",
      "Processed 20000000 videos...\n",
      "Processed 21000000 videos...\n",
      "Processed 22000000 videos...\n",
      "Processed 23000000 videos...\n",
      "Processed 24000000 videos...\n",
      "Processed 25000000 videos...\n",
      "Processed 26000000 videos...\n",
      "Processed 27000000 videos...\n",
      "Processed 28000000 videos...\n",
      "Processed 29000000 videos...\n",
      "Processed 30000000 videos...\n",
      "Processed 31000000 videos...\n",
      "Processed 32000000 videos...\n",
      "Processed 33000000 videos...\n",
      "Processed 34000000 videos...\n",
      "Processed 35000000 videos...\n",
      "Processed 36000000 videos...\n",
      "Processed 37000000 videos...\n",
      "Processed 38000000 videos...\n",
      "Processed 39000000 videos...\n",
      "Processed 40000000 videos...\n",
      "Processed 41000000 videos...\n",
      "Processed 42000000 videos...\n",
      "Processed 43000000 videos...\n",
      "Processed 44000000 videos...\n",
      "Processed 45000000 videos...\n",
      "Processed 46000000 videos...\n",
      "Processed 47000000 videos...\n",
      "Processed 48000000 videos...\n",
      "Processed 49000000 videos...\n",
      "Processed 50000000 videos...\n",
      "Processed 51000000 videos...\n",
      "Processed 52000000 videos...\n",
      "Processed 53000000 videos...\n",
      "Processed 54000000 videos...\n",
      "Processed 55000000 videos...\n",
      "Processed 56000000 videos...\n",
      "Processed 57000000 videos...\n",
      "Processed 58000000 videos...\n",
      "Processed 59000000 videos...\n",
      "Processed 60000000 videos...\n",
      "Processed 61000000 videos...\n",
      "Processed 62000000 videos...\n",
      "Processed 63000000 videos...\n",
      "Processed 64000000 videos...\n",
      "Processed 65000000 videos...\n",
      "Processed 66000000 videos...\n",
      "Processed 67000000 videos...\n",
      "Processed 68000000 videos...\n",
      "Processed 69000000 videos...\n",
      "Processed 70000000 videos...\n",
      "Processed 71000000 videos...\n",
      "Processed 72000000 videos...\n",
      "Processed 73000000 videos...\n",
      "Processed 74000000 videos...\n",
      "Processed 75000000 videos...\n",
      "Processed 76000000 videos...\n",
      "Processed 77000000 videos...\n",
      "Processed 78000000 videos...\n",
      "Processed 79000000 videos...\n",
      "Processed 80000000 videos...\n",
      "Processed 81000000 videos...\n",
      "Processed 82000000 videos...\n",
      "Processed 83000000 videos...\n",
      "Processed 84000000 videos...\n",
      "Processed 85000000 videos...\n"
     ]
    }
   ],
   "source": [
    "data = dok_matrix((1000000, len(vocab)), dtype=np.uint8)\n",
    "groundtruth = []\n",
    "\n",
    "\n",
    "reader = Zreader(\n",
    "    \"/dlabdata1/youtube_large/yt_metadata_all.jsonl.zst\", chunk_size=2**28)\n",
    "\n",
    "idx = 0\n",
    "i_vid = 0\n",
    "\n",
    "for line in reader.readlines():\n",
    "    ###start_iter = time.time()\n",
    "    idx += 1\n",
    "\n",
    "    if idx % 1000000 == 0:\n",
    "        print('Processed ' + str(idx) + ' videos...')\n",
    "\n",
    "    if i_vid % 1000000 == 0 and i_vid != 0:\n",
    "\n",
    "        file_name = 'data' + str(int(i_vid / 1000000)) + '.npz'\n",
    "        \n",
    "        if not os.path.isfile('/dlabdata1/youtube_large/olam/data/classifier/csr_matrices/' + file_name):\n",
    "            \n",
    "            data = data.tocsr()\n",
    "            scipy.sparse.save_npz(\n",
    "                '/dlabdata1/youtube_large/olam/data/classifier/csr_matrices/' + file_name, data)\n",
    "            data = dok_matrix((1000000, len(vocab)), dtype=np.uint8)\n",
    "\n",
    "    if idx in index_data:\n",
    "\n",
    "        # line is a str dict, video is the dict corresponding to the str dict\n",
    "        video = json.loads(line)\n",
    "\n",
    "        # Get the tokens for each video and theirs number of occurences\n",
    "        freq_tokens_per_video = get_freq_tokens_per_video(video)\n",
    "\n",
    "        # For each video, create a underlying dictionnary for filling the sparse matrix efficiently\n",
    "        dict_freq_tokens_for_sparse_matrix = fill_underlying_dict(\n",
    "            freq_tokens_per_video, word2id, i_vid)\n",
    "\n",
    "        # Need to check that the video contains token from the reduced vocabulary\n",
    "        if dict_freq_tokens_for_sparse_matrix != {}:\n",
    "\n",
    "            # Update the Sparse Matrix\n",
    "            dict.update(data, dict_freq_tokens_for_sparse_matrix)\n",
    "            i_vid += 1\n",
    "\n",
    "            # Get groundtruth values\n",
    "            groundtruth.append(video['categories'])\n",
    "\n",
    "# Save last sparse matrix\n",
    "data = data.tocsr()\n",
    "data = remove_zero_rows(data)\n",
    "scipy.sparse.save_npz(\n",
    "    '/dlabdata1/youtube_large/olam/data/classifier/csr_matrices/data_last.npz', data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get training features for classifier\n",
    "\n",
    "- get full matrix of BoW\n",
    "- process for pyspark\n",
    "- !!! on the cluster, run the model, SAVE the model AND transformed data \n",
    "- transform the data to have k features, which are the distribution over the topics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get full matrix of BoW\n",
    "data = scipy.sparse.load_npz('/dlabdata1/youtube_large/olam/data/classifier/csr_matrices/data1.npz')\n",
    "\n",
    "for i in range(2, 18):\n",
    "    data_next = scipy.sparse.load_npz('/dlabdata1/youtube_large/olam/data/classifier/csr_matrices/data' + str(i) + '.npz')\n",
    "    data = scipy.sparse.vstack([data, data_next])\n",
    "\n",
    "# Add last matrix\n",
    "data_last = scipy.sparse.load_npz('/dlabdata1/youtube_large/olam/data/classifier/csr_matrices/data_last.npz')\n",
    "data = scipy.sparse.vstack([data, data_last])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(groundtruth) == remove_zero_rows(data).shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.sparse.save_npz('/dlabdata1/youtube_large/olam/data/classifier/csr_matrices/data_final.npz', data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dict_for_row(row, S):\n",
    "    '''Construct SparseVector bag-of-word for each row (videos)'''\n",
    "    tmp_dict = {}\n",
    "    for key, value in row:\n",
    "        tmp_dict[key[1]] = value\n",
    "\n",
    "    return SparseVector(S.shape[1], tmp_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process video for topic modelling...\n",
      "0 videos processed...\n",
      "1000000 videos processed...\n",
      "2000000 videos processed...\n",
      "3000000 videos processed...\n",
      "4000000 videos processed...\n",
      "5000000 videos processed...\n",
      "6000000 videos processed...\n",
      "7000000 videos processed...\n",
      "8000000 videos processed...\n",
      "9000000 videos processed...\n",
      "10000000 videos processed...\n",
      "11000000 videos processed...\n",
      "12000000 videos processed...\n",
      "13000000 videos processed...\n",
      "14000000 videos processed...\n",
      "15000000 videos processed...\n",
      "16000000 videos processed...\n",
      "17000000 videos processed...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'spark' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-d9d93085948b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Construct dataframe for LDA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreateDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_spark\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"features\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'spark' is not defined"
     ]
    }
   ],
   "source": [
    "# process for pyspark\n",
    "\n",
    "data_spark = []\n",
    "\n",
    "print('Process video for topic modelling...')\n",
    "for i in range(data.shape[0]):\n",
    "\n",
    "    if i % 1000000 == 0:\n",
    "        print(str(i) + ' videos processed...')\n",
    "\n",
    "    data_spark.append([i, get_dict_for_row(data.getrow(i).todok().items(), data)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = SparkConf().setMaster(\"local[10]\").setAll([('spark.executor.memory', '4g'),('spark.driver.memory','16g'),('spark.driver.maxResultSize', '0')])\n",
    "\n",
    "# create the session\n",
    "spark = SparkSession.builder.config(conf=conf).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct dataframe for LDA\n",
    "df = spark.createDataFrame(data_spark, [\"id\", \"features\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-d9c13aac1e9d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Save the spark dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#save the dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0;34m.\u001b[0m\u001b[0moption\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'compression'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'gzip'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/dlabdata1/youtube_large/olam/data/classifier/sparkdf_data.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pyspark/sql/readwriter.py\u001b[0m in \u001b[0;36mjson\u001b[0;34m(self, path, mode, compression, dateFormat, timestampFormat, lineSep, encoding, ignoreNullFields)\u001b[0m\n\u001b[1;32m    907\u001b[0m             \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdateFormat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdateFormat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimestampFormat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimestampFormat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m             lineSep=lineSep, encoding=encoding, ignoreNullFields=ignoreNullFields)\n\u001b[0;32m--> 909\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jwrite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    910\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0msince\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1301\u001b[0m             \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEND_COMMAND_PART\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1303\u001b[0;31m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1304\u001b[0m         return_value = get_return_value(\n\u001b[1;32m   1305\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1031\u001b[0m         \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1033\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1034\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1035\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_connection_guard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m   1198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1199\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1200\u001b[0;31m             \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmart_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1201\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Answer received: {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1202\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRETURN_MESSAGE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 669\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    670\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Save the spark dataframe\n",
    "#save the dataframe\n",
    "df.write\\\n",
    "        .option('compression', 'gzip')\\\n",
    "        .json('/dlabdata1/youtube_large/olam/data/classifier/sparkdf_data.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-f1624bd1cb93>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Get model and/or transformed data!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLocalLDAModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/dlabdata1/youtube_large/olam/data/classifier/best_model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pyspark/ml/util.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(cls, path)\u001b[0m\n\u001b[1;32m    328\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[0;34m\"\"\"Reads an ML instance from the input path, a shortcut of `read().load(path)`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pyspark/ml/util.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasestring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"path should be a basestring, got type %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m         \u001b[0mjava_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_clazz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_from_java\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m             raise NotImplementedError(\"This Java ML type cannot be loaded into Python currently: %r\"\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1301\u001b[0m             \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEND_COMMAND_PART\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1303\u001b[0;31m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1304\u001b[0m         return_value = get_return_value(\n\u001b[1;32m   1305\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1031\u001b[0m         \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1033\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1034\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1035\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_connection_guard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m   1198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1199\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1200\u001b[0;31m             \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmart_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1201\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Answer received: {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1202\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRETURN_MESSAGE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 669\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    670\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Get model and/or transformed data!\n",
    "\n",
    "model = LocalLDAModel.load('/dlabdata1/youtube_large/olam/data/classifier/best_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the classifier\n",
    "\n",
    "- Train set into train' and validation set, in order to do cross validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
