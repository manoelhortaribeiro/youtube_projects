{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/olam/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import collections\n",
    "import fasttext\n",
    "import json\n",
    "import nltk\n",
    "import pickle\n",
    "import scipy.sparse\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import zstandard as zstd\n",
    "\n",
    "from collections import Counter\n",
    "from langdetect import detect\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from scipy.sparse import dok_matrix\n",
    "\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "s_stemmer = SnowballStemmer(language='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Zreader:\n",
    "\n",
    "    def __init__(self, file, chunk_size=16384):\n",
    "        '''Init method'''\n",
    "        self.fh = open(file,'rb')\n",
    "        self.chunk_size = chunk_size\n",
    "        self.dctx = zstd.ZstdDecompressor()\n",
    "        self.reader = self.dctx.stream_reader(self.fh)\n",
    "        self.buffer = ''\n",
    "\n",
    "\n",
    "    def readlines(self):\n",
    "        '''Generator method that creates an iterator for each line of JSON'''\n",
    "        while True:\n",
    "            chunk = self.reader.read(self.chunk_size).decode(errors=\"ignore\")\n",
    "            if not chunk:\n",
    "                break\n",
    "            lines = (self.buffer + chunk).split(\"\\n\")\n",
    "\n",
    "            for line in lines[:-1]:\n",
    "                yield line\n",
    "\n",
    "            self.buffer = lines[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LanguageIdentification:\n",
    "\n",
    "    def __init__(self):\n",
    "        pretrained_lang_model = \"/home/olam/fasttext/lid.176.bin\"\n",
    "        self.model = fasttext.load_model(pretrained_lang_model)\n",
    "\n",
    "    def predict_lang(self, text):\n",
    "        predictions = self.model.predict(text, k=1) \n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "LANGUAGE = LanguageIdentification()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_language(text):\n",
    "    '''Method that detect the language of the argument using langdetect'''\n",
    "    \n",
    "    \n",
    "    # Create list to store the language detections\n",
    "    #detections = []\n",
    "    \n",
    "    \n",
    "    # TextBlob\n",
    "    #start_detect = time.time()\n",
    "    #blob = TextBlob(text)\n",
    "    #textblob_res = blob.detect_language()\n",
    "    #end_detect = time.time()\n",
    "    #duration_detect = end_detect - start_detect\n",
    "    #print('TextBlob : ' + str(duration_detect))\n",
    "    \n",
    "    # Langedetect\n",
    "    #start_detect = time.time()\n",
    "    #for i in range(5):\n",
    "    #    detections.append(detect(text))\n",
    "    #end_detect = time.time()\n",
    "    #duration_detect = end_detect - start_detect\n",
    "    #print('Langedetect : ' + str(duration_detect))\n",
    "    \n",
    "    # LangID\n",
    "    #start_detect = time.time()\n",
    "    #langid_res = langid.classify(text)[0]\n",
    "    #end_detect = time.time()\n",
    "    #duration_detect = end_detect - start_detect\n",
    "    #print('LangId : ' + str(duration_detect))\n",
    "    \n",
    "    # FastText\n",
    "    #start_detect = time.time()\n",
    "    fastext_res = LANGUAGE.predict_lang(text)[0][0].replace('__label__', '')\n",
    "    #end_detect = time.time()\n",
    "    #duration_detect = end_detect - start_detect\n",
    "    #print('Fastext : ' + str(duration_detect))\n",
    "    \n",
    "    # Create the counter to get the most detected language\n",
    "    #c = Counter(detections)\n",
    "    #language_detected, _ = c.most_common()[0]\n",
    "\n",
    "    \n",
    "    #print('LangId result : ' + langid_res)\n",
    "    #print('FastText result : ' + fastext_res)\n",
    "    \n",
    "    return fastext_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_en_video(vid_title, vid_description):\n",
    "    '''Returns True if the language of the video is english'''\n",
    "    \n",
    "    detected_language = ''\n",
    "    \n",
    "    # First check for description and if there is none, chech for the title.\n",
    "    # Handling exceptions when a text couldn't be used of langdetect\n",
    "    if vid_description != '':\n",
    "        try:\n",
    "            detected_language = detect_language(vid_description)\n",
    "        except:\n",
    "            if vid_title != '':\n",
    "                try:\n",
    "                    detected_language = detect_language(vid_title)\n",
    "                except:\n",
    "                    detected_language = None\n",
    "    elif vid_title != '':\n",
    "        try:\n",
    "            detected_language = detect_language(vid_title)\n",
    "        except:\n",
    "            detected_language = None\n",
    "    else:\n",
    "        detected_language = None\n",
    "        \n",
    "    return detected_language == 'en'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_1000_views(video):\n",
    "    try:\n",
    "        return video['view_count'] >= 10000\n",
    "    except KeyError:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isEnglishAlpha(s):\n",
    "    try:\n",
    "        s.encode(encoding='utf-8').decode('ascii')\n",
    "    except UnicodeDecodeError:\n",
    "        return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_freq_tokens_per_video(video):\n",
    "    ''''''\n",
    "    \n",
    "    title_tokens = [w for w in tokenizer.tokenize(video['title'].lower()) if not w in stop_words]\n",
    "    tag_tokens = [w for w in tokenizer.tokenize(video['tags'].lower()) if not w in stop_words]\n",
    "    \n",
    "    # We want to keep duplicates !!\n",
    "    tokens_per_video = title_tokens + tag_tokens\n",
    "\n",
    "    # Filter token with length < 3, with non english alphabet since fastext is not 100% accurate and remove numerical token \n",
    "    tokens_keep = []\n",
    "    for token in tokens_per_video:\n",
    "        if len(token) >= 3 and (not token.isnumeric()) and isEnglishAlpha(token):\n",
    "            tokens_keep.append(token)\n",
    "    \n",
    "    \n",
    "    # Stemming\n",
    "    stemmed_tokens_per_video = ([s_stemmer.stem(w) for w in tokens_keep])\n",
    "    \n",
    "    \n",
    "    # Return a Counter object of the tokens\n",
    "    return collections.Counter(tokens_keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_underlying_dict(freq_tokens_per_video, dict_stemmed_tokens, dict_freq_tokens_for_sparse_matrix, i_vid):\n",
    "    '''Method to fill the underlying dictionnary in order to \n",
    "    update the sparse matrix incrementally by videos'''\n",
    "    \n",
    "    for key in freq_tokens_per_video.keys():\n",
    "        \n",
    "        # Column index in the sparse matrix (one column for each token)\n",
    "        j_token = dict_stemmed_tokens[key]\n",
    "    \n",
    "        # Filling the underlying dict\n",
    "        dict_freq_tokens_for_sparse_matrix[(i_vid % 1000000, j_token)] = freq_tokens_per_video[key]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### GET THE LIST OF CHANNELS IN channelcrawler.csv\n",
    "\n",
    "df_channelcrawler = pd.read_csv('/dlabdata1/youtube_large/channelcrawler.csv')\n",
    "\n",
    "df_channelcrawler['channel_id'] = df_channelcrawler['link'].apply(lambda x: x.replace('http://www.youtube.com/channel/', ''))\n",
    "\n",
    "# Store in a set since it will be faster to check if a channel is in channelcrawler\n",
    "set_channelcrawler = set(df_channelcrawler['channel_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "164648"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set_channelcrawler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the set of channels that contains only 1 video\n",
    "with open('/dlabdata1/youtube_large/olam/channels_with_1_vid.pickle', 'rb') as f:\n",
    "    channels_with_1_vid = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A) First pass to build dict of tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Zreader(\"/dlabdata1/youtube_large/yt_metadata_all.jsonl.zst\", chunk_size=2**28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1000000 videos.\n",
      "Processed 2000000 videos.\n",
      "Processed 3000000 videos.\n",
      "Processed 4000000 videos.\n",
      "Processed 5000000 videos.\n",
      "Processed 6000000 videos.\n",
      "Processed 7000000 videos.\n",
      "Processed 8000000 videos.\n",
      "Processed 9000000 videos.\n",
      "Processed 10000000 videos.\n",
      "Processed 11000000 videos.\n",
      "Processed 12000000 videos.\n",
      "Processed 13000000 videos.\n",
      "Processed 14000000 videos.\n",
      "Processed 15000000 videos.\n",
      "Processed 16000000 videos.\n",
      "Processed 17000000 videos.\n",
      "Processed 18000000 videos.\n",
      "Processed 19000000 videos.\n",
      "Processed 20000000 videos.\n",
      "Processed 21000000 videos.\n",
      "Processed 22000000 videos.\n",
      "Processed 23000000 videos.\n",
      "Processed 24000000 videos.\n",
      "Processed 25000000 videos.\n",
      "Processed 26000000 videos.\n",
      "Processed 27000000 videos.\n",
      "Processed 28000000 videos.\n",
      "Processed 29000000 videos.\n",
      "Processed 30000000 videos.\n",
      "Processed 31000000 videos.\n",
      "Processed 32000000 videos.\n",
      "Processed 33000000 videos.\n",
      "Processed 34000000 videos.\n",
      "Processed 35000000 videos.\n",
      "Processed 36000000 videos.\n",
      "Processed 37000000 videos.\n",
      "Processed 38000000 videos.\n",
      "Processed 39000000 videos.\n",
      "Processed 40000000 videos.\n",
      "Processed 41000000 videos.\n",
      "Processed 42000000 videos.\n",
      "Processed 43000000 videos.\n",
      "Processed 44000000 videos.\n",
      "Processed 45000000 videos.\n",
      "Processed 46000000 videos.\n",
      "Processed 47000000 videos.\n",
      "Processed 48000000 videos.\n",
      "Processed 49000000 videos.\n",
      "Processed 50000000 videos.\n",
      "Processed 51000000 videos.\n",
      "Processed 52000000 videos.\n",
      "Processed 53000000 videos.\n",
      "Processed 54000000 videos.\n",
      "Processed 55000000 videos.\n",
      "Processed 56000000 videos.\n",
      "Processed 57000000 videos.\n",
      "Processed 58000000 videos.\n",
      "Processed 59000000 videos.\n",
      "Processed 60000000 videos.\n",
      "Processed 61000000 videos.\n",
      "Processed 62000000 videos.\n",
      "Processed 63000000 videos.\n",
      "Processed 64000000 videos.\n",
      "Processed 65000000 videos.\n",
      "Processed 66000000 videos.\n",
      "Processed 67000000 videos.\n",
      "Processed 68000000 videos.\n",
      "Processed 70000000 videos.\n",
      "Processed 71000000 videos.\n",
      "Processed 72000000 videos.\n",
      "Processed 73000000 videos.\n",
      "Processed 74000000 videos.\n",
      "Processed 75000000 videos.\n",
      "Processed 76000000 videos.\n",
      "Processed 77000000 videos.\n",
      "Processed 78000000 videos.\n",
      "Processed 79000000 videos.\n",
      "Processed 80000000 videos.\n",
      "Processed 81000000 videos.\n",
      "Processed 82000000 videos.\n",
      "Processed 83000000 videos.\n",
      "Processed 84000000 videos.\n",
      "Processed 85000000 videos.\n"
     ]
    }
   ],
   "source": [
    "idx = 0\n",
    "\n",
    "# Variable that contains the idx of every non english vid and that\n",
    "# belongs to a channel in channelcrawler.csv TO BE USED IN SECOND ITER\n",
    "idx_vid_to_consider = set()\n",
    "\n",
    "# Variable first instanciated as set to check existing tokens efficiently, \n",
    "# which will be a list in order to get the index for each tokens\n",
    "list_stemmed_tokens = set()\n",
    "\n",
    "for line in reader.readlines():\n",
    "    #start_iter = time.time()\n",
    "    idx += 1\n",
    "    \n",
    "    if idx % 1000000 == 0:\n",
    "        print('Processed ' + str(idx) + ' videos.')\n",
    "    \n",
    "        \n",
    "    # line is a str dict, video is the dict corresponding to the str dict\n",
    "    video = json.loads(line)\n",
    "    \n",
    "    if video['channel_id'] in set_channelcrawler \\\n",
    "            and video['channel_id'] not in channels_with_1_vid\\\n",
    "            and check_en_video(video['title'], video['description'])\\\n",
    "            and check_1000_views(video):\n",
    "        \n",
    "        # Keep idx of video in memory\n",
    "        idx_vid_to_consider.add(idx)\n",
    "        \n",
    "        # Get the stemmed token of the video\n",
    "        tokens_per_video = get_freq_tokens_per_video(video).keys()\n",
    "        \n",
    "        # Update list_stemmed_tokens\n",
    "        list_stemmed_tokens.update(tokens_per_video)\n",
    "    #end_iter = time.time()\n",
    "    #duration_iter = end_iter - start_iter\n",
    "    #print('Time for 1 iteration : ' + str(duration_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_stemmed_tokens = list(list_stemmed_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3538761"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_stemmed_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21714294"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(idx_vid_to_consider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/dlabdata1/youtube_large/olam/filtered10000/idx_vid_to_consider.pickle', 'wb') as f:\n",
    "    pickle.dump(idx_vid_to_consider, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/dlabdata1/youtube_large/olam/filtered10000/list_stemmed_tokens.pickle', 'wb') as f:\n",
    "    pickle.dump(list_stemmed_tokens, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B) Second pass to build the sparse matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load set of videos to consider\n",
    "with open('/dlabdata1/youtube_large/olam/filtered/idx_vid_to_consider.pickle', 'rb') as f:\n",
    "    idx_vid_to_consider = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dictionnary of tokens\n",
    "with open('/dlabdata1/youtube_large/olam/filtered/list_stemmed_tokens.pickle', 'rb') as f:\n",
    "    list_stemmed_tokens = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of videos to consider : 21714294\n"
     ]
    }
   ],
   "source": [
    "print('Number of videos to consider : ' + str(len(idx_vid_to_consider)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens : 3538761\n"
     ]
    }
   ],
   "source": [
    "print('Number of tokens : ' + str(len(list_stemmed_tokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dimension of sparse matrix\n",
    "size_of_tokens_dict = len(list_stemmed_tokens)\n",
    "number_of_vid = len(idx_vid_to_consider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionnary of tokens with their indice\n",
    "dict_stemmed_tokens = {}\n",
    "\n",
    "# Fill dictionnary of tokens\n",
    "for i, token in enumerate(list_stemmed_tokens):\n",
    "    dict_stemmed_tokens[token] = i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test code on sparse matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows = 1000\n",
    "ncolumns = 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "S_1 = dok_matrix((nrows, ncolumns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "S_2 = dok_matrix((nrows, ncolumns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "S_1i = dok_matrix((nrows, ncolumns), dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "S_2i = dok_matrix((nrows, ncolumns), dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5000):\n",
    "    x = random.randint(0, 999)\n",
    "    y = random.randint(0, 99999)\n",
    "    \n",
    "    v = random.randint(0, 20)\n",
    "    \n",
    "    S_1[x, y] = v\n",
    "    S_1i[x, y] = v\n",
    "    \n",
    "for i in range(10000):\n",
    "    x = random.randint(0, 999)\n",
    "    y = random.randint(0, 99999)\n",
    "    \n",
    "    v = random.randint(0, 20)\n",
    "    \n",
    "    S_2[x, y] = v\n",
    "    S_2i[x, y] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1000x100000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 4748 stored elements in Dictionary Of Keys format>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1000x100000 sparse matrix of type '<class 'numpy.uint8'>'\n",
       "\twith 4748 stored elements in Dictionary Of Keys format>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S_1i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1000x100000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 9522 stored elements in Dictionary Of Keys format>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1000x100000 sparse matrix of type '<class 'numpy.uint8'>'\n",
       "\twith 9522 stored elements in Dictionary Of Keys format>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S_2i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4748\n"
     ]
    }
   ],
   "source": [
    "print(S_1.count_nonzero())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "147584"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.getsizeof(S_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "147584"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.getsizeof(S_1i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "295032"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.getsizeof(S_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "295032"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.getsizeof(S_2i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "S_1_csr = S_1.tocsr()\n",
    "S_1i_csr = S_1i.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1000x100000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 4748 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S_1_csr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4748\n"
     ]
    }
   ],
   "source": [
    "print((S_1.tocsr()).count_nonzero())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4748\n"
     ]
    }
   ],
   "source": [
    "print(S_1_csr.count_nonzero())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1000x100000 sparse matrix of type '<class 'numpy.uint8'>'\n",
       "\twith 4751 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S_1i_csr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.getsizeof(S_1_csr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.getsizeof(S_1i_csr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "S_test = dok_matrix((20,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "S1 = dok_matrix((10,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "S2 = dok_matrix((10,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(20):\n",
    "    for j in range(10):\n",
    "        \n",
    "        value = random.randint(0, 20)\n",
    "        \n",
    "        S_test[i, j] = value\n",
    "        \n",
    "        if i < 10:\n",
    "            S1[i, j] = value\n",
    "        else:\n",
    "            S2[i - 10, j] = value\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 5.,  7.,  6., 15., 14.,  5., 16.,  9., 20.,  1.],\n",
       "        [ 7.,  8.,  3.,  3.,  3., 17., 14., 20., 20.,  7.],\n",
       "        [ 8.,  5., 15.,  3., 10., 13.,  9., 14., 17., 12.],\n",
       "        [ 7., 16.,  7., 18.,  8.,  3.,  8., 20.,  9., 17.],\n",
       "        [ 5.,  0., 12.,  9., 15., 10.,  3., 10., 17.,  5.],\n",
       "        [19.,  7.,  3.,  0., 15., 13.,  1.,  9.,  5.,  7.],\n",
       "        [ 3., 12.,  5.,  6.,  9.,  4.,  5.,  6.,  2., 18.],\n",
       "        [16.,  0.,  9.,  4., 15.,  4., 10., 12.,  1.,  9.],\n",
       "        [14., 14., 18.,  0., 15.,  4.,  8.,  9., 18.,  0.],\n",
       "        [ 8.,  5., 11.,  5., 14., 11., 14., 13., 20., 11.],\n",
       "        [14., 10., 19.,  9., 17., 17., 11., 14., 10.,  8.],\n",
       "        [ 9.,  9.,  3., 20., 17.,  6., 15., 17., 16., 11.],\n",
       "        [ 6., 17., 19.,  2.,  8., 17.,  5.,  8.,  8.,  3.],\n",
       "        [ 6.,  1.,  8., 11.,  7., 15., 10.,  4.,  3., 14.],\n",
       "        [17., 18., 17.,  5., 19.,  8., 11.,  4., 11.,  8.],\n",
       "        [17.,  6., 14., 11.,  8., 18., 11.,  6.,  0.,  7.],\n",
       "        [13., 18., 20., 10., 17.,  7.,  3.,  3.,  6., 10.],\n",
       "        [19.,  6.,  2., 18., 14., 16., 15., 14., 20., 12.],\n",
       "        [ 4., 18.,  9.,  7.,  0., 14.,  7., 11.,  5., 19.],\n",
       "        [ 8.,  6., 15.,  4., 17., 16., 19., 20.,  8.,  2.]])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S_test.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 5.,  7.,  6., 15., 14.,  5., 16.,  9., 20.,  1.],\n",
       "        [ 7.,  8.,  3.,  3.,  3., 17., 14., 20., 20.,  7.],\n",
       "        [ 8.,  5., 15.,  3., 10., 13.,  9., 14., 17., 12.],\n",
       "        [ 7., 16.,  7., 18.,  8.,  3.,  8., 20.,  9., 17.],\n",
       "        [ 5.,  0., 12.,  9., 15., 10.,  3., 10., 17.,  5.],\n",
       "        [19.,  7.,  3.,  0., 15., 13.,  1.,  9.,  5.,  7.],\n",
       "        [ 3., 12.,  5.,  6.,  9.,  4.,  5.,  6.,  2., 18.],\n",
       "        [16.,  0.,  9.,  4., 15.,  4., 10., 12.,  1.,  9.],\n",
       "        [14., 14., 18.,  0., 15.,  4.,  8.,  9., 18.,  0.],\n",
       "        [ 8.,  5., 11.,  5., 14., 11., 14., 13., 20., 11.]])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S1.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[14., 10., 19.,  9., 17., 17., 11., 14., 10.,  8.],\n",
       "        [ 9.,  9.,  3., 20., 17.,  6., 15., 17., 16., 11.],\n",
       "        [ 6., 17., 19.,  2.,  8., 17.,  5.,  8.,  8.,  3.],\n",
       "        [ 6.,  1.,  8., 11.,  7., 15., 10.,  4.,  3., 14.],\n",
       "        [17., 18., 17.,  5., 19.,  8., 11.,  4., 11.,  8.],\n",
       "        [17.,  6., 14., 11.,  8., 18., 11.,  6.,  0.,  7.],\n",
       "        [13., 18., 20., 10., 17.,  7.,  3.,  3.,  6., 10.],\n",
       "        [19.,  6.,  2., 18., 14., 16., 15., 14., 20., 12.],\n",
       "        [ 4., 18.,  9.,  7.,  0., 14.,  7., 11.,  5., 19.],\n",
       "        [ 8.,  6., 15.,  4., 17., 16., 19., 20.,  8.,  2.]])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S2.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "S_testcsr = S_test.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9344"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.getsizeof(S_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.getsizeof(S_testcsr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 5.,  7.,  6., 15., 14.,  5., 16.,  9., 20.,  1.],\n",
       "        [ 7.,  8.,  3.,  3.,  3., 17., 14., 20., 20.,  7.],\n",
       "        [ 8.,  5., 15.,  3., 10., 13.,  9., 14., 17., 12.],\n",
       "        [ 7., 16.,  7., 18.,  8.,  3.,  8., 20.,  9., 17.],\n",
       "        [ 5.,  0., 12.,  9., 15., 10.,  3., 10., 17.,  5.],\n",
       "        [19.,  7.,  3.,  0., 15., 13.,  1.,  9.,  5.,  7.],\n",
       "        [ 3., 12.,  5.,  6.,  9.,  4.,  5.,  6.,  2., 18.],\n",
       "        [16.,  0.,  9.,  4., 15.,  4., 10., 12.,  1.,  9.],\n",
       "        [14., 14., 18.,  0., 15.,  4.,  8.,  9., 18.,  0.],\n",
       "        [ 8.,  5., 11.,  5., 14., 11., 14., 13., 20., 11.],\n",
       "        [14., 10., 19.,  9., 17., 17., 11., 14., 10.,  8.],\n",
       "        [ 9.,  9.,  3., 20., 17.,  6., 15., 17., 16., 11.],\n",
       "        [ 6., 17., 19.,  2.,  8., 17.,  5.,  8.,  8.,  3.],\n",
       "        [ 6.,  1.,  8., 11.,  7., 15., 10.,  4.,  3., 14.],\n",
       "        [17., 18., 17.,  5., 19.,  8., 11.,  4., 11.,  8.],\n",
       "        [17.,  6., 14., 11.,  8., 18., 11.,  6.,  0.,  7.],\n",
       "        [13., 18., 20., 10., 17.,  7.,  3.,  3.,  6., 10.],\n",
       "        [19.,  6.,  2., 18., 14., 16., 15., 14., 20., 12.],\n",
       "        [ 4., 18.,  9.,  7.,  0., 14.,  7., 11.,  5., 19.],\n",
       "        [ 8.,  6., 15.,  4., 17., 16., 19., 20.,  8.,  2.]])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S_testcsr.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<20x10 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 193 stored elements in COOrdinate format>"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S_stacked = scipy.sparse.vstack([S1, S2])\n",
    "S_stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 5.,  7.,  6., 15., 14.,  5., 16.,  9., 20.,  1.],\n",
       "        [ 7.,  8.,  3.,  3.,  3., 17., 14., 20., 20.,  7.],\n",
       "        [ 8.,  5., 15.,  3., 10., 13.,  9., 14., 17., 12.],\n",
       "        [ 7., 16.,  7., 18.,  8.,  3.,  8., 20.,  9., 17.],\n",
       "        [ 5.,  0., 12.,  9., 15., 10.,  3., 10., 17.,  5.],\n",
       "        [19.,  7.,  3.,  0., 15., 13.,  1.,  9.,  5.,  7.],\n",
       "        [ 3., 12.,  5.,  6.,  9.,  4.,  5.,  6.,  2., 18.],\n",
       "        [16.,  0.,  9.,  4., 15.,  4., 10., 12.,  1.,  9.],\n",
       "        [14., 14., 18.,  0., 15.,  4.,  8.,  9., 18.,  0.],\n",
       "        [ 8.,  5., 11.,  5., 14., 11., 14., 13., 20., 11.],\n",
       "        [14., 10., 19.,  9., 17., 17., 11., 14., 10.,  8.],\n",
       "        [ 9.,  9.,  3., 20., 17.,  6., 15., 17., 16., 11.],\n",
       "        [ 6., 17., 19.,  2.,  8., 17.,  5.,  8.,  8.,  3.],\n",
       "        [ 6.,  1.,  8., 11.,  7., 15., 10.,  4.,  3., 14.],\n",
       "        [17., 18., 17.,  5., 19.,  8., 11.,  4., 11.,  8.],\n",
       "        [17.,  6., 14., 11.,  8., 18., 11.,  6.,  0.,  7.],\n",
       "        [13., 18., 20., 10., 17.,  7.,  3.,  3.,  6., 10.],\n",
       "        [19.,  6.,  2., 18., 14., 16., 15., 14., 20., 12.],\n",
       "        [ 4., 18.,  9.,  7.,  0., 14.,  7., 11.,  5., 19.],\n",
       "        [ 8.,  6., 15.,  4., 17., 16., 19., 20.,  8.,  2.]])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S_stacked.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.sparse.save_npz('/home/olam/csr_matrices/test.npz', S_stacked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "S_loaded = scipy.sparse.load_npz('/home/olam/csr_matrices/test.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.getsizeof(S_loaded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sparse matrix\n",
    "S = dok_matrix((1000000, size_of_tokens_dict), dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Zreader(\"/dlabdata1/youtube_large/yt_metadata_all.jsonl.zst\", chunk_size=2**28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of matrix dok: 335544424\n",
      "Shape of S : (1000000, 3538761) and number of elems : 6021786\n",
      "Size of matrix csr: 48\n",
      "Shape of S : (1000000, 3538761) and number of elems : 0\n",
      "Processed 1000000 videos.\n",
      "\n",
      "Size of matrix dok: 167772272\n",
      "Shape of S : (1000000, 3538761) and number of elems : 4887475\n",
      "Size of matrix csr: 48\n",
      "Shape of S : (1000000, 3538761) and number of elems : 0\n",
      "Processed 2000000 videos.\n",
      "\n",
      "Size of matrix dok: 335544424\n",
      "Shape of S : (1000000, 3538761) and number of elems : 6080916\n",
      "Size of matrix csr: 48\n",
      "Shape of S : (1000000, 3538761) and number of elems : 0\n",
      "Processed 3000000 videos.\n",
      "\n",
      "Size of matrix dok: 167772272\n",
      "Shape of S : (1000000, 3538761) and number of elems : 4916670\n",
      "Size of matrix csr: 48\n",
      "Shape of S : (1000000, 3538761) and number of elems : 0\n",
      "Processed 4000000 videos.\n",
      "\n",
      "Size of matrix dok: 167772272\n",
      "Shape of S : (1000000, 3538761) and number of elems : 5490427\n",
      "Size of matrix csr: 48\n",
      "Shape of S : (1000000, 3538761) and number of elems : 0\n",
      "Processed 5000000 videos.\n",
      "\n",
      "Size of matrix dok: 335544424\n",
      "Shape of S : (1000000, 3538761) and number of elems : 6371825\n",
      "Size of matrix csr: 48\n",
      "Shape of S : (1000000, 3538761) and number of elems : 0\n",
      "Processed 6000000 videos.\n",
      "\n",
      "Size of matrix dok: 167772272\n",
      "Shape of S : (1000000, 3538761) and number of elems : 4905592\n",
      "Size of matrix csr: 48\n",
      "Shape of S : (1000000, 3538761) and number of elems : 0\n",
      "Processed 7000000 videos.\n",
      "\n",
      "Size of matrix dok: 335544424\n",
      "Shape of S : (1000000, 3538761) and number of elems : 5993298\n",
      "Size of matrix csr: 48\n",
      "Shape of S : (1000000, 3538761) and number of elems : 0\n",
      "Processed 8000000 videos.\n",
      "\n",
      "Size of matrix dok: 167772272\n",
      "Shape of S : (1000000, 3538761) and number of elems : 5157020\n",
      "Size of matrix csr: 48\n",
      "Shape of S : (1000000, 3538761) and number of elems : 0\n",
      "Processed 9000000 videos.\n",
      "\n",
      "Size of matrix dok: 335544424\n",
      "Shape of S : (1000000, 3538761) and number of elems : 6428877\n",
      "Size of matrix csr: 48\n",
      "Shape of S : (1000000, 3538761) and number of elems : 0\n",
      "Processed 10000000 videos.\n",
      "\n",
      "Size of matrix dok: 167772272\n",
      "Shape of S : (1000000, 3538761) and number of elems : 4836588\n",
      "Size of matrix csr: 48\n",
      "Shape of S : (1000000, 3538761) and number of elems : 0\n",
      "Processed 11000000 videos.\n",
      "\n",
      "Size of matrix dok: 167772272\n",
      "Shape of S : (1000000, 3538761) and number of elems : 4372337\n",
      "Size of matrix csr: 48\n",
      "Shape of S : (1000000, 3538761) and number of elems : 0\n",
      "Processed 12000000 videos.\n",
      "\n",
      "Size of matrix dok: 335544424\n",
      "Shape of S : (1000000, 3538761) and number of elems : 5669130\n",
      "Size of matrix csr: 48\n",
      "Shape of S : (1000000, 3538761) and number of elems : 0\n",
      "Processed 13000000 videos.\n",
      "\n",
      "Size of matrix dok: 335544424\n",
      "Shape of S : (1000000, 3538761) and number of elems : 5824943\n",
      "Size of matrix csr: 48\n",
      "Shape of S : (1000000, 3538761) and number of elems : 0\n",
      "Processed 14000000 videos.\n",
      "\n",
      "Size of matrix dok: 335544424\n",
      "Shape of S : (1000000, 3538761) and number of elems : 6655798\n",
      "Size of matrix csr: 48\n",
      "Shape of S : (1000000, 3538761) and number of elems : 0\n",
      "Processed 15000000 videos.\n",
      "\n",
      "Size of matrix dok: 167772272\n",
      "Shape of S : (1000000, 3538761) and number of elems : 5399201\n",
      "Size of matrix csr: 48\n",
      "Shape of S : (1000000, 3538761) and number of elems : 0\n",
      "Processed 16000000 videos.\n",
      "\n",
      "Size of matrix dok: 335544424\n",
      "Shape of S : (1000000, 3538761) and number of elems : 5724703\n",
      "Size of matrix csr: 48\n",
      "Shape of S : (1000000, 3538761) and number of elems : 0\n",
      "Processed 17000000 videos.\n",
      "\n",
      "Size of matrix dok: 167772272\n",
      "Shape of S : (1000000, 3538761) and number of elems : 5342357\n",
      "Size of matrix csr: 48\n",
      "Shape of S : (1000000, 3538761) and number of elems : 0\n",
      "Processed 18000000 videos.\n",
      "\n",
      "Size of matrix dok: 167772272\n",
      "Shape of S : (1000000, 3538761) and number of elems : 5420467\n",
      "Size of matrix csr: 48\n",
      "Shape of S : (1000000, 3538761) and number of elems : 0\n",
      "Processed 19000000 videos.\n",
      "\n",
      "Size of matrix dok: 167772272\n",
      "Shape of S : (1000000, 3538761) and number of elems : 5014937\n",
      "Size of matrix csr: 48\n",
      "Shape of S : (1000000, 3538761) and number of elems : 0\n",
      "Processed 20000000 videos.\n",
      "\n",
      "Size of matrix dok: 335544424\n",
      "Shape of S : (1000000, 3538761) and number of elems : 5647924\n",
      "Size of matrix csr: 48\n",
      "Shape of S : (1000000, 3538761) and number of elems : 0\n",
      "Processed 21000000 videos.\n",
      "\n",
      "Size of matrix dok: 167772272\n",
      "Shape of S : (1000000, 3538761) and number of elems : 5552893\n",
      "Size of matrix csr: 48\n",
      "Shape of S : (1000000, 3538761) and number of elems : 0\n",
      "Processed 22000000 videos.\n",
      "\n",
      "Size of matrix dok: 167772272\n",
      "Shape of S : (1000000, 3538761) and number of elems : 5381138\n",
      "Size of matrix csr: 48\n",
      "Shape of S : (1000000, 3538761) and number of elems : 0\n",
      "Processed 23000000 videos.\n",
      "\n",
      "Size of matrix dok: 335544424\n",
      "Shape of S : (1000000, 3538761) and number of elems : 5696090\n",
      "Size of matrix csr: 48\n",
      "Shape of S : (1000000, 3538761) and number of elems : 0\n",
      "Processed 24000000 videos.\n",
      "\n",
      "Size of matrix dok: 167772272\n",
      "Shape of S : (1000000, 3538761) and number of elems : 4998340\n",
      "Size of matrix csr: 48\n",
      "Shape of S : (1000000, 3538761) and number of elems : 0\n",
      "Processed 25000000 videos.\n",
      "\n",
      "Size of matrix dok: 167772272\n",
      "Shape of S : (1000000, 3538761) and number of elems : 5393942\n",
      "Size of matrix csr: 48\n",
      "Shape of S : (1000000, 3538761) and number of elems : 0\n",
      "Processed 26000000 videos.\n",
      "\n",
      "Size of matrix dok: 167772272\n",
      "Shape of S : (1000000, 3538761) and number of elems : 5492187\n",
      "Size of matrix csr: 48\n",
      "Shape of S : (1000000, 3538761) and number of elems : 0\n",
      "Processed 27000000 videos.\n",
      "\n",
      "Size of matrix dok: 167772272\n",
      "Shape of S : (1000000, 3538761) and number of elems : 5198605\n",
      "Size of matrix csr: 48\n",
      "Shape of S : (1000000, 3538761) and number of elems : 0\n",
      "Processed 28000000 videos.\n",
      "\n",
      "Size of matrix dok: 167772272\n",
      "Shape of S : (1000000, 3538761) and number of elems : 5383879\n",
      "Size of matrix csr: 48\n",
      "Shape of S : (1000000, 3538761) and number of elems : 0\n",
      "Processed 29000000 videos.\n",
      "\n",
      "Size of matrix dok: 167772272\n",
      "Shape of S : (1000000, 3538761) and number of elems : 5576256\n",
      "Size of matrix csr: 48\n",
      "Shape of S : (1000000, 3538761) and number of elems : 0\n",
      "Processed 30000000 videos.\n",
      "\n",
      "Size of matrix dok: 167772272\n",
      "Shape of S : (1000000, 3538761) and number of elems : 5330704\n",
      "Size of matrix csr: 48\n",
      "Shape of S : (1000000, 3538761) and number of elems : 0\n",
      "Processed 31000000 videos.\n",
      "\n",
      "Size of matrix dok: 167772272\n",
      "Shape of S : (1000000, 3538761) and number of elems : 5117182\n",
      "Size of matrix csr: 48\n",
      "Shape of S : (1000000, 3538761) and number of elems : 0\n",
      "Processed 32000000 videos.\n",
      "\n",
      "Size of matrix dok: 335544424\n",
      "Shape of S : (1000000, 3538761) and number of elems : 5920075\n",
      "Size of matrix csr: 48\n",
      "Shape of S : (1000000, 3538761) and number of elems : 0\n",
      "Processed 33000000 videos.\n",
      "\n",
      "Size of matrix dok: 167772272\n",
      "Shape of S : (1000000, 3538761) and number of elems : 5402970\n",
      "Size of matrix csr: 48\n",
      "Shape of S : (1000000, 3538761) and number of elems : 0\n",
      "Processed 34000000 videos.\n",
      "\n",
      "Size of matrix dok: 335544424\n",
      "Shape of S : (1000000, 3538761) and number of elems : 7352110\n",
      "Size of matrix csr: 48\n",
      "Shape of S : (1000000, 3538761) and number of elems : 0\n",
      "Processed 35000000 videos.\n",
      "\n",
      "Size of matrix dok: 167772272\n",
      "Shape of S : (1000000, 3538761) and number of elems : 4718950\n",
      "Size of matrix csr: 48\n",
      "Shape of S : (1000000, 3538761) and number of elems : 0\n",
      "Processed 36000000 videos.\n",
      "\n",
      "Size of matrix dok: 167772272\n",
      "Shape of S : (1000000, 3538761) and number of elems : 5343916\n",
      "Size of matrix csr: 48\n",
      "Shape of S : (1000000, 3538761) and number of elems : 0\n",
      "Processed 37000000 videos.\n",
      "\n",
      "Size of matrix dok: 167772272\n",
      "Shape of S : (1000000, 3538761) and number of elems : 4551324\n",
      "Size of matrix csr: 48\n",
      "Shape of S : (1000000, 3538761) and number of elems : 0\n",
      "Processed 38000000 videos.\n",
      "\n",
      "Size of matrix dok: 167772272\n",
      "Shape of S : (1000000, 3538761) and number of elems : 5156424\n",
      "Size of matrix csr: 48\n",
      "Shape of S : (1000000, 3538761) and number of elems : 0\n",
      "Processed 39000000 videos.\n",
      "\n",
      "Size of matrix dok: 167772272\n",
      "Shape of S : (1000000, 3538761) and number of elems : 5038041\n",
      "Size of matrix csr: 48\n",
      "Shape of S : (1000000, 3538761) and number of elems : 0\n",
      "Processed 40000000 videos.\n",
      "\n",
      "Size of matrix dok: 167772272\n",
      "Shape of S : (1000000, 3538761) and number of elems : 5542189\n",
      "Size of matrix csr: 48\n",
      "Shape of S : (1000000, 3538761) and number of elems : 0\n",
      "Processed 41000000 videos.\n",
      "\n",
      "Size of matrix dok: 335544424\n",
      "Shape of S : (1000000, 3538761) and number of elems : 6279576\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of matrix csr: 48\n",
      "Shape of S : (1000000, 3538761) and number of elems : 0\n",
      "Processed 42000000 videos.\n",
      "\n",
      "Size of matrix dok: 335544424\n",
      "Shape of S : (1000000, 3538761) and number of elems : 5770591\n",
      "Size of matrix csr: 48\n",
      "Shape of S : (1000000, 3538761) and number of elems : 0\n",
      "Processed 43000000 videos.\n",
      "\n",
      "Size of matrix dok: 335544424\n",
      "Shape of S : (1000000, 3538761) and number of elems : 5747828\n",
      "Size of matrix csr: 48\n",
      "Shape of S : (1000000, 3538761) and number of elems : 0\n",
      "Processed 44000000 videos.\n",
      "\n",
      "Size of matrix dok: 167772272\n",
      "Shape of S : (1000000, 3538761) and number of elems : 5337829\n",
      "Size of matrix csr: 48\n",
      "Shape of S : (1000000, 3538761) and number of elems : 0\n",
      "Processed 45000000 videos.\n",
      "\n",
      "Size of matrix dok: 167772272\n",
      "Shape of S : (1000000, 3538761) and number of elems : 5278383\n",
      "Size of matrix csr: 48\n",
      "Shape of S : (1000000, 3538761) and number of elems : 0\n",
      "Processed 46000000 videos.\n",
      "\n",
      "Size of matrix dok: 167772272\n",
      "Shape of S : (1000000, 3538761) and number of elems : 5368975\n",
      "Size of matrix csr: 48\n",
      "Shape of S : (1000000, 3538761) and number of elems : 0\n",
      "Processed 47000000 videos.\n",
      "\n",
      "Size of matrix dok: 167772272\n",
      "Shape of S : (1000000, 3538761) and number of elems : 5109677\n",
      "Size of matrix csr: 48\n",
      "Shape of S : (1000000, 3538761) and number of elems : 0\n",
      "Processed 48000000 videos.\n",
      "\n",
      "Size of matrix dok: 335544424\n",
      "Shape of S : (1000000, 3538761) and number of elems : 5635691\n",
      "Size of matrix csr: 48\n",
      "Shape of S : (1000000, 3538761) and number of elems : 0\n",
      "Processed 49000000 videos.\n",
      "\n",
      "Size of matrix dok: 167772272\n",
      "Shape of S : (1000000, 3538761) and number of elems : 5477602\n",
      "Size of matrix csr: 48\n",
      "Shape of S : (1000000, 3538761) and number of elems : 0\n",
      "Processed 50000000 videos.\n",
      "\n",
      "Size of matrix dok: 335544424\n",
      "Shape of S : (1000000, 3538761) and number of elems : 5804708\n",
      "Size of matrix csr: 48\n",
      "Shape of S : (1000000, 3538761) and number of elems : 0\n",
      "Processed 51000000 videos.\n",
      "\n",
      "Size of matrix dok: 167772272\n",
      "Shape of S : (1000000, 3538761) and number of elems : 5551219\n",
      "Size of matrix csr: 48\n",
      "Shape of S : (1000000, 3538761) and number of elems : 0\n",
      "Processed 52000000 videos.\n",
      "\n",
      "Size of matrix dok: 167772272\n",
      "Shape of S : (1000000, 3538761) and number of elems : 5148214\n",
      "Size of matrix csr: 48\n",
      "Shape of S : (1000000, 3538761) and number of elems : 0\n",
      "Processed 53000000 videos.\n",
      "\n",
      "Size of matrix dok: 335544424\n",
      "Shape of S : (1000000, 3538761) and number of elems : 5669691\n",
      "Size of matrix csr: 48\n",
      "Shape of S : (1000000, 3538761) and number of elems : 0\n",
      "Processed 54000000 videos.\n",
      "\n",
      "Size of matrix dok: 167772272\n",
      "Shape of S : (1000000, 3538761) and number of elems : 5490141\n",
      "Size of matrix csr: 48\n",
      "Shape of S : (1000000, 3538761) and number of elems : 0\n",
      "Processed 55000000 videos.\n",
      "\n",
      "Size of matrix dok: 167772272\n",
      "Shape of S : (1000000, 3538761) and number of elems : 5480823\n",
      "Size of matrix csr: 48\n",
      "Shape of S : (1000000, 3538761) and number of elems : 0\n",
      "Processed 56000000 videos.\n",
      "\n",
      "Size of matrix dok: 167772272\n",
      "Shape of S : (1000000, 3538761) and number of elems : 5585343\n",
      "Size of matrix csr: 48\n",
      "Shape of S : (1000000, 3538761) and number of elems : 0\n",
      "Processed 57000000 videos.\n",
      "\n",
      "Size of matrix dok: 167772272\n",
      "Shape of S : (1000000, 3538761) and number of elems : 5044062\n",
      "Size of matrix csr: 48\n",
      "Shape of S : (1000000, 3538761) and number of elems : 0\n",
      "Processed 58000000 videos.\n",
      "\n",
      "Size of matrix dok: 335544424\n",
      "Shape of S : (1000000, 3538761) and number of elems : 5601802\n",
      "Size of matrix csr: 48\n",
      "Shape of S : (1000000, 3538761) and number of elems : 0\n",
      "Processed 59000000 videos.\n",
      "\n",
      "Size of matrix dok: 335544424\n",
      "Shape of S : (1000000, 3538761) and number of elems : 5667124\n",
      "Size of matrix csr: 48\n",
      "Shape of S : (1000000, 3538761) and number of elems : 0\n",
      "Processed 60000000 videos.\n",
      "\n",
      "Size of matrix dok: 167772272\n",
      "Shape of S : (1000000, 3538761) and number of elems : 4606956\n",
      "Size of matrix csr: 48\n",
      "Shape of S : (1000000, 3538761) and number of elems : 0\n",
      "Processed 61000000 videos.\n",
      "\n",
      "Size of matrix dok: 167772272\n",
      "Shape of S : (1000000, 3538761) and number of elems : 5472208\n",
      "Size of matrix csr: 48\n",
      "Shape of S : (1000000, 3538761) and number of elems : 0\n",
      "Processed 62000000 videos.\n",
      "\n",
      "Size of matrix dok: 167772272\n",
      "Shape of S : (1000000, 3538761) and number of elems : 4830224\n",
      "Size of matrix csr: 48\n",
      "Shape of S : (1000000, 3538761) and number of elems : 0\n",
      "Processed 63000000 videos.\n",
      "\n",
      "Size of matrix dok: 335544424\n",
      "Shape of S : (1000000, 3538761) and number of elems : 6193085\n",
      "Size of matrix csr: 48\n",
      "Shape of S : (1000000, 3538761) and number of elems : 0\n",
      "Processed 64000000 videos.\n",
      "\n",
      "Size of matrix dok: 335544424\n",
      "Shape of S : (1000000, 3538761) and number of elems : 6116705\n",
      "Size of matrix csr: 48\n",
      "Shape of S : (1000000, 3538761) and number of elems : 0\n",
      "Processed 65000000 videos.\n",
      "\n",
      "Size of matrix dok: 167772272\n",
      "Shape of S : (1000000, 3538761) and number of elems : 5550587\n",
      "Size of matrix csr: 48\n",
      "Shape of S : (1000000, 3538761) and number of elems : 0\n",
      "Processed 66000000 videos.\n",
      "\n",
      "Size of matrix dok: 167772272\n",
      "Shape of S : (1000000, 3538761) and number of elems : 5009256\n",
      "Size of matrix csr: 48\n",
      "Shape of S : (1000000, 3538761) and number of elems : 0\n",
      "Processed 67000000 videos.\n",
      "\n",
      "Size of matrix dok: 167772272\n",
      "Shape of S : (1000000, 3538761) and number of elems : 4443397\n",
      "Size of matrix csr: 48\n",
      "Shape of S : (1000000, 3538761) and number of elems : 0\n",
      "Processed 68000000 videos.\n",
      "\n",
      "Size of matrix dok: 167772272\n",
      "Shape of S : (1000000, 3538761) and number of elems : 5249541\n",
      "Size of matrix csr: 48\n",
      "Shape of S : (1000000, 3538761) and number of elems : 0\n",
      "Processed 69000000 videos.\n",
      "\n",
      "Size of matrix dok: 167772272\n",
      "Shape of S : (1000000, 3538761) and number of elems : 5427306\n",
      "Size of matrix csr: 48\n",
      "Shape of S : (1000000, 3538761) and number of elems : 0\n",
      "Processed 70000000 videos.\n",
      "\n",
      "Size of matrix dok: 167772272\n",
      "Shape of S : (1000000, 3538761) and number of elems : 4750273\n",
      "Size of matrix csr: 48\n",
      "Shape of S : (1000000, 3538761) and number of elems : 0\n",
      "Processed 71000000 videos.\n",
      "\n",
      "Size of matrix dok: 167772272\n",
      "Shape of S : (1000000, 3538761) and number of elems : 5499200\n",
      "Size of matrix csr: 48\n",
      "Shape of S : (1000000, 3538761) and number of elems : 0\n",
      "Processed 72000000 videos.\n",
      "\n",
      "Size of matrix dok: 167772272\n",
      "Shape of S : (1000000, 3538761) and number of elems : 4965586\n",
      "Size of matrix csr: 48\n",
      "Shape of S : (1000000, 3538761) and number of elems : 0\n",
      "Processed 73000000 videos.\n",
      "\n",
      "Size of matrix dok: 335544424\n",
      "Shape of S : (1000000, 3538761) and number of elems : 5844781\n",
      "Size of matrix csr: 48\n",
      "Shape of S : (1000000, 3538761) and number of elems : 0\n",
      "Processed 74000000 videos.\n",
      "\n",
      "Size of matrix dok: 335544424\n",
      "Shape of S : (1000000, 3538761) and number of elems : 5691458\n",
      "Size of matrix csr: 48\n",
      "Shape of S : (1000000, 3538761) and number of elems : 0\n",
      "Processed 75000000 videos.\n",
      "\n",
      "Size of matrix dok: 167772272\n",
      "Shape of S : (1000000, 3538761) and number of elems : 4017443\n",
      "Size of matrix csr: 48\n",
      "Shape of S : (1000000, 3538761) and number of elems : 0\n",
      "Processed 76000000 videos.\n",
      "\n",
      "Size of matrix dok: 167772272\n",
      "Shape of S : (1000000, 3538761) and number of elems : 5171170\n",
      "Size of matrix csr: 48\n",
      "Shape of S : (1000000, 3538761) and number of elems : 0\n",
      "Processed 77000000 videos.\n",
      "\n",
      "Size of matrix dok: 335544424\n",
      "Shape of S : (1000000, 3538761) and number of elems : 6393120\n",
      "Size of matrix csr: 48\n",
      "Shape of S : (1000000, 3538761) and number of elems : 0\n",
      "Processed 78000000 videos.\n",
      "\n",
      "Size of matrix dok: 167772272\n",
      "Shape of S : (1000000, 3538761) and number of elems : 4739462\n",
      "Size of matrix csr: 48\n",
      "Shape of S : (1000000, 3538761) and number of elems : 0\n",
      "Processed 79000000 videos.\n",
      "\n",
      "Size of matrix dok: 335544424\n",
      "Shape of S : (1000000, 3538761) and number of elems : 6411989\n",
      "Size of matrix csr: 48\n",
      "Shape of S : (1000000, 3538761) and number of elems : 0\n",
      "Processed 80000000 videos.\n",
      "\n",
      "Size of matrix dok: 167772272\n",
      "Shape of S : (1000000, 3538761) and number of elems : 5330339\n",
      "Size of matrix csr: 48\n",
      "Shape of S : (1000000, 3538761) and number of elems : 0\n",
      "Processed 81000000 videos.\n",
      "\n",
      "Size of matrix dok: 335544424\n",
      "Shape of S : (1000000, 3538761) and number of elems : 6521663\n",
      "Size of matrix csr: 48\n",
      "Shape of S : (1000000, 3538761) and number of elems : 0\n",
      "Processed 82000000 videos.\n",
      "\n",
      "Size of matrix dok: 167772272\n",
      "Shape of S : (1000000, 3538761) and number of elems : 5330046\n",
      "Size of matrix csr: 48\n",
      "Shape of S : (1000000, 3538761) and number of elems : 0\n",
      "Processed 83000000 videos.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of matrix dok: 167772272\n",
      "Shape of S : (1000000, 3538761) and number of elems : 5549563\n",
      "Size of matrix csr: 48\n",
      "Shape of S : (1000000, 3538761) and number of elems : 0\n",
      "Processed 84000000 videos.\n",
      "\n",
      "Size of matrix dok: 167772272\n",
      "Shape of S : (1000000, 3538761) and number of elems : 5560493\n",
      "Size of matrix csr: 48\n",
      "Shape of S : (1000000, 3538761) and number of elems : 0\n",
      "Processed 85000000 videos.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "idx = 0\n",
    "\n",
    "# Row index in the sparse matrix (one row for each video)\n",
    "i_vid = 0\n",
    "\n",
    "\n",
    "for line in reader.readlines():\n",
    "    ###start_iter = time.time()\n",
    "    idx += 1\n",
    "    \n",
    "    if idx % 1000000 == 0:\n",
    "        print('Size of matrix dok: ' + str(sys.getsizeof(S)))\n",
    "        print('Shape of S : ' + str(S.get_shape()) + ' and number of elems : ' + str(S.getnnz()))\n",
    "        S = S.tocsr()\n",
    "        print('Size of matrix csr: ' + str(sys.getsizeof(S)))\n",
    "        file_name = 'S' + str(int(idx / 1000000))\n",
    "        scipy.sparse.save_npz('/dlabdata1/youtube_large/olam/filtered10000/csr_matrices/' + file_name + '.npz', S)\n",
    "        S = dok_matrix((1000000, size_of_tokens_dict), dtype=np.uint8)\n",
    "        print('Shape of S : ' + str(S.get_shape()) + ' and number of elems : ' + str(S.getnnz()))\n",
    "        print('Processed ' + str(idx) + ' videos.')\n",
    "        print('')\n",
    "        \n",
    "    \n",
    "    if idx in idx_vid_to_consider:\n",
    "\n",
    "        # line is a str dict, video is the dict corresponding to the str dict\n",
    "        video = json.loads(line)\n",
    "\n",
    "        # For each video, create a underlying dictionnary for filling the sparse matrix efficiently\n",
    "        dict_freq_tokens_for_sparse_matrix = {}\n",
    "\n",
    "        # Get the tokens for each video and theirs number of occurences\n",
    "        ###start_freq = time.time()\n",
    "        freq_tokens_per_video = get_freq_tokens_per_video(video)\n",
    "        ###print('Time for getting tokens of video : ' + str(time.time() - start_freq))\n",
    "\n",
    "        # Fill the underlying dict\n",
    "        fill_underlying_dict(freq_tokens_per_video, dict_stemmed_tokens, dict_freq_tokens_for_sparse_matrix, i_vid)\n",
    "\n",
    "        # Update the Sparse Matrix\n",
    "        ###start_update = time.time()\n",
    "        dict.update(S, dict_freq_tokens_for_sparse_matrix)\n",
    "        ###print('Time for updating sparse_matrix : ' + str(time.time() - start_update))\n",
    "\n",
    "        # Increment Row index for next video\n",
    "        i_vid += 1\n",
    "        \n",
    "    ###print('Time for 1 iter : ' + str(time.time() - start_iter))\n",
    "    \n",
    "# Save last sparse matrix\n",
    "S = S.tocsr()\n",
    "scipy.sparse.save_npz('/dlabdata1/youtube_large/olam/filtered10000/csr_matrices/S_last.npz', S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = scipy.sparse.load_npz('/dlabdata1/youtube_large/olam/filtered10000/csr_matrices/S1.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2, 86):\n",
    "    S_next = scipy.sparse.load_npz('/dlabdata1/youtube_large/olam/filtered10000/csr_matrices/S' + str(i) + '.npz')\n",
    "    S = scipy.sparse.vstack([S, S_next])\n",
    "\n",
    "# Add last matrix\n",
    "S_last = scipy.sparse.load_npz('/dlabdata1/youtube_large/olam/filtered10000/csr_matrices/S_last.npz')\n",
    "S = scipy.sparse.vstack([S, S_last])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<86000000x3538761 sparse matrix of type '<class 'numpy.uint8'>'\n",
       "\twith 466357648 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## !!!!! Need to reselect only line of videos to consider!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load set of videos to consider\n",
    "with open('/dlabdata1/youtube_large/olam/filtered/list_stemmed_tokens.pickle', 'rb') as f:\n",
    "    list_stemmed_tokens_filtered = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_vid_to_consider_from_0 = []\n",
    "for i in idx_vid_to_consider:\n",
    "    idx_vid_to_consider_from_0.append(i - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "S_full = S[idx_vid_to_consider_from_0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<86000000x5726884 sparse matrix of type '<class 'numpy.uint8'>'\n",
       "\twith 927647643 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.sparse.save_npz('/dlabdata1/youtube_large/olam/filtered10000/csr_matrices/S_full.npz', S_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "S_full = scipy.sparse.load_npz('/dlabdata1/youtube_large/olam/filtered10000/csr_matrices/S_full.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "S_full = S_full.tocsc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed : 0 tokens\n",
      "Processed : 1000000 tokens\n",
      "Processed : 2000000 tokens\n",
      "Processed : 3000000 tokens\n"
     ]
    }
   ],
   "source": [
    "# Remove tokens that appear in less than 20 videos\n",
    "\n",
    "id_tokens_to_consider = []\n",
    "\n",
    "# Iterate on the columns\n",
    "for i in range(S_full.shape[1]):\n",
    "    \n",
    "    if i%1000000 == 0:\n",
    "        print('Processed : ' + str(i) + ' tokens')\n",
    "        \n",
    "    # Check column has more than 20 non zero entries\n",
    "    if S_full[:,i].count_nonzero() >= 100:\n",
    "        id_tokens_to_consider.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65907"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(id_tokens_to_consider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, id_token in enumerate(id_tokens_to_consider):\n",
    "    id2word[i] = list_stemmed_tokens[id_token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65907"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(id2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<21714294x65907 sparse matrix of type '<class 'numpy.uint8'>'\n",
       "\twith 109510371 stored elements in Compressed Sparse Column format>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S_final = S_full[:,id_tokens_to_consider]\n",
    "S_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "S_final = S_final.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.sparse.save_npz('/dlabdata1/youtube_large/olam/filtered10000/csr_matrices/S_final_tok100vid.npz', S_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/dlabdata1/youtube_large/olam/filtered10000/id2word_tok100vid.pickle', 'wb') as f:\n",
    "    pickle.dump(id2word, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the dict of vid_id to channel_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load set of videos to consider\n",
    "with open('/home/olam/idx_vid_to_consider.pickle', 'rb') as f:\n",
    "    idx_vid_to_consider = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load set of videos to consider\n",
    "with open('/dlabdata1/youtube_large/olam/filtered/idx_vid_to_consider.pickle', 'rb') as f:\n",
    "    idx_vid_to_consider_filtered = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45421300"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(idx_vid_to_consider_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid2chan_id = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid2chan_id_filtered = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Zreader(\"/dlabdata1/youtube_large/yt_metadata_all.jsonl.zst\", chunk_size=2**28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed : 1000000 videos\n",
      "Processed : 2000000 videos\n",
      "Processed : 3000000 videos\n",
      "Processed : 4000000 videos\n",
      "Processed : 5000000 videos\n",
      "Processed : 6000000 videos\n",
      "Processed : 7000000 videos\n",
      "Processed : 8000000 videos\n",
      "Processed : 9000000 videos\n",
      "Processed : 10000000 videos\n",
      "Processed : 11000000 videos\n",
      "Processed : 12000000 videos\n",
      "Processed : 13000000 videos\n",
      "Processed : 14000000 videos\n",
      "Processed : 15000000 videos\n",
      "Processed : 16000000 videos\n",
      "Processed : 17000000 videos\n",
      "Processed : 18000000 videos\n",
      "Processed : 19000000 videos\n",
      "Processed : 20000000 videos\n",
      "Processed : 21000000 videos\n",
      "Processed : 22000000 videos\n",
      "Processed : 23000000 videos\n",
      "Processed : 24000000 videos\n",
      "Processed : 25000000 videos\n",
      "Processed : 26000000 videos\n",
      "Processed : 27000000 videos\n",
      "Processed : 28000000 videos\n",
      "Processed : 29000000 videos\n",
      "Processed : 30000000 videos\n",
      "Processed : 31000000 videos\n",
      "Processed : 32000000 videos\n",
      "Processed : 33000000 videos\n",
      "Processed : 34000000 videos\n",
      "Processed : 35000000 videos\n",
      "Processed : 36000000 videos\n",
      "Processed : 37000000 videos\n",
      "Processed : 38000000 videos\n",
      "Processed : 39000000 videos\n",
      "Processed : 40000000 videos\n",
      "Processed : 41000000 videos\n",
      "Processed : 42000000 videos\n",
      "Processed : 43000000 videos\n",
      "Processed : 44000000 videos\n",
      "Processed : 45000000 videos\n",
      "Processed : 46000000 videos\n",
      "Processed : 47000000 videos\n",
      "Processed : 48000000 videos\n",
      "Processed : 49000000 videos\n",
      "Processed : 50000000 videos\n",
      "Processed : 51000000 videos\n",
      "Processed : 52000000 videos\n",
      "Processed : 53000000 videos\n",
      "Processed : 54000000 videos\n",
      "Processed : 55000000 videos\n",
      "Processed : 56000000 videos\n",
      "Processed : 57000000 videos\n",
      "Processed : 58000000 videos\n",
      "Processed : 59000000 videos\n",
      "Processed : 60000000 videos\n",
      "Processed : 61000000 videos\n",
      "Processed : 62000000 videos\n",
      "Processed : 63000000 videos\n",
      "Processed : 64000000 videos\n",
      "Processed : 65000000 videos\n",
      "Processed : 66000000 videos\n",
      "Processed : 67000000 videos\n",
      "Processed : 68000000 videos\n",
      "Processed : 69000000 videos\n",
      "Processed : 70000000 videos\n",
      "Processed : 71000000 videos\n",
      "Processed : 72000000 videos\n",
      "Processed : 73000000 videos\n",
      "Processed : 74000000 videos\n",
      "Processed : 75000000 videos\n",
      "Processed : 76000000 videos\n",
      "Processed : 77000000 videos\n",
      "Processed : 78000000 videos\n",
      "Processed : 79000000 videos\n",
      "Processed : 80000000 videos\n",
      "Processed : 81000000 videos\n",
      "Processed : 82000000 videos\n",
      "Processed : 83000000 videos\n",
      "Processed : 84000000 videos\n",
      "Processed : 85000000 videos\n"
     ]
    }
   ],
   "source": [
    "idx = 0\n",
    "for line in reader.readlines():\n",
    "    \n",
    "    idx += 1\n",
    "    if idx%1000000 == 0:\n",
    "        print('Processed : ' + str(idx) + ' videos')\n",
    "    \n",
    "    if idx in idx_vid_to_consider_filtered:\n",
    "        \n",
    "        # line is a str dict, video is the dict corresponding to the str dict\n",
    "        video = json.loads(line)\n",
    "        \n",
    "        vid2chan_id_filtered[idx] = video['channel_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68642144"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vid2chan_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/olam/vid2chan_id.pickle', 'wb') as f:\n",
    "    pickle.dump(vid2chan_id, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels_id = set(vid2chan_id.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels_id_filtered = set(vid2chan_id_filtered.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "155930"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(channels_id_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/dlabdata1/youtube_large/olam/channels_id_filtered.pickle', 'wb') as f:\n",
    "    pickle.dump(channels_id_filtered, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load set of videos to consider\n",
    "with open('/dlabdata1/youtube_large/olam/chan', 'rb') as f:\n",
    "    idx_vid_to_consider_test = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156982"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(idx_vid_to_consider_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
