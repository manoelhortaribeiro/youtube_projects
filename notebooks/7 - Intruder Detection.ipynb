{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/olam/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import collections\n",
    "import fasttext\n",
    "import gzip\n",
    "import json\n",
    "import math\n",
    "import matplotlib\n",
    "import nltk\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import scipy.sparse\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import zstandard as zstd\n",
    "\n",
    "from collections import Counter\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from joblib import dump, load\n",
    "from langdetect import detect\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.types import LongType, StructField, StructType\n",
    "from pyspark.ml.clustering import LDA, LDAModel, LocalLDAModel\n",
    "from pyspark.ml.linalg import Vectors, SparseVector\n",
    "from scipy.sparse import dok_matrix\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get top 5 terms per topic with one intruder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = SparkConf().setMaster(\"local[4]\").setAll(\n",
    "    [('spark.executor.memory', '2g'), ('spark.driver.memory', '8g'), ('spark.driver.maxResultSize', '0')])\n",
    "\n",
    "# create the session\n",
    "spark = SparkSession.builder.appName(\n",
    "    \"LDA_topicmodelling\").config(conf=conf).getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_terms(n_topic, use_bigram):\n",
    "    '''Return a dictionnary of topic_id as keys and a list of terms as values, \n",
    "    where the terms are sorted by their distribution in the topic (descending)'''\n",
    "    \n",
    "    i_topic = 0\n",
    "    dict_ = {}\n",
    "    filename = 'describe_topics_' + str(n_topic) + '.json'\n",
    "\n",
    "    if use_bigram:\n",
    "        path_file = '/dlabdata1/youtube_large/olam/data/with_ngram/describe_topics/' + filename\n",
    "        path_id2word = '/dlabdata1/youtube_large/olam/data/with_ngram/id2word_top20.pickle'\n",
    "    else:\n",
    "        path_file = '/dlabdata1/youtube_large/olam/data/final_res/describe_topics/' + filename\n",
    "        path_id2word = '/dlabdata1/youtube_large/olam/data/final_res/id2word_top20.pickle'\n",
    "        \n",
    "    with open(path_id2word, 'rb') as f:\n",
    "        id2word = pickle.load(f)\n",
    "    f.close()\n",
    "        \n",
    "    describe_topics = spark.read.json(path_file)\n",
    "\n",
    "    for row in describe_topics.sort('topic').rdd.collect():\n",
    "\n",
    "        term_weights = row.termWeights   \n",
    "\n",
    "        for i, token_id in enumerate(row.termIndices):\n",
    "\n",
    "            if i == 0:\n",
    "                dict_[i_topic] = [id2word[token_id]]\n",
    "            else:\n",
    "                dict_[i_topic].append(id2word[token_id])\n",
    "\n",
    "        i_topic += 1\n",
    "    \n",
    "    return dict_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top5_terms_per_topic(dict_topic_term):\n",
    "    '''Return a dictionnary of topic_id as keys and a list top the top5 terms for each topic'''\n",
    "    \n",
    "    dict_top5 = {}\n",
    "\n",
    "    for key, val in dict_topic_term.items():\n",
    "        dict_top5[key] = dict_topic_term[key][:5]\n",
    "        \n",
    "    return dict_top5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_top_terms(dict_top5):\n",
    "    '''Return the set of all top5 terms'''\n",
    "    \n",
    "    set_all_top_terms = []\n",
    "\n",
    "    for _, val in dict_top5.items():\n",
    "        set_all_top_terms.extend(val)\n",
    "        \n",
    "    return set(set_all_top_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_intruders(dict_topic_term, dict_top5, set_all_top_terms):\n",
    "    '''Return a dictionnary of topic_id as keys and the corresponding intruder'''\n",
    "    \n",
    "    dict_furthest_intruder_per_topic = {}\n",
    "\n",
    "    for key, value in dict_topic_term.items():\n",
    "        set_all_top_terms_tmp = set_all_top_terms.copy()\n",
    "\n",
    "        for term in dict_top5[key]:\n",
    "            set_all_top_terms_tmp.remove(term)\n",
    "\n",
    "        worst_term = ''\n",
    "        worst_idx = 0\n",
    "\n",
    "        for term in set_all_top_terms:\n",
    "            idx = dict_topic_term[key].index(term)\n",
    "            if idx >= worst_idx and idx <= len(dict_topic_term[key]) / 100:\n",
    "                worst_idx = idx\n",
    "                worst_term = term\n",
    "\n",
    "        dict_furthest_intruder_per_topic[key] = worst_term\n",
    "        \n",
    "    return dict_furthest_intruder_per_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(n_topic, dict_top5, dict_furthest_intruder_per_topic):\n",
    "    '''Return matrix of all top5 terms shuffled with the intruder'''\n",
    "    \n",
    "    data = []\n",
    "\n",
    "    for i in range(n_topic):\n",
    "        terms = []\n",
    "\n",
    "        terms.extend(dict_top5[i])\n",
    "        terms.append(dict_furthest_intruder_per_topic[i])\n",
    "\n",
    "        random.shuffle(terms)\n",
    "\n",
    "        data.append(terms)\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_csv_file(data, n_topic, use_bigram):\n",
    "    '''Save the terms with intruder into a csv file'''\n",
    "    \n",
    "    columns = ['Term 1', 'Term 2', 'Term 3', 'Term 4', 'Term 5', 'Term 6']\n",
    "\n",
    "    df = pd.DataFrame(data, columns=columns)\n",
    "    \n",
    "    if use_bigram:\n",
    "        path_file = '/home/olam/intruder' + str(n_topic) + '_bigram.csv'\n",
    "    else:\n",
    "        path_file = '/home/olam/intruder' + str(n_topic) + '.csv'\n",
    "    \n",
    "    df.to_csv(path_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intruder(n_topic, use_bigram):\n",
    "    '''Run the intruder pipeline, in order to get a csv file with the top5 \n",
    "    terms and with one intruder and return the dictionnary of intruder'''\n",
    "    \n",
    "    dict_topic_term = get_topic_terms(n_topic, use_bigram)\n",
    "    dict_top5 = get_top5_terms_per_topic(dict_topic_term)\n",
    "    set_all_top_terms = get_all_top_terms(dict_top5)\n",
    "    dict_furthest_intruder_per_topic = get_intruders(dict_topic_term, dict_top5, set_all_top_terms)\n",
    "    data = get_data(n_topic, dict_top5, dict_furthest_intruder_per_topic)\n",
    "    \n",
    "    random_indices = random.sample(list(np.arange(0, len(data))), 20)\n",
    "    random_indices.sort()\n",
    "    data = [data[i] for i in random_indices]\n",
    "    \n",
    "    get_csv_file(data, n_topic, use_bigram)\n",
    "    \n",
    "    return {idx: dict_furthest_intruder_per_topic[idx] for idx in random_indices}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_topic_term = get_topic_terms(55, False)\n",
    "dict_top5 = get_top5_terms_per_topic(dict_topic_term)\n",
    "set_all_top_terms = get_all_top_terms(dict_top5)\n",
    "dict_furthest_intruder_per_topic = get_intruders(dict_topic_term, dict_top5, set_all_top_terms)\n",
    "data = get_data(55, dict_top5, dict_furthest_intruder_per_topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0['fnaf', 'five', 'motiv', 'night', 'freddi', 'youtub']\n",
      "1['film', 'trailer', 'movi', 'episod', 'show', 'funni']\n",
      "2['gta', 'grand', 'glitch', 'mod', 'live', 'onlin']\n",
      "3['youtub', 'react', 'girl', 'reaction', 'prank', 'ladi']\n",
      "4['offici', 'beauti', 'rap', 'remix', 'video', 'music']\n",
      "5['egg', 'cake', 'pet', 'cat', 'long', 'park']\n",
      "6['long', 'travel', 'stori', 'scari', 'citi', 'time']\n",
      "7['toy', 'disney', 'doll', 'power', 'play', 'surpris']\n",
      "8['indian', 'power', 'pakistan', 'ali', 'hindi', 'india']\n",
      "9['fire', 'tour', 'build', 'time', 'hous', 'home']\n",
      "10['beauti', 'eye', 'power', 'makeup', 'tutori', 'look']\n",
      "11['power', 'big', 'beach', 'clean', 'fish', 'paul']\n",
      "12['bodi', 'fit', 'review', 'weight', 'exercis', 'workout']\n",
      "13['jame', 'bts', 'pop', 'radio', 'royal', 'week']\n",
      "14['bird', 'god', 'yoga', 'christian', 'king', 'jame']\n",
      "15['bros', 'mario', 'bike', 'super', 'beginn', 'smash']\n",
      "16['plant', 'style', 'power', 'malayalam', 'danc', 'garden']\n",
      "17['edit', 'review', 'make', 'photo', 'pro', 'camera']\n",
      "18['let', 'gameplay', 'game', 'play', 'walkthrough', 'beginn']\n",
      "19['box', 'amazon', 'van', 'farm', 'youtub', 'busi']\n",
      "20['short', 'galaxi', 'monster', 'minecraft', 'mod', 'halloween']\n",
      "21['one', 'babi', 'vlog', 'mom', 'famili', 'routin']\n",
      "22['long', 'hairstyl', 'hair', 'natur', 'style', 'back']\n",
      "23['live', 'lyric', 'free', 'fortnit', 'piano', 'cover']\n",
      "24['tutori', 'beginn', 'photoshop', 'comic', 'effect', 'design']\n",
      "25['show', 'trick', 'roblox', 'card', 'simul', 'magic']\n",
      "26['ever', 'six', 'top', 'rainbow', 'power', 'best']\n",
      "27['learn', 'english', 'comic', 'time', 'book', 'man']\n",
      "28['hot', 'edit', 'overwatch', 'gold', 'tree', 'sam']\n",
      "29['team', 'ultim', 'open', 'fifa', 'pack', 'glitch']\n",
      "30['haul', 'shop', 'dog', 'challeng', 'fashion', 'big']\n",
      "31['birthday', 'stock', 'market', 'parti', 'money', 'fire']\n",
      "32['wwe', 'basketbal', 'wrestl', 'joe', 'nba', 'jame']\n",
      "33['joe', 'fight', 'wwe', 'ufc', 'switch', 'philippin']\n",
      "34['car', 'red', 'wheel', 'race', 'drive', 'truck']\n",
      "35['children', 'pop', 'babi', 'song', 'kid', 'cartoon']\n",
      "36['sport', 'footbal', 'offici', 'gun', 'dead', 'red']\n",
      "37['comedi', 'moment', 'funni', 'anim', 'bird', 'video']\n",
      "38['mobil', 'legend', 'pubg', 'gun', 'sim', 'train']\n",
      "39['news', 'trump', 'polit', 'joe', 'today', 'live']\n",
      "40['gold', 'pokemon', 'ball', 'dragon', 'asmr', 'sleep']\n",
      "41['king', 'video', 'one', 'game', 'xbox', 'gameplay']\n",
      "42['today', 'space', 'histori', 'war', 'fact', 'star']\n",
      "43['friday', 'fan', 'princ', 'new', 'light', 'machin']\n",
      "44['blue', 'rock', 'lesson', 'shop', 'guitar', 'metal']\n",
      "45['short', 'khan', 'christian', 'anim', 'film', 'bollywood']\n",
      "46['type', 'beat', 'youtub', 'free', 'android', 'iphon']\n",
      "47['op', 'call', 'black', 'duti', 'five', 'zombi']\n",
      "48['new', 'movi', 'latest', 'free', 'video', 'song']\n",
      "49['hack', 'day', 'school', 'back', 'one', 'life']\n",
      "50['video', 'ladi', 'vega', 'remix', 'para', 'indonesia']\n",
      "51['like', 'eat', 'recip', 'cook', 'chicken', 'food']\n",
      "52['bag', 'water', 'pool', 'camp', 'slime', 'new']\n",
      "53['like', 'guy', 'women', 'love', 'look', 'date']\n",
      "54['diy', 'draw', 'make', 'paint', 'art', 'trick']\n"
     ]
    }
   ],
   "source": [
    "for i, row in enumerate(data):\n",
    "    print(str(i) + str(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'youtub', 1: 'funni', 2: 'live', 3: 'ladi', 4: 'beauti', 5: 'long', 6: 'long', 7: 'power', 8: 'power', 9: 'time', 10: 'power', 11: 'power', 12: 'review', 13: 'jame', 14: 'jame', 15: 'beginn', 16: 'style', 17: 'make', 18: 'beginn', 19: 'youtub', 20: 'short', 21: 'one', 22: 'back', 23: 'free', 24: 'comic', 25: 'show', 26: 'power', 27: 'time', 28: 'edit', 29: 'glitch', 30: 'big', 31: 'fire', 32: 'joe', 33: 'wwe', 34: 'red', 35: 'pop', 36: 'offici', 37: 'bird', 38: 'gun', 39: 'joe', 40: 'gold', 41: 'king', 42: 'today', 43: 'new', 44: 'shop', 45: 'christian', 46: 'youtub', 47: 'five', 48: 'free', 49: 'one', 50: 'remix', 51: 'like', 52: 'new', 53: 'look', 54: 'trick'}\n"
     ]
    }
   ],
   "source": [
    "print(dict_furthest_intruder_per_topic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Get the csv file with intruder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_furthest_intruder_per_topic_55_bigram = intruder(n_topic=55, use_bigram=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_furthest_intruder_per_topic_55 = intruder(n_topic=55, use_bigram=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/olam/intruder/intruder55_abel.pickle', 'wb') as f:\n",
    "    pickle.dump(dict_furthest_intruder_per_topic_55, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_furthest_intruder_per_topic_110 = intruder(n_topic=110, use_bigram=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/olam/intruder/intruder110_abel.pickle', 'wb') as f:\n",
    "    pickle.dump(dict_furthest_intruder_per_topic_110, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get analyze results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(df, dict_intruder):\n",
    "    '''\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas Dataframe\n",
    "        Results of the user \n",
    "    dict_intruder : dict\n",
    "        Dictionnary that contains the groundtruth intruder\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    The accuracy of the correct intruder detected by a user\n",
    "    '''\n",
    "    return (np.array(df['Intruder']) == np.array(list(dict_intruder.values()))).sum() / len(dict_intruder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Paul with 110 topics: 0.3\n"
     ]
    }
   ],
   "source": [
    "# Paul\n",
    "\n",
    "df110_paul = pd.read_csv('/home/olam/intruder_res/intruder110_Paul.csv')\n",
    "\n",
    "with open('/home/olam/intruder/intruder110_paul.pickle', 'rb') as f:\n",
    "    dict_intruder110_paul = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "accuracy_110_paul = get_accuracy(df110_paul, dict_intruder110_paul)\n",
    "print('Accuracy for Paul with 110 topics: ' + str(accuracy_110_paul))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Nico with 55 topics: 0.25\n"
     ]
    }
   ],
   "source": [
    "# Nico\n",
    "\n",
    "df55_nico = pd.read_csv('/home/olam/intruder_res/intruder55_Nico.csv')\n",
    "\n",
    "with open('/home/olam/intruder/intruder55_nico.pickle', 'rb') as f:\n",
    "    dict_intruder55_nico = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "accuracy_55_nico = get_accuracy(df55_nico, dict_intruder55_nico)\n",
    "print('Accuracy for Nico with 55 topics: ' + str(accuracy_55_nico))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Olivier with 55 topics: 0.55\n"
     ]
    }
   ],
   "source": [
    "# Olivier55\n",
    "\n",
    "df55_olivier = pd.read_csv('/home/olam/intruder_res/intruder55_Olivier.csv')\n",
    "\n",
    "with open('/home/olam/intruder/intruder55_olivier.pickle', 'rb') as f:\n",
    "    dict_intruder55_olivier = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "accuracy_55_olivier = get_accuracy(df55_olivier, dict_intruder55_olivier)\n",
    "print('Accuracy for Olivier with 55 topics: ' + str(accuracy_55_olivier))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Robin with 55 topics: 0.6\n"
     ]
    }
   ],
   "source": [
    "# Robin\n",
    "\n",
    "df55_robin = pd.read_csv('/home/olam/intruder_res/intruder55_Robin.csv')\n",
    "\n",
    "with open('/home/olam/intruder/intruder55_robin.pickle', 'rb') as f:\n",
    "    dict_intruder55_robin = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "accuracy_55_robin = get_accuracy(df55_robin, dict_intruder55_robin)\n",
    "print('Accuracy for Robin with 55 topics: ' + str(accuracy_55_robin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Olivier with 110 topics: 0.35\n"
     ]
    }
   ],
   "source": [
    "# Olivier110\n",
    "\n",
    "df110_olivier = pd.read_csv('/home/olam/intruder_res/intruder110_Olivier.csv')\n",
    "\n",
    "with open('/home/olam/intruder/intruder110_olivier.pickle', 'rb') as f:\n",
    "    dict_intruder110_olivier = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "accuracy_110_olivier = get_accuracy(df110_olivier, dict_intruder110_olivier)\n",
    "print('Accuracy for Olivier with 110 topics: ' + str(accuracy_110_olivier))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Stan with 55 topics: 0.45\n"
     ]
    }
   ],
   "source": [
    "# Stan55\n",
    "\n",
    "df55_stan = pd.read_csv('/home/olam/intruder_res/intruder55_Stan.csv')\n",
    "\n",
    "with open('/home/olam/intruder/intruder55_stan.pickle', 'rb') as f:\n",
    "    dict_intruder55_stan = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "accuracy_55_stan = get_accuracy(df55_stan, dict_intruder55_stan)\n",
    "print('Accuracy for Stan with 55 topics: ' + str(accuracy_55_stan))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Stan with 110 topics: 0.35\n"
     ]
    }
   ],
   "source": [
    "# Stan110\n",
    "\n",
    "df110_stan = pd.read_csv('/home/olam/intruder_res/intruder110_Stan.csv')\n",
    "\n",
    "with open('/home/olam/intruder/intruder110_stan.pickle', 'rb') as f:\n",
    "    dict_intruder110_stan = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "accuracy_110_Stan = get_accuracy(df110_stan, dict_intruder110_stan)\n",
    "print('Accuracy for Stan with 110 topics: ' + str(accuracy_110_Stan))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Dani with 55 topics: 0.55\n"
     ]
    }
   ],
   "source": [
    "# Dani\n",
    "\n",
    "df55_dani = pd.read_csv('/home/olam/intruder_res/intruder55_Dani.csv')\n",
    "\n",
    "with open('/home/olam/intruder/intruder55_dani.pickle', 'rb') as f:\n",
    "    dict_intruder55_dani = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "accuracy_55_dani = get_accuracy(df55_dani, dict_intruder55_dani)\n",
    "print('Accuracy for Dani with 55 topics: ' + str(accuracy_55_dani))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Olivia with 55 topics: 0.4\n"
     ]
    }
   ],
   "source": [
    "# Olivia\n",
    "\n",
    "df55_olivia = pd.read_csv('/home/olam/intruder_res/intruder55_Olivia.csv')\n",
    "\n",
    "with open('/home/olam/intruder/intruder55_olivia.pickle', 'rb') as f:\n",
    "    dict_intruder55_olivia = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "accuracy_55_olivia = get_accuracy(df55_olivia, dict_intruder55_olivia)\n",
    "print('Accuracy for Olivia with 55 topics: ' + str(accuracy_55_olivia))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Kevin with 55 topics: 0.35\n"
     ]
    }
   ],
   "source": [
    "# Kevin\n",
    "\n",
    "df55_kevin = pd.read_csv('/home/olam/intruder_res/intruder55_Kevin.csv')\n",
    "\n",
    "with open('/home/olam/intruder/intruder55_kevin.pickle', 'rb') as f:\n",
    "    dict_intruder55_kevin = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "accuracy_55_Kevin = get_accuracy(df55_kevin, dict_intruder55_kevin)\n",
    "print('Accuracy for Kevin with 55 topics: ' + str(accuracy_55_Kevin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Jalel with 110 topics: 0.3\n"
     ]
    }
   ],
   "source": [
    "# Jalel\n",
    "\n",
    "df110_jalel = pd.read_csv('/home/olam/intruder_res/intruder110_Jalel.csv')\n",
    "\n",
    "with open('/home/olam/intruder/intruder110_jalel.pickle', 'rb') as f:\n",
    "    dict_intruder110_jalel = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "accuracy_110_jalel = get_accuracy(df110_jalel, dict_intruder110_jalel)\n",
    "print('Accuracy for Jalel with 110 topics: ' + str(accuracy_110_jalel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Larry with 110 topics: 0.45\n"
     ]
    }
   ],
   "source": [
    "# Larry\n",
    "\n",
    "df110_larry = pd.read_csv('/home/olam/intruder_res/intruder110_Larry.csv')\n",
    "\n",
    "with open('/home/olam/intruder/intruder110_larry.pickle', 'rb') as f:\n",
    "    dict_intruder110_larry = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "accuracy_110_larry = get_accuracy(df110_larry, dict_intruder110_larry)\n",
    "print('Accuracy for Larry with 110 topics: ' + str(accuracy_110_larry))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Rayane with 110 topics: 0.2\n"
     ]
    }
   ],
   "source": [
    "# Rayane\n",
    "\n",
    "df110_rayane = pd.read_csv('/home/olam/intruder_res/intruder110_Rayane.csv')\n",
    "\n",
    "with open('/home/olam/intruder/intruder110_rayane.pickle', 'rb') as f:\n",
    "    dict_intruder110_rayane = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "accuracy_110_rayane = get_accuracy(df110_rayane, dict_intruder110_rayane)\n",
    "print('Accuracy for Rayane with 110 topics: ' + str(accuracy_110_rayane))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Manoel with 55 topics: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Manoel\n",
    "\n",
    "df55_manoel = pd.read_csv('/home/olam/intruder_res/intruder55_Manoel.csv')\n",
    "\n",
    "with open('/home/olam/intruder/intruder55_manoel.pickle', 'rb') as f:\n",
    "    dict_intruder55_manoel = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "accuracy_55_manoel = get_accuracy(df55_manoel, dict_intruder55_manoel)\n",
    "print('Accuracy for Manoel with 55 topics: ' + str(accuracy_55_manoel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{4: 'style',\n",
       " 21: 'documentari',\n",
       " 27: 'play',\n",
       " 32: 'hand',\n",
       " 36: 'death',\n",
       " 50: 'man',\n",
       " 53: 'work',\n",
       " 60: 'style',\n",
       " 62: 'pop',\n",
       " 67: 'battl',\n",
       " 69: 'day',\n",
       " 70: 'top',\n",
       " 71: 'studio',\n",
       " 80: 'peopl',\n",
       " 86: 'custom',\n",
       " 89: 'today',\n",
       " 91: 'easi',\n",
       " 94: 'year',\n",
       " 95: 'review',\n",
       " 105: 'south'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_intruder55_manoel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Abel with 110 topics: 0.05\n"
     ]
    }
   ],
   "source": [
    "# Abel\n",
    "\n",
    "df110_abel = pd.read_csv('/home/olam/intruder_res/intruder110_Abel.csv')\n",
    "\n",
    "with open('/home/olam/intruder/intruder110_abel.pickle', 'rb') as f:\n",
    "    dict_intruder110_abel = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "accuracy_110_abel = get_accuracy(df110_abel, dict_intruder110_abel)\n",
    "print('Accuracy for Abel with 110 topics: ' + str(accuracy_110_abel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{9: 'tip',\n",
       " 12: 'mark',\n",
       " 13: 'age',\n",
       " 30: 'famili',\n",
       " 35: 'old',\n",
       " 38: 'snow',\n",
       " 43: 'last',\n",
       " 45: 'man',\n",
       " 54: 'custom',\n",
       " 64: 'class',\n",
       " 68: 'back',\n",
       " 72: 'mark',\n",
       " 76: 'tip',\n",
       " 79: 'show',\n",
       " 81: 'last',\n",
       " 87: 'year',\n",
       " 95: 'review',\n",
       " 98: 'fast',\n",
       " 102: 'reaction',\n",
       " 107: 'record'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_intruder110_abel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Olivier with 55 topics: 0.8909090909090909\n"
     ]
    }
   ],
   "source": [
    "# With selecting worst intruder possible in the top5 of other topics\n",
    "\n",
    "df55 = pd.read_csv('/home/olam/intruder55_oli.csv')\n",
    "\n",
    "accuracy_55_oli = get_accuracy(df55, dict_furthest_intruder_per_topic_55)\n",
    "print('Accuracy for Olivier with 55 topics: ' + str(accuracy_55_oli))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Stan with 55 topics: 0.6\n"
     ]
    }
   ],
   "source": [
    "# With selecting worst intruder possible in the top5 of other topics\n",
    "\n",
    "df55_stan = pd.read_csv('/home/olam/intruder55_stan.csv')\n",
    "\n",
    "accuracy_55_stan = get_accuracy(df55_stan, dict_furthest_intruder_per_topic_55)\n",
    "print('Accuracy for Stan with 55 topics: ' + str(accuracy_55_stan))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Olivier with 110 topics: 0.7636363636363637\n"
     ]
    }
   ],
   "source": [
    "# With selecting worst intruder possible in the top5 of other topics\n",
    "\n",
    "df110 = pd.read_csv('/home/olam/intruder110_oli.csv')\n",
    "\n",
    "accuracy_110_oli = 2 * get_accuracy(df110, dict_furthest_intruder_per_topic_110)\n",
    "print('Accuracy for Olivier with 110 topics: ' + str(accuracy_110_oli))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
