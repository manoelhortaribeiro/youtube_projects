{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Characterising the evolution of the user interests on YT\n",
    "\n",
    "This notebook covers the whole pipeline of the project.\n",
    "\n",
    "Here is the table content of the principal tasks : \n",
    "- **Data Processing**\n",
    "- **Preparing Pyspark Model**\n",
    "- **Topic modelling**\n",
    "- **Results: Topic Coherence**\n",
    "- **Classifier**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.1 Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/olam/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import collections\n",
    "import fasttext\n",
    "import gzip\n",
    "import json\n",
    "import nltk\n",
    "import os\n",
    "import pickle\n",
    "import scipy.sparse\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import zstandard as zstd\n",
    "\n",
    "from collections import Counter\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from langdetect import detect\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import LongType, StructField, StructType\n",
    "from pyspark.ml.clustering import LDA, LDAModel, LocalLDAModel\n",
    "from pyspark.ml.linalg import Vectors, SparseVector\n",
    "from scipy.sparse import dok_matrix\n",
    "\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Data Processing \n",
    "\n",
    "In this section, we will select the data for the topic modelling model as follow:\n",
    "\n",
    "- videos has at least 10'000 views\n",
    "- videos from channels with at least 100'000 subscribers\n",
    "\n",
    "For that, we proceed as follow :\n",
    "\n",
    "- first pass over the whole dataset in order to build the vocabulary and the keep the index of the relevant videos\n",
    "- second pass over the whole dataset to construct a NxM sparse matrix, where N is the number of videos and M is the number of words in the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 50456 relevant channels.\n"
     ]
    }
   ],
   "source": [
    "# GET THE LIST OF RELEVANT CHANNELS\n",
    "\n",
    "df_channelcrawler = pd.read_csv('/dlabdata1/youtube_large/channelcrawler.csv')\n",
    "\n",
    "df_channelcrawler['channel_id'] = df_channelcrawler['link'].apply(\n",
    "    lambda x: x.replace('http://www.youtube.com/channel/', ''))\n",
    "\n",
    "# Filter channels with at least 100'000 subs\n",
    "df_channelcrawler = df_channelcrawler[df_channelcrawler['subscribers'] >= 100000]\n",
    "\n",
    "# Store in a set since it will be faster to check if a channel is in channelcrawler\n",
    "set_relevant_channels = set(df_channelcrawler['channel_id'])\n",
    "\n",
    "print('There are ' + str(len(set_relevant_channels)) + ' relevant channels.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting NLP pre-processing features\n",
    "stop_words = set(stopwords.words('english'))\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "s_stemmer = SnowballStemmer(language='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_10000_views(video):\n",
    "    try:\n",
    "        return video['view_count'] >= 10000\n",
    "    except KeyError:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_channel(video):\n",
    "    try:\n",
    "        return video['channel_id'] in set_relevant_channels\n",
    "    except:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isEnglishAlpha(s):\n",
    "    try:\n",
    "        s.encode(encoding='utf-8').decode('ascii')\n",
    "    except UnicodeDecodeError:\n",
    "        return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_freq_tokens_per_video(video):\n",
    "    ''''''\n",
    "\n",
    "    title_tokens = [w for w in tokenizer.tokenize(\n",
    "        video['title'].lower()) if not w in stop_words]\n",
    "    tag_tokens = [w for w in tokenizer.tokenize(\n",
    "        video['tags'].lower()) if not w in stop_words]\n",
    "\n",
    "    # We want to keep duplicates !!\n",
    "    tokens_per_video = title_tokens + tag_tokens\n",
    "\n",
    "    # Filter token with length < 3, with non english alphabet since fastext is not 100% accurate and remove numerical token\n",
    "    tokens_keep = []\n",
    "    for token in tokens_per_video:\n",
    "        if len(token) >= 3 and (not token.isnumeric()) and isEnglishAlpha(token):\n",
    "            tokens_keep.append(token)\n",
    "\n",
    "    # Stemming\n",
    "    stemmed_tokens_per_video = ([s_stemmer.stem(w) for w in tokens_keep])\n",
    "\n",
    "    # Return a Counter object of the tokens\n",
    "    return collections.Counter(stemmed_tokens_per_video)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 First pass \n",
    "The first pass on the dataset will allow us to recover relevant videos and list of tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1000000 videos...\n",
      "Processed 2000000 videos...\n",
      "Processed 3000000 videos...\n",
      "Processed 4000000 videos...\n",
      "Processed 5000000 videos...\n",
      "Processed 6000000 videos...\n",
      "Processed 7000000 videos...\n",
      "Processed 8000000 videos...\n",
      "Processed 9000000 videos...\n",
      "Processed 10000000 videos...\n",
      "Processed 11000000 videos...\n",
      "Processed 12000000 videos...\n",
      "Processed 13000000 videos...\n",
      "Processed 14000000 videos...\n",
      "Processed 15000000 videos...\n",
      "Processed 16000000 videos...\n",
      "Processed 17000000 videos...\n",
      "Processed 18000000 videos...\n",
      "Processed 19000000 videos...\n",
      "Processed 20000000 videos...\n",
      "Processed 21000000 videos...\n",
      "Processed 22000000 videos...\n",
      "Processed 23000000 videos...\n",
      "Processed 24000000 videos...\n",
      "Processed 25000000 videos...\n",
      "Processed 26000000 videos...\n",
      "Processed 27000000 videos...\n",
      "Processed 28000000 videos...\n",
      "Processed 29000000 videos...\n",
      "Processed 30000000 videos...\n",
      "Processed 31000000 videos...\n",
      "Processed 32000000 videos...\n",
      "Processed 33000000 videos...\n",
      "Processed 34000000 videos...\n",
      "Processed 35000000 videos...\n",
      "Processed 36000000 videos...\n",
      "Processed 37000000 videos...\n",
      "Processed 38000000 videos...\n",
      "Processed 39000000 videos...\n",
      "Processed 40000000 videos...\n",
      "Processed 41000000 videos...\n",
      "Processed 42000000 videos...\n",
      "Processed 43000000 videos...\n",
      "Processed 44000000 videos...\n",
      "Processed 45000000 videos...\n",
      "Processed 46000000 videos...\n",
      "Processed 47000000 videos...\n",
      "Processed 48000000 videos...\n",
      "Processed 49000000 videos...\n",
      "Processed 50000000 videos...\n",
      "Processed 51000000 videos...\n",
      "Processed 52000000 videos...\n",
      "Processed 53000000 videos...\n",
      "Processed 54000000 videos...\n",
      "Processed 55000000 videos...\n",
      "Processed 56000000 videos...\n",
      "Processed 57000000 videos...\n",
      "Processed 58000000 videos...\n",
      "Processed 59000000 videos...\n",
      "Processed 60000000 videos...\n",
      "Processed 61000000 videos...\n",
      "Processed 62000000 videos...\n",
      "Processed 63000000 videos...\n",
      "Processed 64000000 videos...\n",
      "Processed 65000000 videos...\n",
      "Processed 66000000 videos...\n",
      "Processed 67000000 videos...\n",
      "Processed 68000000 videos...\n",
      "Processed 69000000 videos...\n",
      "Processed 70000000 videos...\n",
      "Processed 71000000 videos...\n",
      "Processed 72000000 videos...\n",
      "Processed 73000000 videos...\n"
     ]
    }
   ],
   "source": [
    "# Variable that contains the idx of every non english vid and that\n",
    "# belongs to a channel in channelcrawler.csv TO BE USED IN SECOND ITER\n",
    "set_relevant_vid = set()\n",
    "\n",
    "# Variable first instanciated as set to check existing tokens efficiently,\n",
    "# which will be a list in order to get the index for each tokens\n",
    "set_stemmed_tokens = set()\n",
    "\n",
    "# Reading the file\n",
    "with gzip.open('/dlabdata1/youtube_large/yt_metadata_en.jsonl.gz', 'rb') as f:\n",
    "\n",
    "    for i, line in enumerate(f):\n",
    "\n",
    "        try:\n",
    "            # line is a byte dict, video is the corresponding dict\n",
    "            video = json.loads(line)\n",
    "        except:\n",
    "            video = {'channel_id': None}\n",
    "\n",
    "        if check_channel(video) and check_10000_views(video):\n",
    "\n",
    "            tokens_per_video = get_freq_tokens_per_video(video)\n",
    "\n",
    "            set_relevant_vid.add(i)\n",
    "            set_stemmed_tokens.update(tokens_per_video)\n",
    "\n",
    "        if i % 1000000 == 0 and i != 0:\n",
    "            print('Processed ' + str(i) + ' videos...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save some intermediate results\n",
    "\n",
    "with open('/dlabdata1/youtube_large/olam/data/final_res/set_relevant_vid.pickle', 'wb') as f:\n",
    "    pickle.dump(set_relevant_vid, f)\n",
    "f.close()\n",
    "\n",
    "with open('/dlabdata1/youtube_large/olam/data/final_res/set_stemmed_tokens.pickle', 'wb') as f:\n",
    "    pickle.dump(set_stemmed_tokens, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Second pass \n",
    "The second pass on the dataset will allow us to create a NxM sparse matrix, where N is the number of videos and M is the number of words in the vocabulary\n",
    "\n",
    "Notes:\n",
    "- In order to keep the memory usage low, we will fill sparse matrix with only 1'000'000 rows and save them in the csr format\n",
    "- Stack the saved sparse matrix together to get the final sparse matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_zero_rows(M):\n",
    "    '''Function that removes all rows from sparse matrix M that contains only zero.'''\n",
    "    num_nonzeros = np.diff(M.indptr)\n",
    "    return M[num_nonzeros != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_underlying_dict(freq_tokens_per_video, word2id, i_vid):\n",
    "    '''Method to fill the underlying dictionnary in order to \n",
    "    update the sparse matrix incrementally by videos'''\n",
    "\n",
    "    dict_freq_tokens_for_sparse_matrix = {}\n",
    "\n",
    "    for key in freq_tokens_per_video.keys():\n",
    "\n",
    "        # Column index in the sparse matrix (one column for each token)\n",
    "        try:\n",
    "            j_token = word2id[key]\n",
    "\n",
    "            # Filling the underlying dict\n",
    "            dict_freq_tokens_for_sparse_matrix[(\n",
    "                i_vid % 1000000,   j_token)] = freq_tokens_per_video[key]\n",
    "\n",
    "        except KeyError:\n",
    "            None\n",
    "\n",
    "    return dict_freq_tokens_for_sparse_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dimension of sparse matrix\n",
    "size_of_tokens_dict = len(set_stemmed_tokens)\n",
    "number_of_vid = len(set_relevant_vid)\n",
    "\n",
    "# Create dictionnary of tokens with their indice\n",
    "word2id = {}\n",
    "\n",
    "# Fill dictionnary of tokens\n",
    "for i, token in enumerate(set_stemmed_tokens):\n",
    "    word2id[token] = i\n",
    "    \n",
    "id2word = {v: k for k, v in word2id.items()}\n",
    "\n",
    "# Create mini sparse matrix\n",
    "S = dok_matrix((1000000, size_of_tokens_dict), dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1000000 videos...\n",
      "Processed 2000000 videos...\n",
      "Processed 3000000 videos...\n",
      "Processed 4000000 videos...\n",
      "Processed 5000000 videos...\n",
      "Processed 6000000 videos...\n",
      "Processed 7000000 videos...\n",
      "Processed 8000000 videos...\n",
      "Processed 10000000 videos...\n",
      "Processed 11000000 videos...\n",
      "Processed 12000000 videos...\n",
      "Processed 13000000 videos...\n",
      "Processed 14000000 videos...\n",
      "Processed 15000000 videos...\n",
      "Processed 16000000 videos...\n",
      "Processed 17000000 videos...\n",
      "Processed 18000000 videos...\n",
      "Processed 19000000 videos...\n",
      "Processed 20000000 videos...\n",
      "Processed 21000000 videos...\n",
      "Processed 22000000 videos...\n",
      "Processed 23000000 videos...\n",
      "Processed 24000000 videos...\n",
      "Processed 25000000 videos...\n",
      "Processed 26000000 videos...\n",
      "Processed 27000000 videos...\n",
      "Processed 28000000 videos...\n",
      "Processed 29000000 videos...\n",
      "Processed 30000000 videos...\n",
      "Processed 31000000 videos...\n",
      "Processed 32000000 videos...\n",
      "Processed 33000000 videos...\n",
      "Processed 34000000 videos...\n",
      "Processed 35000000 videos...\n",
      "Processed 36000000 videos...\n",
      "Processed 37000000 videos...\n",
      "Processed 38000000 videos...\n",
      "Processed 39000000 videos...\n",
      "Processed 40000000 videos...\n",
      "Processed 41000000 videos...\n",
      "Processed 42000000 videos...\n",
      "Processed 43000000 videos...\n",
      "Processed 44000000 videos...\n",
      "Processed 45000000 videos...\n",
      "Processed 46000000 videos...\n",
      "Processed 47000000 videos...\n",
      "Processed 48000000 videos...\n",
      "Processed 49000000 videos...\n",
      "Processed 50000000 videos...\n",
      "Processed 51000000 videos...\n",
      "Processed 52000000 videos...\n",
      "Processed 54000000 videos...\n",
      "Processed 55000000 videos...\n",
      "Processed 56000000 videos...\n",
      "Processed 57000000 videos...\n",
      "Processed 58000000 videos...\n",
      "Processed 59000000 videos...\n",
      "Processed 60000000 videos...\n",
      "Processed 61000000 videos...\n",
      "Processed 62000000 videos...\n",
      "Processed 63000000 videos...\n",
      "Processed 64000000 videos...\n",
      "Processed 65000000 videos...\n",
      "Processed 66000000 videos...\n",
      "Processed 67000000 videos...\n",
      "Processed 68000000 videos...\n",
      "Processed 69000000 videos...\n",
      "Processed 70000000 videos...\n",
      "Processed 71000000 videos...\n",
      "Processed 72000000 videos...\n",
      "Processed 73000000 videos...\n"
     ]
    }
   ],
   "source": [
    "i_vid = 0\n",
    "\n",
    "# Reading the file\n",
    "with gzip.open('/dlabdata1/youtube_large/yt_metadata_en.jsonl.gz', 'rb') as f:\n",
    "\n",
    "    for i, line in enumerate(f):\n",
    "\n",
    "        if i_vid % 1000000 == 0 and i_vid != 0:\n",
    "\n",
    "            file_name = 'S' + str(int(i_vid/1000000)) + '.npz'\n",
    "            \n",
    "            if not os.path.isfile('/dlabdata1/youtube_large/olam/data/final_res/matrices/' + file_name):\n",
    "\n",
    "                # Transform to csr format for memory efficiency\n",
    "                S = S.tocsr()\n",
    "                scipy.sparse.save_npz(\n",
    "                    '/dlabdata1/youtube_large/olam/data/final_res/matrices/' + file_name, S)\n",
    "\n",
    "                # Refresh mini sparse matrix\n",
    "                S = dok_matrix((1000000, size_of_tokens_dict), dtype=np.uint8)\n",
    "\n",
    "        if i in set_relevant_vid:\n",
    "\n",
    "            video = json.loads(line)\n",
    "\n",
    "            # Get the tokens for each video and theirs number of occurences\n",
    "            freq_tokens_per_video = get_freq_tokens_per_video(video)\n",
    "\n",
    "            # Fill the underlying dict\n",
    "            dict_freq_tokens_for_sparse_matrix = fill_underlying_dict(\n",
    "                freq_tokens_per_video, word2id, i_vid)\n",
    "\n",
    "            # Fill data in to sparse matrix\n",
    "            dict.update(S, dict_freq_tokens_for_sparse_matrix)\n",
    "\n",
    "            # Increase i_vid\n",
    "            i_vid += 1\n",
    "\n",
    "        if i % 1000000 == 0 and i != 0:\n",
    "            print('Processed ' + str(i) + ' videos...')\n",
    "\n",
    "# Save last sparse matrix\n",
    "S = S.tocsr()\n",
    "scipy.sparse.save_npz(\n",
    "    '/dlabdata1/youtube_large/olam/data/final_res/matrices/S_last.npz', S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get final sparse matrix\n",
    "S = scipy.sparse.load_npz(\n",
    "    '/dlabdata1/youtube_large/olam/data/final_res/matrices/S1.npz')\n",
    "\n",
    "for i in range(2, 17):\n",
    "    S_next = scipy.sparse.load_npz(\n",
    "        '/dlabdata1/youtube_large/olam/data/final_res/matrices/S' + str(i) + '.npz')\n",
    "    S = scipy.sparse.vstack([S, S_next])\n",
    "\n",
    "# Add last matrix\n",
    "S_last = scipy.sparse.load_npz(\n",
    "    '/dlabdata1/youtube_large/olam/data/final_res/matrices/S_last.npz')\n",
    "S = scipy.sparse.vstack([S, S_last])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the full matrix\n",
    "scipy.sparse.save_npz(\n",
    "    '/dlabdata1/youtube_large/olam/data/final_res/matrices/S_full.npz', S)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Process the data for Topic Modelling with PySpark\n",
    "\n",
    "First, for a better topic modelling model, we select the videos from the sparse matrix as follow:\n",
    "- we group the videos by their respective `channel_id`, `category` and `upload_date`\n",
    "- keep the 20 videos with the most `view_counts` from each group\n",
    "- keep tokens that appears in at least 100 videos\n",
    "\n",
    "Then, we should compute a spark dataframe from our final sparse matrix in order to compute the models on the hadoop cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Filter the videos for topic modelling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 1/73\n",
      "Progress: 2/73\n",
      "Progress: 3/73\n",
      "Progress: 4/73\n",
      "Progress: 5/73\n",
      "Progress: 6/73\n",
      "Progress: 7/73\n",
      "Progress: 8/73\n",
      "Progress: 9/73\n",
      "Progress: 10/73\n",
      "Progress: 11/73\n",
      "Progress: 12/73\n",
      "Progress: 13/73\n",
      "Progress: 14/73\n",
      "Progress: 15/73\n",
      "Progress: 16/73\n",
      "Progress: 17/73\n",
      "Progress: 18/73\n",
      "Progress: 19/73\n",
      "Progress: 20/73\n",
      "Progress: 21/73\n",
      "Progress: 22/73\n",
      "Progress: 23/73\n",
      "Progress: 24/73\n",
      "Progress: 25/73\n",
      "Progress: 26/73\n",
      "Progress: 27/73\n",
      "Progress: 28/73\n",
      "Progress: 29/73\n",
      "Progress: 30/73\n",
      "Progress: 31/73\n",
      "Progress: 32/73\n",
      "Progress: 33/73\n",
      "Progress: 34/73\n",
      "Progress: 35/73\n",
      "Progress: 36/73\n",
      "Progress: 37/73\n",
      "Progress: 38/73\n",
      "Progress: 39/73\n",
      "Progress: 40/73\n",
      "Progress: 41/73\n",
      "Progress: 42/73\n",
      "Progress: 43/73\n",
      "Progress: 44/73\n",
      "Progress: 45/73\n",
      "Progress: 46/73\n",
      "Progress: 47/73\n",
      "Progress: 48/73\n",
      "Progress: 49/73\n",
      "Progress: 50/73\n",
      "Progress: 51/73\n",
      "Progress: 52/73\n",
      "Progress: 53/73\n",
      "Progress: 54/73\n",
      "Progress: 55/73\n",
      "Progress: 56/73\n",
      "Progress: 57/73\n",
      "Progress: 58/73\n",
      "Progress: 59/73\n",
      "Progress: 60/73\n",
      "Progress: 61/73\n",
      "Progress: 62/73\n",
      "Progress: 63/73\n",
      "Progress: 64/73\n",
      "Progress: 65/73\n",
      "Progress: 66/73\n",
      "Progress: 67/73\n",
      "Progress: 68/73\n",
      "Progress: 69/73\n",
      "Progress: 70/73\n",
      "Progress: 71/73\n",
      "Progress: 72/73\n",
      "Progress: 73/73\n"
     ]
    }
   ],
   "source": [
    "# create pandas DataFrame of relevant videos with relevant features\n",
    "columns_names = ['channel_id',\n",
    "                 'view_counts', 'uploaded_year', 'category']\n",
    "\n",
    "# store relevant features of relevant videos in a list\n",
    "list_relevant_data = []\n",
    "\n",
    "# Reading the file\n",
    "with gzip.open('/dlabdata1/youtube_large/yt_metadata_en.jsonl.gz', 'rb') as f:\n",
    "\n",
    "    for i, line in enumerate(f):\n",
    "        if i % 1000000 == 0 and i != 0:\n",
    "            print('Progress: ' + str(int(i/1000000)) + '/73')\n",
    "\n",
    "        if i in set_relevant_vid:\n",
    "\n",
    "            # line is a str dict, video is the dict corresponding to the str dict\n",
    "            video = json.loads(line)\n",
    "\n",
    "            list_vid_relevant_features = [video['channel_id']]\n",
    "            list_vid_relevant_features.append(video['view_count'])\n",
    "            list_vid_relevant_features.append(video['upload_date'][:4])\n",
    "            list_vid_relevant_features.append(video['categories'])\n",
    "\n",
    "            list_relevant_data.append(list_vid_relevant_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_relevant_data = pd.DataFrame(list_relevant_data, columns=columns_names)\n",
    "df_relevant_data_top20 = df_relevant_data.sort_values(['view_counts'], ascending=False).groupby(\n",
    "    ['category', 'uploaded_year', 'channel_id']).head(20)\n",
    "\n",
    "set_relevant_vid_top20 = sorted(df_relevant_data_top20.index.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save intermediate result\n",
    "with open('/dlabdata1/youtube_large/olam/data/final_res/model/set_relevant_vid_top20.pickle', 'wb') as f:\n",
    "    pickle.dump(set_relevant_vid_top20, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Keep only relevant tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load intermediate data\n",
    "S = scipy.sparse.load_npz(\n",
    "    '/dlabdata1/youtube_large/olam/data/final_res/matrices/S_full.npz')\n",
    "\n",
    "\n",
    "# Load set of videos in the top20 as processed abose\n",
    "with open('/dlabdata1/youtube_large/olam/data/final_res/model/set_relevant_vid_top20.pickle', 'rb') as f:\n",
    "    set_relevant_vid_top20 = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed : 0 tokens\n",
      "Processed : 1000000 tokens\n",
      "Processed : 2000000 tokens\n"
     ]
    }
   ],
   "source": [
    "S = S[set_relevant_vid_top20, :]\n",
    "\n",
    "# Convert matrix to csc for efficient computing\n",
    "S = S.tocsc()\n",
    "\n",
    "list_relevant_tokens = []\n",
    "\n",
    "# Iterate on the columns\n",
    "for i in range(S.shape[1]):\n",
    "\n",
    "    if i % 1000000 == 0:\n",
    "        print('Processed : ' + str(i) + ' tokens')\n",
    "\n",
    "    # Check column has more than 100 non zero entries\n",
    "    if S[:, i].count_nonzero() >= 100:\n",
    "        list_relevant_tokens.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = S[:, list_relevant_tokens].tocsr()\n",
    "S = remove_zero_rows(S)\n",
    "\n",
    "scipy.sparse.save_npz('/dlabdata1/youtube_large/olam/data/final_res/matrices/S_final.npz', S)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Build a dictionnary id2word for final sparse matrix\n",
    "\n",
    "`id2word_top20` is a dictionnary that map each of the token id to the token itself only for relevant tokens for top20 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word_top20 = {}\n",
    "\n",
    "for i, id_token in enumerate(list_relevant_tokens):\n",
    "    id2word_top20[i] = id2word[id_token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save intermediate result\n",
    "with open('/dlabdata1/youtube_large/olam/data/final_res/id2word_top20.pickle', 'wb') as f:\n",
    "    pickle.dump(id2word_top20, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Get Spark dataframe to use the hadoop cluster to perform topic modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = SparkConf().setMaster(\"local\").setAll(\n",
    "    [('spark.executor.memory', '4g'), ('spark.driver.memory', '16g'), ('spark.driver.maxResultSize', '0')])\n",
    "\n",
    "# create the session\n",
    "spark = SparkSession.builder.config(conf=conf).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dict_for_row(row, S):\n",
    "    '''Construct SparseVector bag-of-word for each row (videos)'''\n",
    "    tmp_dict = {}\n",
    "    for key, value in row:\n",
    "        tmp_dict[key[1]] = value\n",
    "\n",
    "    return SparseVector(S.shape[1], tmp_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process video for topic modelling...\n",
      "0 videos processed...\n",
      "1000000 videos processed...\n",
      "2000000 videos processed...\n",
      "3000000 videos processed...\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "\n",
    "print('Process video for topic modelling...')\n",
    "for i in range(S.shape[0]):\n",
    "\n",
    "    if i % 1000000 == 0:\n",
    "        print(str(i) + ' videos processed...')\n",
    "\n",
    "    data.append([i, get_dict_for_row(S.getrow(i).todok().items(), S)])\n",
    "\n",
    "\n",
    "# Construct dataframe for LDA\n",
    "all_df = spark.createDataFrame(data, [\"id\", \"features\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the dataframe\n",
    "all_df.write.option('compression', 'gzip').json(\n",
    "    '/dlabdata1/youtube_large/olam/data/final_res/model/sparkdf.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Topic Modelling\n",
    "\n",
    "The python script for topic modelling can be found in the folder `script/yt_lda_tune.py`\n",
    "\n",
    "In order to run the script on the Hadoop server, the following need to be done:\n",
    "\n",
    "- copy the file in hdfs: `$ hdfs dfs -put /dlabdata1/youtube_large/olam/data/final_res/model/sparkdf.json /user/olam/final_res/`\n",
    "\n",
    "- on the Hadoop server, go to the script folder and launch the following command: `$ spark-submit --master yarn --deploy-mode cluster --num-executors 15 --executor-cores 12 --driver-memory 32g --executor-memory 16g yt_lda_tune.py`\n",
    "\n",
    "- get the resulting files in hdfs: `$ hdfs dfs -get /user/olam/final_res/tune/ /dlabdata1/youtube_large/olam/data/final_res/model/tune/`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Results: Topic Coherence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FakedGensimDict:\n",
    "    \"\"\"\n",
    "    Locally made class for `~gensim.corpora.dictionary.Dictionary`\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data, S):\n",
    "        if not isinstance(data, dict):\n",
    "            raise ValueError('`data` must be an instance of `dict`')\n",
    "\n",
    "        self.id2token = data\n",
    "        self.token2id = {v: k for k, v in data.items()}\n",
    "        self.doc2bow = S\n",
    "\n",
    "    @staticmethod\n",
    "    def from_vocab(vocab):\n",
    "        return FakedGensimDict(dict(zip(range(len(vocab)), vocab)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Preparing the coherence model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = []\n",
    "\n",
    "for i in range(S.shape[0]):\n",
    "    token_indices = list(S.getrow(i).nonzero()[1])\n",
    "    tokens = []\n",
    "\n",
    "    for token_indice in token_indices:\n",
    "        tokens.append(id2word_top20[token_indice])\n",
    "    texts.append(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []\n",
    "\n",
    "for row in S.toarray():\n",
    "    bow = []\n",
    "    idx_nonzero = np.nonzero(row)[0]\n",
    "    for i in range(len(idx_nonzero)):\n",
    "        bow.append((idx_nonzero[i], row[idx_nonzero[i]]))\n",
    "    corpus.append(bow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Get the coherence scores for each model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coherence_scores = []\n",
    "coherence_scores_umass = []\n",
    "\n",
    "n_topics_list = [40, 45, 50, 55, 60, 65, 70, 75, 80, 85, 90, 95,\n",
    "                 100, 105, 110, 115, 120, 125, 130, 135, 140, 145, 150, 155, 160]\n",
    "\n",
    "for i, n_topics in enumerate(n_topics_list):\n",
    "\n",
    "    print('Computing coherence score for model with ' +\n",
    "          str(n_topics) + ' topics...')\n",
    "\n",
    "    # Get describe_topics dataframe\n",
    "    describe_topics = spark.read.json(\n",
    "        '/dlabdata1/youtube_large/olam/data/final_res/model/tune/describe_topics_' + str(n_topics) + '.json')\n",
    "\n",
    "    # Characterize the topics with tokens\n",
    "    topics = []\n",
    "\n",
    "    for row in describe_topics.sort('topic').rdd.collect():\n",
    "        tokenized_topic = []\n",
    "        for j, token_id in enumerate(row.termIndices):\n",
    "            tokenized_topic.append(id2word_top20[token_id])\n",
    "            if j > 10:\n",
    "                break\n",
    "        topics.append(tokenized_topic)\n",
    "\n",
    "    # Compute c_v coherence score and append to coherence scores\n",
    "    coherence_model = CoherenceModel(topics=topics,\n",
    "                                     corpus=S,\n",
    "                                     dictionary=FakedGensimDict(\n",
    "                                         id2word_top20, S),\n",
    "                                     texts=texts,\n",
    "                                     coherence='c_v')\n",
    "\n",
    "    # Compute u_mass coherence score and append to coherence scores\n",
    "    coherence_model_umass = CoherenceModel(topics=topics,\n",
    "                                           corpus=corpus,\n",
    "                                           dictionary=FakedGensimDict(\n",
    "                                               id2word_top20, S),\n",
    "                                           coherence='u_mass')\n",
    "\n",
    "    print('Getting c_v coherence score...')\n",
    "    coherence_scores.append(coherence_model.get_coherence())\n",
    "    print('Getting u_mass coherence score...')\n",
    "    coherence_scores_umass.append(coherence_model_umass.get_coherence())\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "\n",
    "ax.set_title('Coherence score for a given number of topics', fontsize=24)\n",
    "ax.set_xlabel('Number of Topics', fontsize=16)\n",
    "ax.set_ylabel('Coherence Score c_v', fontsize=16)\n",
    "\n",
    "ax.grid('on')\n",
    "\n",
    "ax.plot(coherence_scores, label='c_v coherence score', linewidth=3)\n",
    "\n",
    "ax2 = ax.twinx()\n",
    "ax2.set_ylabel('Coherence Score u_mass', fontsize=16)\n",
    "ax2.plot(coherence_scores_umass, label='u_mass coherence score', linewidth=3, color='orange')\n",
    "\n",
    "ax.legend(fontsize=16)\n",
    "ax2.legend(loc='upper right', bbox_to_anchor=(1, 0.93), fontsize=16)\n",
    "\n",
    "plt.xticks(np.arange(len(n_topics_list)), n_topics_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig('/home/olam/coherence_scores')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "465.8088073730469px",
    "left": "1108.0882568359375px",
    "top": "289.4668884277344px",
    "width": "220.64337158203125px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
