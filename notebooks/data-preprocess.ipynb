{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zstandard as zstd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Zreader:\n",
    "\n",
    "    def __init__(self, file, chunk_size=16384):\n",
    "        '''Init method'''\n",
    "        self.fh = open(file,'rb')\n",
    "        self.chunk_size = chunk_size\n",
    "        self.dctx = zstd.ZstdDecompressor()\n",
    "        self.reader = self.dctx.stream_reader(self.fh)\n",
    "        self.buffer = ''\n",
    "\n",
    "\n",
    "    def readlines(self):\n",
    "        '''Generator method that creates an iterator for each line of JSON'''\n",
    "        while True:\n",
    "            chunk = self.reader.read(self.chunk_size).decode(errors=\"ignore\")\n",
    "            if not chunk:\n",
    "                break\n",
    "            lines = (self.buffer + chunk).split(\"\\n\")\n",
    "\n",
    "            for line in lines[:-1]:\n",
    "                yield line\n",
    "\n",
    "            self.buffer = lines[-1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get list of channels in ```channelcrawler.csv```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_channelcrawler = pd.read_csv('/dlabdata1/youtube_large/channelcrawler.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>join_date</th>\n",
       "      <th>link</th>\n",
       "      <th>name</th>\n",
       "      <th>subscribers</th>\n",
       "      <th>videos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Film and Animation</td>\n",
       "      <td>2017-05-21</td>\n",
       "      <td>http://www.youtube.com/channel/UCBJuEqXfXTdcPS...</td>\n",
       "      <td>MagnusNation</td>\n",
       "      <td>65100</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Entertainment</td>\n",
       "      <td>2011-12-13</td>\n",
       "      <td>http://www.youtube.com/channel/UCkNW9Q1VR_aeZ6...</td>\n",
       "      <td>Mago Dario Animazion...</td>\n",
       "      <td>60200</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Music</td>\n",
       "      <td>2013-09-13</td>\n",
       "      <td>http://www.youtube.com/channel/UC1xcnrpcF59FWW...</td>\n",
       "      <td>Mägo de Oz - Topic</td>\n",
       "      <td>40200</td>\n",
       "      <td>395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Music</td>\n",
       "      <td>2008-03-17</td>\n",
       "      <td>http://www.youtube.com/channel/UCXhkGgooXHDNwg...</td>\n",
       "      <td>Mago Merlino</td>\n",
       "      <td>14800</td>\n",
       "      <td>838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Entertainment</td>\n",
       "      <td>2014-10-19</td>\n",
       "      <td>http://www.youtube.com/channel/UCvZGsuvKlYOGiZ...</td>\n",
       "      <td>MAGO TOMÁS</td>\n",
       "      <td>26200</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             category   join_date  \\\n",
       "0  Film and Animation  2017-05-21   \n",
       "1       Entertainment  2011-12-13   \n",
       "2               Music  2013-09-13   \n",
       "3               Music  2008-03-17   \n",
       "4       Entertainment  2014-10-19   \n",
       "\n",
       "                                                link                     name  \\\n",
       "0  http://www.youtube.com/channel/UCBJuEqXfXTdcPS...             MagnusNation   \n",
       "1  http://www.youtube.com/channel/UCkNW9Q1VR_aeZ6...  Mago Dario Animazion...   \n",
       "2  http://www.youtube.com/channel/UC1xcnrpcF59FWW...       Mägo de Oz - Topic   \n",
       "3  http://www.youtube.com/channel/UCXhkGgooXHDNwg...             Mago Merlino   \n",
       "4  http://www.youtube.com/channel/UCvZGsuvKlYOGiZ...               MAGO TOMÁS   \n",
       "\n",
       "   subscribers  videos  \n",
       "0        65100      28  \n",
       "1        60200      48  \n",
       "2        40200     395  \n",
       "3        14800     838  \n",
       "4        26200      31  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_channelcrawler.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 164648 entries, 0 to 164647\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count   Dtype \n",
      "---  ------       --------------   ----- \n",
      " 0   category     164462 non-null  object\n",
      " 1   join_date    164647 non-null  object\n",
      " 2   link         164648 non-null  object\n",
      " 3   name         164633 non-null  object\n",
      " 4   subscribers  164648 non-null  int64 \n",
      " 5   videos       164648 non-null  int64 \n",
      "dtypes: int64(2), object(4)\n",
      "memory usage: 7.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df_channelcrawler.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_channelcrawler['channel_id'] = df_channelcrawler['link'].apply(lambda x: x.replace('http://www.youtube.com/channel/', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>join_date</th>\n",
       "      <th>link</th>\n",
       "      <th>name</th>\n",
       "      <th>subscribers</th>\n",
       "      <th>videos</th>\n",
       "      <th>channel_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Film and Animation</td>\n",
       "      <td>2017-05-21</td>\n",
       "      <td>http://www.youtube.com/channel/UCBJuEqXfXTdcPS...</td>\n",
       "      <td>MagnusNation</td>\n",
       "      <td>65100</td>\n",
       "      <td>28</td>\n",
       "      <td>UCBJuEqXfXTdcPSbGO9qqn1g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Entertainment</td>\n",
       "      <td>2011-12-13</td>\n",
       "      <td>http://www.youtube.com/channel/UCkNW9Q1VR_aeZ6...</td>\n",
       "      <td>Mago Dario Animazion...</td>\n",
       "      <td>60200</td>\n",
       "      <td>48</td>\n",
       "      <td>UCkNW9Q1VR_aeZ6uht83jJVQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Music</td>\n",
       "      <td>2013-09-13</td>\n",
       "      <td>http://www.youtube.com/channel/UC1xcnrpcF59FWW...</td>\n",
       "      <td>Mägo de Oz - Topic</td>\n",
       "      <td>40200</td>\n",
       "      <td>395</td>\n",
       "      <td>UC1xcnrpcF59FWWELtZvJTdg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Music</td>\n",
       "      <td>2008-03-17</td>\n",
       "      <td>http://www.youtube.com/channel/UCXhkGgooXHDNwg...</td>\n",
       "      <td>Mago Merlino</td>\n",
       "      <td>14800</td>\n",
       "      <td>838</td>\n",
       "      <td>UCXhkGgooXHDNwgJXmoTSN7g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Entertainment</td>\n",
       "      <td>2014-10-19</td>\n",
       "      <td>http://www.youtube.com/channel/UCvZGsuvKlYOGiZ...</td>\n",
       "      <td>MAGO TOMÁS</td>\n",
       "      <td>26200</td>\n",
       "      <td>31</td>\n",
       "      <td>UCvZGsuvKlYOGiZTsxwJNS5Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             category   join_date  \\\n",
       "0  Film and Animation  2017-05-21   \n",
       "1       Entertainment  2011-12-13   \n",
       "2               Music  2013-09-13   \n",
       "3               Music  2008-03-17   \n",
       "4       Entertainment  2014-10-19   \n",
       "\n",
       "                                                link                     name  \\\n",
       "0  http://www.youtube.com/channel/UCBJuEqXfXTdcPS...             MagnusNation   \n",
       "1  http://www.youtube.com/channel/UCkNW9Q1VR_aeZ6...  Mago Dario Animazion...   \n",
       "2  http://www.youtube.com/channel/UC1xcnrpcF59FWW...       Mägo de Oz - Topic   \n",
       "3  http://www.youtube.com/channel/UCXhkGgooXHDNwg...             Mago Merlino   \n",
       "4  http://www.youtube.com/channel/UCvZGsuvKlYOGiZ...               MAGO TOMÁS   \n",
       "\n",
       "   subscribers  videos                channel_id  \n",
       "0        65100      28  UCBJuEqXfXTdcPSbGO9qqn1g  \n",
       "1        60200      48  UCkNW9Q1VR_aeZ6uht83jJVQ  \n",
       "2        40200     395  UC1xcnrpcF59FWWELtZvJTdg  \n",
       "3        14800     838  UCXhkGgooXHDNwgJXmoTSN7g  \n",
       "4        26200      31  UCvZGsuvKlYOGiZTsxwJNS5Q  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_channelcrawler.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#store in a set since it will be faster to check if a channel is in channelcrawler\n",
    "set_channelcrawler = set(df_channelcrawler['channel_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove non-english channels\n",
    "\n",
    "Here, I use langdetect\n",
    "\n",
    "Fishing for characters from different alphabets may let us with french-spanish-etc channels -> discuss with Manoel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langdetect import detect\n",
    "from langdetect import detect_langs\n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_en_videos = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Zreader(\"/dlabdata1/youtube_large/yt_metadata_all.jsonl.zst\", chunk_size=2**28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_language(text):\n",
    "    '''Method that detect the language of the argument using langdetect'''\n",
    "    \n",
    "    # Create list to store the language detections\n",
    "    detections = []\n",
    "    \n",
    "    for i in range(5):\n",
    "        detections.append(detect(text))\n",
    "        \n",
    "    # Create the counter to get the most detected language\n",
    "    c = Counter(detections)\n",
    "    language_detected, _ = c.most_common()[0]\n",
    "    \n",
    "    print(detections)\n",
    "    return language_detected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Bonjour, je m'appelle Olivier et j'ai twenty ans\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['nl', 'fr', 'fr', 'fr', 'fr']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'fr'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detect_language(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To ignore - Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "idx = 0\n",
    "for line in reader.readlines():\n",
    "    idx += 1\n",
    "    \n",
    "    if idx % 250 == 0:\n",
    "        break\n",
    "        \n",
    "    # line is a str dict, res is the dict corresponding to the str dict\n",
    "    res = json.loads(line)\n",
    "    \n",
    "    title = res['title']\n",
    "    description = res['description']\n",
    "    \n",
    "    if detect(title) == 'en' and res['channel_id'] in set_channelcrawler:\n",
    "        list_en_videos.append(res)\n",
    "    \n",
    "    try: \n",
    "        if description != '':\n",
    "            best_lang1 = str(detect_langs(description)[0])\n",
    "            best_lang2 = str(detect_langs(description)[0])\n",
    "            best_lang3 = str(detect_langs(description)[0])\n",
    "            print('Detect language from description: ' + detect(description))\n",
    "            print('Probability1 of languages from description: ' + best_lang1)\n",
    "            print('Probability2 of languages from description: ' + best_lang2)\n",
    "            print('Probability3 of languages from description: ' + best_lang3)\n",
    "            #print('')\n",
    "            \n",
    "            language, prob = best_lang1.split(':')[0], float(best_lang1.split(':')[1])\n",
    "            \n",
    "            if prob < 0.8:\n",
    "                print('Top1 lang detect from description with prob: ' + language + ' ' + str(prob))\n",
    "                print('Title of the video : ' + title)\n",
    "                print('Channel of the video : ' + res['channel_id'])\n",
    "                print('')\n",
    "        elif title != '':\n",
    "            try:\n",
    "                print('Detect language from title: ' + detect(title))\n",
    "                print('Probability of languages from title: ' + str(detect_langs(title)))\n",
    "                print('')\n",
    "            except:\n",
    "                print('Language not known for the video')\n",
    "                \n",
    "    except:\n",
    "        try:\n",
    "            if title != '':\n",
    "                print('Detect language from title: ' + detect(title))\n",
    "                print('Probability of languages from title: ' + str(detect_langs(title)))\n",
    "                print('')\n",
    "        except:\n",
    "            print('Language not known for the video')\n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'categories': 'Howto & Style',\n",
       " 'channel_id': 'UCzzzZ3-icktxbC3j7hkWqRw',\n",
       " 'crawl_date': '2019-11-08 05:24:10.745916',\n",
       " 'description': 'Benvenuto to Ciao Citalia, the blog from the leading Italian holiday specialist. Make Ciao Citalia your go-to for destination guides, food and wine features, recipes, and inspiration for things to see and do on your next holiday to Italy. You’ll also find first-hand accounts from our team on their travels through Italy, from a Tuscan honeymoon to a trip on the famous Venice Simplon-Orient-Express.\\n\\nTake a look now at https://ciao.citalia.com/',\n",
       " 'dislike_count': 2,\n",
       " 'display_id': 'FV_kEBb1XqU',\n",
       " 'duration': 63,\n",
       " 'like_count': 17,\n",
       " 'tags': 'Citalia,blog,italy,vog,videos,video,italian,food,wine,rome,venice,florence,milan,amalfi,coast,beach,holiday,travel,tips',\n",
       " 'title': 'Ciao Citalia | The blog from the Italian holiday specialists',\n",
       " 'upload_date': '2017-06-02 00:00:00',\n",
       " 'view_count': 1334}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_en_videos[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "165"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_en_videos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check rankings.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "rankings = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/dlabdata1/youtube_large/rankings.jsonl', 'r') as json_file:\n",
    "    json_list = list(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for json_str in json_list:\n",
    "    res = json.loads(json_str)\n",
    "    rankings.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "164677"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rankings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'success': True,\n",
       " 'data': {'social blade rank': 389823,\n",
       "  'subscriber rank': 231223,\n",
       "  'video views rank': 192084,\n",
       "  'country rank': 3,\n",
       "  'film rank': 11654,\n",
       "  'country': 'Anguilla'},\n",
       " 'crawl_time': '2020-02-17 16:40:48.336406',\n",
       " 'channel': 'UCBJuEqXfXTdcPSbGO9qqn1g'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rankings[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Title, Tag and (Description) pre-processing per video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_test = list_en_videos[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ciao Citalia | The blog from the Italian holiday specialists'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_test['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/olam/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1 : lowercase, remove stop words and tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_per_video = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_tokens = [w for w in tokenizer.tokenize(video_test['title'].lower()) if not w in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_tokens = [w for w in tokenizer.tokenize(video_test['tags'].lower()) if not w in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ciao', 'citalia', 'blog', 'italian', 'holiday', 'specialists']\n"
     ]
    }
   ],
   "source": [
    "print(title_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['citalia', 'blog', 'italy', 'vog', 'videos', 'video', 'italian', 'food', 'wine', 'rome', 'venice', 'florence', 'milan', 'amalfi', 'coast', 'beach', 'holiday', 'travel', 'tips']\n"
     ]
    }
   ],
   "source": [
    "print(tag_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to keep duplicates !!\n",
    "tokens_per_video = title_tokens + tag_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ciao', 'citalia', 'blog', 'italian', 'holiday', 'specialists', 'citalia', 'blog', 'italy', 'vog', 'videos', 'video', 'italian', 'food', 'wine', 'rome', 'venice', 'florence', 'milan', 'amalfi', 'coast', 'beach', 'holiday', 'travel', 'tips']\n"
     ]
    }
   ],
   "source": [
    "print(tokens_per_video)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2 : Stemming\n",
    "\n",
    "Ask Manoel : Stemming vs Lemmatization for the task ? We have a huge dataset so we shouldn't juste lemmatization since it would take too much time right ? For tags, lemmatization make no sense since we do not have any sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_stemmer = SnowballStemmer(language='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_per_video_stemmed = [s_stemmer.stem(w) for w in tokens_per_video]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ciao', 'citalia', 'blog', 'italian', 'holiday', 'specialist', 'citalia', 'blog', 'itali', 'vog', 'video', 'video', 'italian', 'food', 'wine', 'rome', 'venic', 'florenc', 'milan', 'amalfi', 'coast', 'beach', 'holiday', 'travel', 'tip']\n"
     ]
    }
   ],
   "source": [
    "print(tokens_per_video_stemmed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3 : Putting it together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/olam/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import collections\n",
    "\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "s_stemmer = SnowballStemmer(language='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_freq_tokens_per_video(video):\n",
    "    title_tokens = [w for w in tokenizer.tokenize(video['title'].lower()) if not w in stop_words]\n",
    "    tag_tokens = [w for w in tokenizer.tokenize(video['tags'].lower()) if not w in stop_words]\n",
    "    \n",
    "    # We want to keep duplicates !!\n",
    "    tokens_per_video = title_tokens + tag_tokens\n",
    "\n",
    "    # Stemming\n",
    "    stemmed_tokens_per_video = ([s_stemmer.stem(w) for w in tokens_per_video])\n",
    "    \n",
    "    # Return a Counter object of the tokens\n",
    "    return collections.Counter(stemmed_tokens_per_video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'citalia': 2, 'blog': 2, 'italian': 2, 'holiday': 2, 'video': 2, 'ciao': 1, 'specialist': 1, 'itali': 1, 'vog': 1, 'food': 1, 'wine': 1, 'rome': 1, 'venic': 1, 'florenc': 1, 'milan': 1, 'amalfi': 1, 'coast': 1, 'beach': 1, 'travel': 1, 'tip': 1})\n"
     ]
    }
   ],
   "source": [
    "print(get_freq_tokens_per_video(list_en_videos[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Sparse Matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import dok_matrix\n",
    "from sys import getsizeof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_stemmed_tokens = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "for video in list_en_videos:\n",
    "    tokens_per_video = get_freq_tokens_per_video(video).keys()\n",
    "    list_stemmed_tokens.update(tokens_per_video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "list_stemmed_tokens = list(list_stemmed_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "891"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_stemmed_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_of_tokens_dict = len(list_stemmed_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_videos = len(list_en_videos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = dok_matrix((number_videos, size_of_tokens_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_underlying_dict(freq_tokens_per_video, list_stemmed_tokens, dict_freq_tokens_for_sparse_matrix, idx_video):\n",
    "    '''Method to fill the underlying dictionnary in order to \n",
    "    update the sparse matrix incrementally by videos'''\n",
    "    \n",
    "    for key in freq_tokens_per_video.keys():\n",
    "        \n",
    "        # Column index in the sparse matrix (one column for each token)\n",
    "        idy_token = list_stemmed_tokens.index(key)\n",
    "    \n",
    "        # Filling the underlying dict\n",
    "        dict_freq_tokens_for_sparse_matrix[(idx_video, idy_token)] = freq_tokens_per_video[key]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Row index in the sparse matrix (one row for each video)\n",
    "idx_video = 0\n",
    "\n",
    "for video in list_en_videos:\n",
    "    # For each video, create a underlying dictionnary for filling the sparse matrix efficiently\n",
    "    dict_freq_tokens_for_sparse_matrix = {}\n",
    "    \n",
    "    # Get the tokens for each video and theirs number of occurences\n",
    "    freq_tokens_per_video = get_freq_tokens_per_video(video)\n",
    "    \n",
    "    # Fill the underlying dict\n",
    "    fill_underlying_dict(freq_tokens_per_video, list_stemmed_tokens, dict_freq_tokens_for_sparse_matrix, idx_video)\n",
    "        \n",
    "    # Update the Sparse Matrix\n",
    "    dict.update(S, dict_freq_tokens_for_sparse_matrix)\n",
    "    \n",
    "    # Increment Row index for next video\n",
    "    idx_video += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<165x891 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 2772 stored elements in Dictionary Of Keys format>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "165"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_en_videos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S.items()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group freq_tokens_per_videos by channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_per_channel = {}\n",
    "channels_in_dict = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "for vid in list_en_videos:\n",
    "    if vid['channel_id'] in channels_in_dict:\n",
    "        tokens_per_channel[vid['channel_id']] = tokens_per_channel[vid['channel_id']] + get_freq_tokens_per_video(vid)\n",
    "    else:\n",
    "        tokens_per_channel[vid['channel_id']] = get_freq_tokens_per_video(vid)\n",
    "        channels_in_dict.add(vid['channel_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'UCzzzZ3-icktxbC3j7hkWqRw': Counter({'ciao': 1,\n",
       "          'citalia': 29,\n",
       "          'blog': 2,\n",
       "          'italian': 17,\n",
       "          'holiday': 12,\n",
       "          'specialist': 1,\n",
       "          'itali': 17,\n",
       "          'vog': 1,\n",
       "          'video': 2,\n",
       "          'food': 21,\n",
       "          'wine': 4,\n",
       "          'rome': 1,\n",
       "          'venic': 1,\n",
       "          'florenc': 1,\n",
       "          'milan': 1,\n",
       "          'amalfi': 1,\n",
       "          'coast': 2,\n",
       "          'beach': 2,\n",
       "          'travel': 7,\n",
       "          'tip': 4,\n",
       "          'birthpac': 1,\n",
       "          'cannelloni': 1,\n",
       "          'sicili': 2,\n",
       "          'gennaro': 26,\n",
       "          'contaldo': 26,\n",
       "          'vacat': 3,\n",
       "          'toarmina': 1,\n",
       "          'palermo': 1,\n",
       "          'syracus': 1,\n",
       "          'trapani': 1,\n",
       "          'sicilian': 1,\n",
       "          'church': 1,\n",
       "          'cefalù': 1,\n",
       "          'cathedr': 1,\n",
       "          'mountain': 1,\n",
       "          'hike': 1,\n",
       "          'ski': 1,\n",
       "          'harbor': 1,\n",
       "          'fish': 6,\n",
       "          'cave': 1,\n",
       "          'lake': 1,\n",
       "          'volcano': 1,\n",
       "          'theatr': 1,\n",
       "          'climb': 1,\n",
       "          'cliff': 1,\n",
       "          'kitesurf': 1,\n",
       "          'waterfal': 1,\n",
       "          'music': 1,\n",
       "          'palac': 1,\n",
       "          'golf': 1,\n",
       "          'beer': 1,\n",
       "          'tenni': 1,\n",
       "          'castl': 1,\n",
       "          'present': 3,\n",
       "          'salvator': 2,\n",
       "          'sandalmak': 1,\n",
       "          'capri': 5,\n",
       "          'shop': 2,\n",
       "          'sandal': 1,\n",
       "          'shoe': 1,\n",
       "          'authent': 1,\n",
       "          'jewel': 1,\n",
       "          'swarovski': 1,\n",
       "          'design': 3,\n",
       "          'luxuri': 3,\n",
       "          'beauti': 2,\n",
       "          'custom': 1,\n",
       "          'uniqu': 1,\n",
       "          'pandolfi': 1,\n",
       "          'leather': 1,\n",
       "          'island': 1,\n",
       "          'ischia': 5,\n",
       "          'boat': 1,\n",
       "          'tour': 1,\n",
       "          'cruis': 1,\n",
       "          'fashion': 1,\n",
       "          'natur': 2,\n",
       "          'bay': 1,\n",
       "          'napl': 1,\n",
       "          'view': 1,\n",
       "          'stun': 1,\n",
       "          'style': 1,\n",
       "          'sophist': 1,\n",
       "          'break': 2,\n",
       "          'restaur': 1,\n",
       "          'grotta': 1,\n",
       "          'azzura': 1,\n",
       "          'tyrrhenian': 1,\n",
       "          'osteria': 1,\n",
       "          'castello': 1,\n",
       "          'aragones': 1,\n",
       "          'pont': 1,\n",
       "          'mount': 1,\n",
       "          'epomeo': 1,\n",
       "          'sant': 1,\n",
       "          'angelo': 1,\n",
       "          'easter': 3,\n",
       "          'roast': 5,\n",
       "          'leg': 6,\n",
       "          'lamb': 12,\n",
       "          'recip': 34,\n",
       "          'chef': 10,\n",
       "          'pea': 2,\n",
       "          'spring': 2,\n",
       "          'pasqua': 1,\n",
       "          'cook': 18,\n",
       "          'babi': 1,\n",
       "          'onion': 1,\n",
       "          'learn': 4,\n",
       "          'make': 21,\n",
       "          'fresh': 7,\n",
       "          'homemad': 4,\n",
       "          'pasta': 23,\n",
       "          'tv': 3,\n",
       "          'genr': 3,\n",
       "          'countri': 5,\n",
       "          'industri': 7,\n",
       "          'interest': 9,\n",
       "          'shape': 1,\n",
       "          'dish': 5,\n",
       "          'ingridi': 1,\n",
       "          'tagliatell': 6,\n",
       "          'cappellacci': 2,\n",
       "          'culurzon': 2,\n",
       "          'ravioli': 2,\n",
       "          'orecchiett': 5,\n",
       "          'farfall': 2,\n",
       "          'best': 1,\n",
       "          'pizza': 11,\n",
       "          'cuisin': 4,\n",
       "          'magherita': 2,\n",
       "          'tradit': 1,\n",
       "          'dough': 1,\n",
       "          'neapolitan': 3,\n",
       "          'scratch': 1,\n",
       "          'insid': 1,\n",
       "          'sorrento': 1,\n",
       "          'citi': 2,\n",
       "          'town': 2,\n",
       "          'villag': 2,\n",
       "          'campania': 1,\n",
       "          'geograph': 2,\n",
       "          'featur': 2,\n",
       "          'adventur': 1,\n",
       "          'cultur': 3,\n",
       "          'destin': 1,\n",
       "          'tourism': 2,\n",
       "          'landmark': 1,\n",
       "          'tourist': 1,\n",
       "          'mushroom': 1,\n",
       "          'truffl': 1,\n",
       "          'sea': 13,\n",
       "          'bream': 15,\n",
       "          'crazi': 1,\n",
       "          'water': 1,\n",
       "          'websit': 3,\n",
       "          'categori': 3,\n",
       "          'profess': 3,\n",
       "          'see': 1,\n",
       "          'whole': 3,\n",
       "          'tomato': 1,\n",
       "          'basil': 1,\n",
       "          'garlic': 2,\n",
       "          'ingredi': 4,\n",
       "          'oliv': 2,\n",
       "          'oil': 2,\n",
       "          'pan': 1,\n",
       "          'fri': 1,\n",
       "          'seabream': 1,\n",
       "          'tuscan': 1,\n",
       "          'chicken': 9,\n",
       "          'meat': 1,\n",
       "          'rosemari': 1,\n",
       "          'bruschetta': 1,\n",
       "          'chilli': 1,\n",
       "          'thigh': 1,\n",
       "          'drumstick': 1,\n",
       "          'perfect': 3,\n",
       "          'cup': 2,\n",
       "          'coffe': 14,\n",
       "          'like': 2,\n",
       "          'beverag': 2,\n",
       "          'type': 1,\n",
       "          'barista': 2,\n",
       "          'pod': 1,\n",
       "          'french': 1,\n",
       "          'press': 1,\n",
       "          'tassimo': 1,\n",
       "          'nespresso': 1,\n",
       "          'dolc': 1,\n",
       "          'gusto': 1,\n",
       "          'home': 1,\n",
       "          'grind': 1,\n",
       "          'store': 1,\n",
       "          'cofe': 1,\n",
       "          'brew': 1,\n",
       "          'bean': 1,\n",
       "          'latt': 1,\n",
       "          'macchiato': 1,\n",
       "          'cafe': 1,\n",
       "          'espresso': 2,\n",
       "          'wheat': 1,\n",
       "          'ricotta': 4,\n",
       "          'tart': 6,\n",
       "          'chees': 1,\n",
       "          'sweet': 1,\n",
       "          'dessert': 2,\n",
       "          'lemon': 1,\n",
       "          'pastri': 1,\n",
       "          'turnip': 2,\n",
       "          'top': 2,\n",
       "          'simpl': 1,\n",
       "          'quick': 1,\n",
       "          'broccoli': 2,\n",
       "          'purpl': 1,\n",
       "          'sprout': 1,\n",
       "          'marin': 1,\n",
       "          'freshwat': 1,\n",
       "          'merri': 2,\n",
       "          'christma': 3,\n",
       "          'brand': 2,\n",
       "          'ambassador': 2,\n",
       "          'job': 2,\n",
       "          'titl': 2,\n",
       "          'tie': 1,\n",
       "          'porchetta': 1,\n",
       "          'introduc': 1,\n",
       "          'partnership': 1}),\n",
       " 'UCzzzUN8yvD2LRAnY-lhzyLQ': Counter({'divin': 2,\n",
       "          'bright': 2,\n",
       "          'spark': 2,\n",
       "          'gimm': 2,\n",
       "          'want': 2,\n",
       "          'offici': 6,\n",
       "          'audio': 10,\n",
       "          'lyric': 215,\n",
       "          'glide': 2,\n",
       "          'ft': 123,\n",
       "          'hunter': 3,\n",
       "          'reec': 3,\n",
       "          'jona': 10,\n",
       "          'blue': 14,\n",
       "          'kaskad': 2,\n",
       "          'olivia': 6,\n",
       "          'noell': 2,\n",
       "          'come': 11,\n",
       "          'notd': 1,\n",
       "          'felix': 8,\n",
       "          'jaehn': 1,\n",
       "          'close': 1,\n",
       "          'georgia': 1,\n",
       "          'ku': 1,\n",
       "          'captain': 1,\n",
       "          'cut': 1,\n",
       "          'andrew': 2,\n",
       "          'benjamin': 2,\n",
       "          'soulmat': 2,\n",
       "          'spencer': 2,\n",
       "          'saylor': 2,\n",
       "          'martin': 11,\n",
       "          'garrix': 7,\n",
       "          'justin': 13,\n",
       "          'mylo': 2,\n",
       "          'burn': 2,\n",
       "          'moilatch': 5,\n",
       "          'remix': 144,\n",
       "          'xylø': 1,\n",
       "          'wanna': 1,\n",
       "          'see': 6,\n",
       "          'anymor': 1,\n",
       "          'pilton': 1,\n",
       "          'pear': 1,\n",
       "          'white': 1,\n",
       "          'rubayn': 1,\n",
       "          'selfish': 1,\n",
       "          'halsey': 4,\n",
       "          'without': 14,\n",
       "          'music': 189,\n",
       "          'edm': 107,\n",
       "          'pop': 9,\n",
       "          'dropnight': 103,\n",
       "          'cover': 10,\n",
       "          'live': 5,\n",
       "          '8d': 1,\n",
       "          'sigala': 5,\n",
       "          'brighter': 2,\n",
       "          'day': 6,\n",
       "          'paul': 7,\n",
       "          'janeway': 2,\n",
       "          'st': 2,\n",
       "          'broken': 2,\n",
       "          'bone': 2,\n",
       "          'wait': 3,\n",
       "          'kyli': 3,\n",
       "          'minogu': 3,\n",
       "          'night': 112,\n",
       "          'chill': 74,\n",
       "          'summer': 51,\n",
       "          'sikdop': 2,\n",
       "          'lost': 16,\n",
       "          'feat': 54,\n",
       "          'nevv': 2,\n",
       "          'smiie': 2,\n",
       "          'fool': 5,\n",
       "          'drop': 103,\n",
       "          'trap': 34,\n",
       "          'muzyka': 23,\n",
       "          'hit': 2,\n",
       "          'eska': 1,\n",
       "          'nation': 14,\n",
       "          'lauv': 7,\n",
       "          'superhero': 2,\n",
       "          'viceton': 2,\n",
       "          'walk': 2,\n",
       "          'thru': 2,\n",
       "          'fire': 2,\n",
       "          'meron': 2,\n",
       "          'ryan': 2,\n",
       "          'illenium': 2,\n",
       "          'take': 9,\n",
       "          'video': 46,\n",
       "          'everex': 2,\n",
       "          'gold': 6,\n",
       "          'max': 5,\n",
       "          'landri': 2,\n",
       "          'didier': 7,\n",
       "          'leclair': 7,\n",
       "          'kosl': 2,\n",
       "          'lux': 6,\n",
       "          'moment': 6,\n",
       "          'sick': 2,\n",
       "          'individu': 2,\n",
       "          'write': 2,\n",
       "          'wall': 2,\n",
       "          'jason': 2,\n",
       "          'walker': 16,\n",
       "          'zalenn': 3,\n",
       "          'shadowkey': 3,\n",
       "          'let': 3,\n",
       "          'go': 7,\n",
       "          'chelsea': 3,\n",
       "          'paig': 6,\n",
       "          'ebbi': 3,\n",
       "          'unknown': 2,\n",
       "          'brain': 2,\n",
       "          'perfect': 6,\n",
       "          '10': 2,\n",
       "          'heather': 2,\n",
       "          'sommer': 2,\n",
       "          'fairlan': 2,\n",
       "          'uncov': 2,\n",
       "          'ilsey': 2,\n",
       "          'shine': 2,\n",
       "          'releas': 2,\n",
       "          'roger': 2,\n",
       "          'dean': 2,\n",
       "          'doubt': 2,\n",
       "          'rival': 8,\n",
       "          'x': 19,\n",
       "          'cadmium': 8,\n",
       "          'wild': 2,\n",
       "          'card': 2,\n",
       "          'figur': 2,\n",
       "          'joe': 2,\n",
       "          'waller': 2,\n",
       "          'danrel': 3,\n",
       "          'alec': 3,\n",
       "          'king': 17,\n",
       "          'vision': 3,\n",
       "          'fiend': 3,\n",
       "          'dn': 70,\n",
       "          'danc': 91,\n",
       "          'kavali': 4,\n",
       "          'bad': 3,\n",
       "          'drug': 3,\n",
       "          'chrisle': 3,\n",
       "          'sound': 9,\n",
       "          'song': 19,\n",
       "          'best': 87,\n",
       "          'electron': 70,\n",
       "          'lökii': 3,\n",
       "          'car': 7,\n",
       "          'holm': 4,\n",
       "          'alvaro': 4,\n",
       "          'delgado': 4,\n",
       "          'fall': 8,\n",
       "          'harley': 10,\n",
       "          'bird': 10,\n",
       "          'new': 56,\n",
       "          'famous': 1,\n",
       "          'cartel': 2,\n",
       "          'run': 2,\n",
       "          'benj': 2,\n",
       "          'heard': 2,\n",
       "          'said': 6,\n",
       "          'sky': 4,\n",
       "          'get': 5,\n",
       "          'matthew': 3,\n",
       "          'koma': 3,\n",
       "          'rise': 4,\n",
       "          'jack': 8,\n",
       "          'marvin': 2,\n",
       "          'vogel': 2,\n",
       "          'jonth': 3,\n",
       "          'twoworldsapart': 3,\n",
       "          'way': 9,\n",
       "          'oneduo': 2,\n",
       "          'ria': 2,\n",
       "          'lucia': 2,\n",
       "          'mile': 2,\n",
       "          'away': 2,\n",
       "          'kalid': 2,\n",
       "          'need': 2,\n",
       "          'hous': 33,\n",
       "          'passeng': 4,\n",
       "          'hell': 4,\n",
       "          'high': 4,\n",
       "          'water': 4,\n",
       "          'ed': 5,\n",
       "          'sheeran': 5,\n",
       "          'young': 8,\n",
       "          'norma': 4,\n",
       "          'jean': 4,\n",
       "          'aronchupa': 2,\n",
       "          'littl': 7,\n",
       "          'sis': 4,\n",
       "          'nora': 4,\n",
       "          'rave': 3,\n",
       "          'grave': 3,\n",
       "          'french': 1,\n",
       "          'marshmello': 17,\n",
       "          'juici': 5,\n",
       "          'j': 5,\n",
       "          'cri': 4,\n",
       "          'jame': 16,\n",
       "          'arthur': 13,\n",
       "          'cherri': 7,\n",
       "          'beach': 6,\n",
       "          'graviti': 2,\n",
       "          'avicii': 9,\n",
       "          'lone': 4,\n",
       "          'togeth': 4,\n",
       "          'rita': 8,\n",
       "          'ora': 8,\n",
       "          'jasmin': 8,\n",
       "          'thompson': 8,\n",
       "          'sandro': 4,\n",
       "          'cavazza': 4,\n",
       "          'poorchoic': 3,\n",
       "          'man': 3,\n",
       "          'hvnnibvl': 3,\n",
       "          'season': 3,\n",
       "          'egzod': 4,\n",
       "          'paper': 3,\n",
       "          'crown': 3,\n",
       "          'leo': 3,\n",
       "          'kind': 3,\n",
       "          'nurko': 3,\n",
       "          'ncs': 5,\n",
       "          'ship': 3,\n",
       "          'wrek': 3,\n",
       "          'essi': 3,\n",
       "          'deep': 2,\n",
       "          'kill': 6,\n",
       "          'pari': 3,\n",
       "          'made': 3,\n",
       "          'time': 8,\n",
       "          'trove': 2,\n",
       "          'emili': 5,\n",
       "          'vaughn': 2,\n",
       "          'lemon': 3,\n",
       "          'fight': 5,\n",
       "          'stronger': 3,\n",
       "          'jessica': 2,\n",
       "          'reynoso': 2,\n",
       "          'electro': 12,\n",
       "          'brand': 1,\n",
       "          'jay': 4,\n",
       "          'warren': 7,\n",
       "          'closer': 3,\n",
       "          'restless': 2,\n",
       "          'modern': 3,\n",
       "          'chillout': 26,\n",
       "          'taz': 9,\n",
       "          'network': 12,\n",
       "          'fox': 2,\n",
       "          'stevenson': 2,\n",
       "          'road': 3,\n",
       "          '7k': 1,\n",
       "          'jake': 3,\n",
       "          'lawrenc': 3,\n",
       "          'one': 3,\n",
       "          'beat': 20,\n",
       "          'galaxi': 4,\n",
       "          'botalk': 5,\n",
       "          'f': 5,\n",
       "          'ck': 5,\n",
       "          'carolin': 4,\n",
       "          'pennel': 4,\n",
       "          'proxim': 7,\n",
       "          'synchronic': 3,\n",
       "          'miss': 7,\n",
       "          'liz': 2,\n",
       "          'rozrywka': 19,\n",
       "          'kloud': 3,\n",
       "          'dark': 3,\n",
       "          'lowli': 3,\n",
       "          'palac': 3,\n",
       "          'cloud': 4,\n",
       "          'kvmo': 4,\n",
       "          'massiv': 4,\n",
       "          'vibe': 52,\n",
       "          'physic': 3,\n",
       "          'ashdown': 3,\n",
       "          'poland': 3,\n",
       "          'cloudkid': 3,\n",
       "          'relas': 1,\n",
       "          'cultur': 5,\n",
       "          'code': 17,\n",
       "          'feel': 8,\n",
       "          'nocopyrightsong': 1,\n",
       "          'magnifico': 4,\n",
       "          'philip': 4,\n",
       "          'nolan': 4,\n",
       "          'vulner': 4,\n",
       "          'phil': 3,\n",
       "          'good': 4,\n",
       "          'better': 3,\n",
       "          'indi': 3,\n",
       "          'hot': 4,\n",
       "          'shade': 4,\n",
       "          'christian': 4,\n",
       "          'walz': 4,\n",
       "          'wonderchild': 2,\n",
       "          'grome': 10,\n",
       "          'guid': 6,\n",
       "          'magnus': 4,\n",
       "          'side': 7,\n",
       "          'aviella': 3,\n",
       "          'natio': 1,\n",
       "          'miti': 3,\n",
       "          'tedi': 3,\n",
       "          'spectrum': 3,\n",
       "          'drake': 8,\n",
       "          'god': 9,\n",
       "          'plan': 7,\n",
       "          'thoreau': 3,\n",
       "          'rework': 4,\n",
       "          'pla': 1,\n",
       "          'chris': 1,\n",
       "          'linton': 1,\n",
       "          'veronica': 1,\n",
       "          'bravo': 1,\n",
       "          'sevnth': 3,\n",
       "          'alo': 3,\n",
       "          'scari': 1,\n",
       "          'hour': 1,\n",
       "          'tekst': 1,\n",
       "          'top': 1,\n",
       "          'love': 14,\n",
       "          'part': 1,\n",
       "          'mia': 4,\n",
       "          'vail': 4,\n",
       "          'money': 4,\n",
       "          'spacemus': 1,\n",
       "          'space': 4,\n",
       "          'yung': 8,\n",
       "          'pinch': 4,\n",
       "          'smoke': 4,\n",
       "          'drive': 4,\n",
       "          'blackbear': 4,\n",
       "          'anim': 4,\n",
       "          'damsteram': 3,\n",
       "          'jrnd': 4,\n",
       "          'narou': 3,\n",
       "          'dylan': 3,\n",
       "          'bradi': 3,\n",
       "          'flame': 3,\n",
       "          'spinnin': 1,\n",
       "          'record': 2,\n",
       "          'spinin': 1,\n",
       "          'free': 1,\n",
       "          'u2': 2,\n",
       "          'andrelli': 2,\n",
       "          'heart': 4,\n",
       "          'color': 4,\n",
       "          'luv': 4,\n",
       "          'børns': 4,\n",
       "          'second': 4,\n",
       "          'madonna': 2,\n",
       "          'album': 2,\n",
       "          'taylor': 6,\n",
       "          'swift': 6,\n",
       "          'end': 12,\n",
       "          'game': 4,\n",
       "          'futur': 8,\n",
       "          'hamang': 5,\n",
       "          'hayley': 4,\n",
       "          'kiyoko': 4,\n",
       "          'curious': 4,\n",
       "          'coast': 4,\n",
       "          'expect': 1,\n",
       "          'craig': 8,\n",
       "          'david': 12,\n",
       "          'goldlink': 4,\n",
       "          'tobu': 3,\n",
       "          'call': 7,\n",
       "          'ember': 5,\n",
       "          'island': 5,\n",
       "          'leav': 7,\n",
       "          'severo': 7,\n",
       "          'wave': 2,\n",
       "          'wiz': 5,\n",
       "          'khalifa': 5,\n",
       "          'charli': 4,\n",
       "          'puth': 4,\n",
       "          'triton': 7,\n",
       "          'readi': 2,\n",
       "          'bloodpop': 3,\n",
       "          'otto': 2,\n",
       "          'know': 10,\n",
       "          'friend': 10,\n",
       "          'noah': 8,\n",
       "          'cyrus': 8,\n",
       "          'alan': 14,\n",
       "          'xxxtentacion': 1,\n",
       "          'world': 3,\n",
       "          '2017': 9,\n",
       "          'year': 4,\n",
       "          'drazil': 3,\n",
       "          'mashup': 3,\n",
       "          '2018': 2,\n",
       "          'tobtok': 4,\n",
       "          'onmyway': 1,\n",
       "          '10k': 1,\n",
       "          'relax': 2,\n",
       "          'christma': 3,\n",
       "          'mix': 5,\n",
       "          '18': 1,\n",
       "          'świąteczn': 1,\n",
       "          'piosenki': 1,\n",
       "          'outnow': 1,\n",
       "          'polska': 1,\n",
       "          'rap': 1,\n",
       "          'hiphop': 1,\n",
       "          'instagram': 8,\n",
       "          'rose': 6,\n",
       "          'revolut': 6,\n",
       "          'pine': 5,\n",
       "          'evan': 4,\n",
       "          'gartner': 4,\n",
       "          'looka': 3,\n",
       "          'krewella': 3,\n",
       "          'alarm': 2,\n",
       "          'monstercat': 2,\n",
       "          'dubstep': 1,\n",
       "          'sam': 5,\n",
       "          'feldt': 5,\n",
       "          'sebastianelli': 4,\n",
       "          'wish': 5,\n",
       "          'well': 5,\n",
       "          'sunset': 3,\n",
       "          'text': 1,\n",
       "          'clean': 5,\n",
       "          'bandit': 5,\n",
       "          'julia': 7,\n",
       "          'michael': 4,\n",
       "          'matoma': 4,\n",
       "          'frequenc': 4,\n",
       "          'zonderl': 4,\n",
       "          'crazi': 3,\n",
       "          'bounc': 1,\n",
       "          'bastill': 4,\n",
       "          'brigh': 1,\n",
       "          'nake': 4,\n",
       "          'wemblay': 1,\n",
       "          'arena': 1,\n",
       "          'melodi': 1,\n",
       "          'soon': 1,\n",
       "          'easi': 5,\n",
       "          'differ': 1,\n",
       "          'visual': 1,\n",
       "          'luka': 4,\n",
       "          'meijer': 4,\n",
       "          'singl': 1,\n",
       "          'winter': 1,\n",
       "          'happi': 4,\n",
       "          'energi': 4,\n",
       "          'facebook': 2,\n",
       "          'gromeeoff': 1,\n",
       "          'elephant': 8,\n",
       "          'back': 8,\n",
       "          'matluck': 3,\n",
       "          'steve': 6,\n",
       "          'void': 6,\n",
       "          'navarra': 4,\n",
       "          'mess': 4,\n",
       "          'laurel': 3,\n",
       "          'wavemus': 1,\n",
       "          'diablo': 6,\n",
       "          'r': 8,\n",
       "          'z': 8,\n",
       "          'n': 8,\n",
       "          'place': 4,\n",
       "          'hexagon': 1,\n",
       "          'digit': 3,\n",
       "          'farm': 3,\n",
       "          'pixl': 4,\n",
       "          'royal': 2,\n",
       "          'spectr': 1,\n",
       "          'mgmt': 4,\n",
       "          'kid': 4,\n",
       "          'two': 4,\n",
       "          'old': 6,\n",
       "          'bass': 4,\n",
       "          'intagram': 1,\n",
       "          'caruso': 8,\n",
       "          'cave': 4,\n",
       "          'droll': 3,\n",
       "          'dimitri': 6,\n",
       "          'vega': 6,\n",
       "          'like': 6,\n",
       "          'mike': 6,\n",
       "          'vs': 4,\n",
       "          'guetta': 4,\n",
       "          'complic': 3,\n",
       "          'r3hab': 20,\n",
       "          'dm': 1,\n",
       "          'lm': 1,\n",
       "          'khalid': 8,\n",
       "          'silenc': 9,\n",
       "          'slushii': 4,\n",
       "          'mello': 1,\n",
       "          'mellogang': 1,\n",
       "          'paperwhit': 4,\n",
       "          'us': 4,\n",
       "          'bomb': 3,\n",
       "          'kygo': 7,\n",
       "          'stargaz': 4,\n",
       "          'rob': 3,\n",
       "          'tirea': 3,\n",
       "          'jesso': 3,\n",
       "          'respo': 1,\n",
       "          'lutar': 1,\n",
       "          'town': 2,\n",
       "          'armin': 4,\n",
       "          'van': 4,\n",
       "          'buuren': 4,\n",
       "          'sunni': 4,\n",
       "          'quintino': 4,\n",
       "          'dream': 2,\n",
       "          'dope': 4,\n",
       "          'indestruct': 4,\n",
       "          'school': 2,\n",
       "          'holiday': 2,\n",
       "          'cosmos': 3,\n",
       "          'arman': 4,\n",
       "          'cekin': 4,\n",
       "          'surrend': 4,\n",
       "          'josh': 3,\n",
       "          'rubin': 3,\n",
       "          'awesom': 1,\n",
       "          'cross': 3,\n",
       "          'mind': 4,\n",
       "          'pt': 2,\n",
       "          '2': 2,\n",
       "          'kiiara': 3,\n",
       "          'coss': 1,\n",
       "          'arizona': 1,\n",
       "          'famba': 4,\n",
       "          'toito': 3,\n",
       "          'kar': 3,\n",
       "          'soundcloud': 2,\n",
       "          'spotifi': 1,\n",
       "          'codeko': 3,\n",
       "          'arcando': 3,\n",
       "          'menend': 3,\n",
       "          'possibl': 3,\n",
       "          'elohim': 4,\n",
       "          'whethan': 4,\n",
       "          'sleepi': 3,\n",
       "          'eye': 3,\n",
       "          'fell': 1,\n",
       "          'cartal': 4,\n",
       "          'beauti': 1,\n",
       "          'croatia': 1,\n",
       "          'vacat': 1,\n",
       "          'rudiment': 3,\n",
       "          'sun': 4,\n",
       "          'leon': 4,\n",
       "          'lour': 4,\n",
       "          'syenc': 6,\n",
       "          'autograf': 4,\n",
       "          'might': 3,\n",
       "          'lil': 3,\n",
       "          'big': 1,\n",
       "          'axwel': 6,\n",
       "          'λ': 4,\n",
       "          'ingrosso': 6,\n",
       "          'hogland': 7,\n",
       "          'tomorrowland': 2,\n",
       "          'cheat': 12,\n",
       "          'nicki': 6,\n",
       "          'romero': 6,\n",
       "          'sober': 6,\n",
       "          'kream': 5,\n",
       "          'clara': 5,\n",
       "          'mae': 5,\n",
       "          'drown': 5,\n",
       "          'syreblarvib': 1,\n",
       "          'art': 1,\n",
       "          'dan': 1,\n",
       "          'black': 3,\n",
       "          'someth': 3,\n",
       "          'remmi': 3,\n",
       "          'mokita': 4,\n",
       "          'chainsmok': 9,\n",
       "          'say': 7,\n",
       "          'palmqvist': 3,\n",
       "          'xo': 1,\n",
       "          'collect': 1,\n",
       "          'cash': 8,\n",
       "          'conor': 3,\n",
       "          'maynard': 3,\n",
       "          'proxmiti': 2,\n",
       "          'thimlif': 4,\n",
       "          'life': 3,\n",
       "          'lauber': 3,\n",
       "          'sensit': 2,\n",
       "          'track': 3,\n",
       "          'dvbbs': 5,\n",
       "          'cmc': 5,\n",
       "          'parallel': 4,\n",
       "          'line': 4,\n",
       "          'sometim': 3,\n",
       "          'kasbo': 5,\n",
       "          'lay': 5,\n",
       "          'keiynan': 4,\n",
       "          'lonsdal': 4,\n",
       "          'manila': 4,\n",
       "          'killa': 4,\n",
       "          'aobeat': 4,\n",
       "          'ok': 3,\n",
       "          'shaylen': 3,\n",
       "          'tropic': 1,\n",
       "          'secret': 5,\n",
       "          'cub': 3,\n",
       "          'rayan': 3,\n",
       "          'truth': 4,\n",
       "          'dare': 4,\n",
       "          'daylight': 3,\n",
       "          'mr': 1,\n",
       "          'revillz': 1,\n",
       "          'fanci': 4,\n",
       "          'stay': 5,\n",
       "          'neil': 3,\n",
       "          'ormandi': 3,\n",
       "          '4k': 2,\n",
       "          'joel': 4,\n",
       "          'adam': 4,\n",
       "          'pleas': 4,\n",
       "          'ray': 3,\n",
       "          'uscata': 3,\n",
       "          'exlus': 1,\n",
       "          'visualis': 1,\n",
       "          'ella': 4,\n",
       "          'vos': 4,\n",
       "          'vinil': 4,\n",
       "          'care': 2,\n",
       "          'ava': 3,\n",
       "          'tvg': 1,\n",
       "          '3k': 1,\n",
       "          'sub': 1,\n",
       "          'wakacj': 1,\n",
       "          'mø': 4,\n",
       "          'sensitivetrack': 1,\n",
       "          'boy': 4,\n",
       "          'sigvardt': 4,\n",
       "          'magnü': 3,\n",
       "          'astronaut': 3,\n",
       "          'uhr': 3,\n",
       "          'talk': 4,\n",
       "          'victoria': 4,\n",
       "          'zaro': 4,\n",
       "          'leowi': 3,\n",
       "          'troy': 5,\n",
       "          'sivan': 5,\n",
       "          'bignsmal': 3,\n",
       "          'zak': 3,\n",
       "          'logan': 4,\n",
       "          'help': 8,\n",
       "          'garabatto': 3,\n",
       "          'pau': 1,\n",
       "          'devi': 2,\n",
       "          'style': 2,\n",
       "          'banner': 1,\n",
       "          'tire': 5,\n",
       "          'neutral': 4,\n",
       "          'walkerjoin': 1,\n",
       "          'join': 1,\n",
       "          'lush': 3,\n",
       "          'simon': 3,\n",
       "          'izii': 3,\n",
       "          'somebodi': 3,\n",
       "          'sensitivemus': 1,\n",
       "          'troubl': 4,\n",
       "          'deb': 3,\n",
       "          'daughter': 3,\n",
       "          'tri': 1,\n",
       "          'mama': 1,\n",
       "          'natalia': 1,\n",
       "          'nykiel': 1,\n",
       "          'move': 4,\n",
       "          'cvrse': 3,\n",
       "          'alon': 1})}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(tokens_per_channel)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
