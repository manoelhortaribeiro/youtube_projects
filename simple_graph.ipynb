{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import queue\n",
    "import time\n",
    "import pickle\n",
    "import gzip\n",
    "import scipy.sparse\n",
    "import sys\n",
    "\n",
    "import zstandard as zstd\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "\n",
    "from scipy.sparse import dok_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dictionnary mapping the video_id to the channel_id\n",
    "vid_to_channels = pd.read_pickle(\"/dlabdata1/youtube_large/id_to_channel_mapping.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Channels that are in set_crawler dataset and also in which the language is in english\n",
    "with open('../../dlabdata1/youtube_large/olam/channels_id.pickle', 'rb') as f:\n",
    "    channels_id = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dictionnary to map the channel id to an integer corresponding to the column/row of the sparse matrix.\n",
    "channel_dict = {}\n",
    "for ind, channel_id in enumerate(channels_id):\n",
    "    channel_dict[channel_id] = ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Zreader:\n",
    "\n",
    "    def __init__(self, file, chunk_size=16384):\n",
    "        '''Init method'''\n",
    "        self.fh = open(file,'rb')\n",
    "        self.chunk_size = chunk_size\n",
    "        self.dctx = zstd.ZstdDecompressor()\n",
    "        self.reader = self.dctx.stream_reader(self.fh)\n",
    "        self.buffer = ''\n",
    "\n",
    "    def readlines(self):\n",
    "        '''Generator method that creates an iterator for each line of JSON'''\n",
    "        while True:\n",
    "            chunk = self.reader.read(self.chunk_size).decode(\"utf-8\", errors=\"ignore\")\n",
    "            if not chunk:\n",
    "                break\n",
    "            lines = (self.buffer + chunk).split(\"\\n\")\n",
    "\n",
    "            for line in lines[:-1]:\n",
    "                yield line\n",
    "\n",
    "            self.buffer = lines[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Row and columns length of the sparse matrix\n",
    "matrix_len = len(channels_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Function to add new edge\n",
    "    PARAMETERS:\n",
    "        - graph_dict: dictionnary mapping the edge (tuple of channel indices) with the weight of that edge\n",
    "        - user_edge_channel_id: new edge to be added in graph_dict\n",
    "'''\n",
    "def add_edge(graph_dict, user_edge_channel_id):\n",
    "    user_edge_source = channel_dict[user_edge_channel_id[0]]\n",
    "    user_edge_dest = channel_dict[user_edge_channel_id[1]]\n",
    "    user_edge = (user_edge_source, user_edge_dest)\n",
    "    \n",
    "    if graph_dict.get(user_edge) is None:\n",
    "        graph_dict[user_edge] = 1\n",
    "    else:\n",
    "        graph_dict[user_edge] += 1\n",
    "        \n",
    "# Adjust chunk_size as necessary -- defaults to 16,384 if not specific\n",
    "reader = Zreader(\"/dlabdata1/youtube_large/youtube_comments.ndjson.zst\", chunk_size=16384)\n",
    "\n",
    "# parameters\n",
    "graph_dict = {}\n",
    "nb = 1\n",
    "idx = 1\n",
    "user_edge = queue.Queue(maxsize=0) # queue corresponding to the an edge\n",
    "\n",
    "user = 'author_id'\n",
    "begin_time = time.time()\n",
    "\n",
    "# Read each line from the reader\n",
    "for line in reader.readlines():\n",
    "    line_split = line.replace('\"', '').split(',')\n",
    "    if len(line_split) == 9:\n",
    "        if idx == 1:\n",
    "            print(line_split)\n",
    "\n",
    "        else:\n",
    "            if vid_to_channels.get(line_split[2]) in channels_id:\n",
    "                corr_channel = vid_to_channels[line_split[2]]\n",
    "                if line_split[0] == user:\n",
    "                    user_edge.put(corr_channel)\n",
    "\n",
    "                    if len(user_edge.queue) == 2:\n",
    "                        add_edge(graph_dict, user_edge.queue)\n",
    "                    elif len(user_edge.queue) == 3:\n",
    "                        user_edge.get()\n",
    "                        add_edge(graph_dict, user_edge.queue)\n",
    "                else:\n",
    "                    user_edge = queue.Queue(maxsize=0)\n",
    "                    user_edge.put(corr_channel)\n",
    "                    user = line_split[0]\n",
    "\n",
    "    idx += 1\n",
    "    if idx % 100000000 == 0:\n",
    "        # Every 100 millions line create a dok matrix, update it with the graph_dict dictionnary, save it \n",
    "        # into csr format and then release memory\n",
    "        graph_matrix = dok_matrix((matrix_len, matrix_len), dtype=np.uint8)\n",
    "        dict.update(graph_matrix, graph_dict)\n",
    "        print('Size of matrix dok: ' + str(sys.getsizeof(graph_matrix)))\n",
    "        graph_dict = {}\n",
    "        # Save sparse matrix\n",
    "        scipy.sparse.save_npz('../../../dlabdata1/youtube_large/jouven/matrices_t/matrice' + str(nb) + '.npz', graph_matrix.tocsr())\n",
    "        graph_matrix = []\n",
    "        nb += 1\n",
    "        print('line number: ' + str(idx) + ' time: ' + str(time.time() - begin_time))\n",
    "        begin_time = time.time()\n",
    "\n",
    "\n",
    "graph_matrix = dok_matrix((matrix_len, matrix_len), dtype=np.uint8)\n",
    "dict.update(graph_matrix, graph_dict)\n",
    "# Save sparse matrix\n",
    "scipy.sparse.save_npz('../../../dlabdata1/youtube_large/jouven/matrices_t/matrice' + str(nb) + '.npz', graph_matrix.tocsr())\n",
    "graph_dict = {}\n",
    "graph_matrix = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Enable to load every sparse matrix to form only one by adding the weights of all sparse matrix\n",
    "'''\n",
    "graph = scipy.sparse.load_npz('../../dlabdata1/youtube_large/jouven/matrices/matrice' + str(1) +'.npz')\n",
    "for i in range(2, 79):\n",
    "    graph += scipy.sparse.load_npz('../../../dlabdata1/youtube_large/jouven/matrices/matrice' + str(i) +'.npz')\n",
    "for i in range(79, 91):\n",
    "    graph += scipy.sparse.load_npz('../../../dlabdata1/youtube_large/jouven/matrices_t/matrice' + str(i) +'.npz')\n",
    "for i in range(91, 104):\n",
    "    graph += scipy.sparse.load_npz('../../../dlabdata1/youtube_large/jouven/matrices_s/matrice' + str(i) +'.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save the final sparse matrix\n",
    "scipy.sparse.save_npz('../../../dlabdata1/youtube_large/jouven/sparse_matrix_graph.npz', graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
