{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pickle\n",
    "import scipy.sparse\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from helpers.helpers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set of duplicate users\n",
    "duplicate_users = dict_occurent_users()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of comments per channel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the number of comments per channel and store it into the YouTube project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid_to_channels = pd.read_pickle(\"/dlabdata1/youtube_large/id_to_channel_mapping.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only english channels\n",
    "channels_id = pd.read_csv(\"/dlabdata1/youtube_large/df_channels_en.csv.gz\")\n",
    "channels_id = set(channels_id['channel'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Add a comment into the a dictionnary keeping track of the number of comments per channel\n",
    "PARAMETERS:\n",
    "    - dictionnary: dicionnary mapping a channel index with it's corresponding number of comments\n",
    "    - corr_channel: the channel index in which we want to add a comment\n",
    "'''\n",
    "def add_comment(dictionnary, corr_channel):\n",
    "    if corr_channel in dictionnary:\n",
    "        dictionnary[corr_channel] += 1\n",
    "    else:\n",
    "        dictionnary[corr_channel] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-6333.590427398682\n",
      "-6144.500817298889\n",
      "-6062.126186847687\n",
      "-5905.280533075333\n",
      "-6172.949314117432\n",
      "-6818.088992357254\n",
      "-6077.464460372925\n",
      "-5907.094409942627\n",
      "-5780.842119693756\n",
      "-5753.591685295105\n"
     ]
    }
   ],
   "source": [
    "# Adjust chunk_size as necessary -- defaults to 16,384 if not specific\n",
    "reader = Zreader(\"/dlabdata1/youtube_large/youtube_comments.ndjson.zst\", chunk_size=160384)\n",
    "\n",
    "# parameters\n",
    "idx = 1\n",
    "comments_per_channel = {}\n",
    "user = ''\n",
    "begin_time = time.time()\n",
    "\n",
    "\n",
    "# Read each line from the reader\n",
    "for line in reader.readlines():\n",
    "    line_split = line.replace('\"', '').split(',')\n",
    "    if len(line_split) == 9:\n",
    "        author_id = line_split[0]\n",
    "        if vid_to_channels.get(line_split[2]) in channels_id:\n",
    "            corr_channel = vid_to_channels[line_split[2]]\n",
    "            if author_id == user:\n",
    "                if author_id in duplicate_users:\n",
    "                    if duplicate_users[author_id] <= 1:\n",
    "                        add_comment(comments_per_channel, corr_channel)\n",
    "                else:\n",
    "                    add_comment(comments_per_channel, corr_channel)\n",
    "            else:\n",
    "                if author_id in duplicate_users:\n",
    "                    duplicate_users[author_id] += 1\n",
    "                    if duplicate_users[author_id] <= 1:\n",
    "                        add_comment(comments_per_channel, corr_channel)\n",
    "                else:\n",
    "                    add_comment(comments_per_channel, corr_channel)\n",
    "            \n",
    "            user = author_id\n",
    "    idx += 1\n",
    "    if idx % 1000000000 == 0:\n",
    "        print(begin_time-time.time())\n",
    "        begin_time = time.time()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the comments_per_channel dictionnary into the YouTube project\n",
    "with open(\"/dlabdata1/youtube_large/jouven/comments_per_channel.pkl\",'wb') as f:\n",
    "     pickle.dump(comments_per_channel, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust chunk_size as necessary -- defaults to 16,384 if not specific\n",
    "reader = Zreader(\"/dlabdata1/youtube_large/youtube_comments.ndjson.zst\", chunk_size=160384)\n",
    "\n",
    "# parameters\n",
    "idx = 1\n",
    "comments_per_channels = {}\n",
    "users_per_channel = {}\n",
    "user = ''\n",
    "begin_time = time.time()\n",
    "\n",
    "\n",
    "# Read each line from the reader\n",
    "for line in reader.readlines():\n",
    "    line_split = line.replace('\"', '').split(',')\n",
    "    if len(line_split) == 9:\n",
    "        author_id = line_split[0]\n",
    "        if vid_to_channels.get(line_split[2]) in channels_id:\n",
    "            corr_channel = vid_to_channels[line_split[2]]\n",
    "            if author_id == user:\n",
    "                if author_id in occurent_users:\n",
    "                    if occurent_users[author_id] <= 1:\n",
    "                        add_comment(comments_per_channels, corr_channel)\n",
    "                else:\n",
    "                    add_comment(comments_per_channels, corr_channel)\n",
    "            else:\n",
    "                if author_id in occurent_users:\n",
    "                    occurent_users[author_id] += 1\n",
    "                    if occurent_users[author_id] <= 1:\n",
    "                        add_comment(comments_per_channels, corr_channel)\n",
    "                else:\n",
    "                    add_comment(comments_per_channels, corr_channel)\n",
    "            \n",
    "            user = author_id\n",
    "    idx += 1\n",
    "    if idx % 1000000000 == 0:\n",
    "        print(begin_time-time.time())\n",
    "        begin_time = time.time()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Video channel mapping filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the original dictionnary having all the video-channel relationship, we only select data corresponding to the selected channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid_to_channels = pd.read_pickle(\"/dlabdata1/youtube_large/id_to_channel_mapping.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set of channels selected\n",
    "dict_channel_ind, dict_ind_channel, channels_id = filtered_channels_index_id_mapping()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid_to_channels_filtered = {}\n",
    "for vid, channel in vid_to_channels.items():\n",
    "    if not dict_channel_ind.get(channel) == None:\n",
    "        if channel in channels_id:\n",
    "            vid_to_channels_filtered[vid] = channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48254261"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vid_to_channels_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the  video_id to the channel index filtered mapping\n",
    "with open(\"/dlabdata1/youtube_large/jouven/video_to_channel_mapping_filtered.pkl\",'wb') as f:\n",
    "     pickle.dump(vid_to_channels_filtered, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the number of users after filtering the set of channels taken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Video to channel mapping\n",
    "vid_to_channels = video_id_to_channel_id()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid_to_channels = pd.read_pickle(\"/dlabdata1/youtube_large/jouven/video_to_channel_mapping_filtered.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set of channels with more than 10k comments\n",
    "dict_channel_ind, dict_ind_channel, channels_id = filtered_channels_index_id_mapping()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-5458.276359081268\n",
      "-5251.27592587471\n",
      "-5658.101206541061\n",
      "-5454.000999212265\n",
      "-5539.64678311348\n",
      "-5518.447799921036\n",
      "-5618.892131090164\n",
      "-5525.270644187927\n",
      "-5547.37446808815\n",
      "-5535.287395238876\n"
     ]
    }
   ],
   "source": [
    "# Adjust chunk_size as necessary -- defaults to 16,384 if not specific\n",
    "reader = Zreader(\"/dlabdata1/youtube_large/youtube_comments.ndjson.zst\", chunk_size=160384)\n",
    "\n",
    "# parameters\n",
    "idx = 1\n",
    "comments_per_channels = {}\n",
    "users_per_channel = {}\n",
    "user = ''\n",
    "begin_time = time.time()\n",
    "nb_user = -1\n",
    "\n",
    "\n",
    "# Read each line from the reader\n",
    "for line in reader.readlines():\n",
    "    line_split = line.replace('\"', '').split(',')\n",
    "    if len(line_split) == 9:\n",
    "        author_id = line_split[0]\n",
    "        if vid_to_channels.get(line_split[2]) in channels_id:\n",
    "            corr_channel = vid_to_channels[line_split[2]]\n",
    "            if author_id != user:\n",
    "                if author_id in occurent_users:\n",
    "                    occurent_users[author_id] += 1\n",
    "                    if occurent_users[author_id] <= 1:\n",
    "                        nb_user += 1\n",
    "                else:\n",
    "                    nb_user += 1\n",
    "            \n",
    "            user = author_id\n",
    "    idx += 1\n",
    "    if idx % 1000000000 == 0:\n",
    "        print('Line number' + str(idx) + str(time.time()-begin_time))\n",
    "        begin_time = time.time()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[406925230]\n"
     ]
    }
   ],
   "source": [
    "with open(\"/dlabdata1/youtube_large/jouven/nb_users.pkl\",'rb') as f:\n",
    "     print(pickle.load(f))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "406925230"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of users that commented a channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bipartite_graph_sparse_matrix = scipy.sparse.load_npz('/dlabdata1/youtube_large/jouven/final_embedding_sparse_matrix/sparse_matrix_bipartite.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oli_dict_channel_ind, oli_dict_ind_channel, oli_channels_id = channels_filtered_oli()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_per_channel = {}\n",
    "for i in range(bipartite_graph_sparse_matrix.shape[0]):\n",
    "    users_per_channel[oli_dict_ind_channel[i]] = bipartite_graph_sparse_matrix[[i],:].count_nonzero()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the users_per_channel dictionnary into the YouTube project\n",
    "with open(\"/dlabdata1/youtube_large/jouven/users_per_channel_id.pkl\",'wb') as f:\n",
    "     pickle.dump(users_per_channel, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
