{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook selecting the colums of the sparse matrix having the most comments in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import queue\n",
    "import time\n",
    "import pickle\n",
    "import gzip\n",
    "import scipy.sparse\n",
    "import sys\n",
    "import operator\n",
    "\n",
    "import zstandard as zstd\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "\n",
    "from scipy.sparse import dok_matrix\n",
    "from scipy.sparse import csr_matrix, hstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionnary mapping the video_id to the channel_id\n",
    "vid_to_channels = pd.read_pickle(\"/dlabdata1/youtube_large/id_to_channel_mapping.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Channels that are in set_crawler dataset and also in which the language is in english\n",
    "with open('../../../dlabdata1/youtube_large/olam/channels_id.pickle', 'rb') as f:\n",
    "    channels_id = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionnary to map the channel id to an integer corresponding to the column/row of the sparse matrix.\n",
    "channel_dict = {}\n",
    "for ind, channel_id in enumerate(channels_id):\n",
    "    channel_dict[channel_id] = ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Zreader:\n",
    "\n",
    "    def __init__(self, file, chunk_size=16384):\n",
    "        '''Init method'''\n",
    "        self.fh = open(file,'rb')\n",
    "        self.chunk_size = chunk_size\n",
    "        self.dctx = zstd.ZstdDecompressor()\n",
    "        self.reader = self.dctx.stream_reader(self.fh)\n",
    "        self.buffer = ''\n",
    "\n",
    "    def readlines(self):\n",
    "        '''Generator method that creates an iterator for each line of JSON'''\n",
    "        while True:\n",
    "            chunk = self.reader.read(self.chunk_size).decode(\"utf-8\", errors=\"ignore\")\n",
    "            if not chunk:\n",
    "                break\n",
    "            lines = (self.buffer + chunk).split(\"\\n\")\n",
    "\n",
    "            for line in lines[:-1]:\n",
    "                yield line\n",
    "\n",
    "            self.buffer = lines[-1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the number of comments for each channel. These results are stored into a dictionnary: \n",
    "index_channel -> number_of_comments_for_index_channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['author_id', 'id', 'video_id', 'parent_id', 'crawled_at', 'likes', 'replies', 'author', 'content']\n",
      "line number: 100000000 time: 402.5513184070587\n",
      "line number: 200000000 time: 402.1791410446167\n",
      "line number: 300000000 time: 429.0353271961212\n",
      "line number: 400000000 time: 431.31581449508667\n",
      "line number: 500000000 time: 426.8570764064789\n",
      "line number: 600000000 time: 427.2702944278717\n",
      "line number: 700000000 time: 416.2495291233063\n",
      "line number: 800000000 time: 412.0062770843506\n",
      "line number: 900000000 time: 436.35715770721436\n",
      "line number: 1000000000 time: 420.625691652298\n",
      "line number: 1100000000 time: 422.53399634361267\n",
      "line number: 1200000000 time: 417.3296959400177\n",
      "line number: 1300000000 time: 414.458532333374\n",
      "line number: 1400000000 time: 424.5543465614319\n",
      "line number: 1500000000 time: 428.0177056789398\n",
      "line number: 1600000000 time: 424.02525520324707\n",
      "line number: 1700000000 time: 487.32174491882324\n",
      "line number: 1800000000 time: 536.2319900989532\n",
      "line number: 1900000000 time: 540.8287675380707\n",
      "line number: 2000000000 time: 539.5818758010864\n",
      "line number: 2100000000 time: 541.5503234863281\n",
      "line number: 2200000000 time: 537.5250420570374\n",
      "line number: 2300000000 time: 543.7741239070892\n",
      "line number: 2400000000 time: 541.2023286819458\n",
      "line number: 2500000000 time: 541.3939778804779\n",
      "line number: 2600000000 time: 553.0381019115448\n",
      "line number: 2700000000 time: 539.2243430614471\n",
      "line number: 2800000000 time: 552.4298601150513\n",
      "line number: 2900000000 time: 542.7020452022552\n",
      "line number: 3000000000 time: 544.0673768520355\n",
      "line number: 3100000000 time: 544.3877515792847\n",
      "line number: 3200000000 time: 549.1312081813812\n",
      "line number: 3300000000 time: 542.2103023529053\n",
      "line number: 3400000000 time: 537.2614431381226\n",
      "line number: 3500000000 time: 544.2208154201508\n",
      "line number: 3600000000 time: 546.8585407733917\n",
      "line number: 3700000000 time: 549.5320332050323\n",
      "line number: 3800000000 time: 532.0416796207428\n",
      "line number: 3900000000 time: 532.3681497573853\n",
      "line number: 4000000000 time: 533.8658983707428\n",
      "line number: 4100000000 time: 541.0329506397247\n",
      "line number: 4200000000 time: 533.8111886978149\n",
      "line number: 4300000000 time: 548.5739703178406\n",
      "line number: 4400000000 time: 541.5186023712158\n",
      "line number: 4500000000 time: 535.5083484649658\n",
      "line number: 4600000000 time: 548.3594098091125\n",
      "line number: 4700000000 time: 538.6079833507538\n",
      "line number: 4800000000 time: 547.491180896759\n",
      "line number: 4900000000 time: 544.3793530464172\n",
      "line number: 5000000000 time: 547.6302103996277\n",
      "line number: 5100000000 time: 540.092250585556\n",
      "line number: 5200000000 time: 542.8729128837585\n",
      "line number: 5300000000 time: 537.701308965683\n",
      "line number: 5400000000 time: 540.6314656734467\n",
      "line number: 5500000000 time: 536.8961336612701\n",
      "line number: 5600000000 time: 540.4067823886871\n",
      "line number: 5700000000 time: 541.9931793212891\n",
      "line number: 5800000000 time: 539.137776851654\n",
      "line number: 5900000000 time: 623.1435375213623\n",
      "line number: 6000000000 time: 592.6089911460876\n",
      "line number: 6100000000 time: 541.1089105606079\n",
      "line number: 6200000000 time: 585.5841896533966\n",
      "line number: 6300000000 time: 520.0452523231506\n",
      "line number: 6400000000 time: 524.5119745731354\n",
      "line number: 6500000000 time: 517.8421490192413\n",
      "line number: 6600000000 time: 530.8168802261353\n",
      "line number: 6700000000 time: 526.1474182605743\n",
      "line number: 6800000000 time: 523.055911064148\n",
      "line number: 6900000000 time: 527.9259188175201\n",
      "line number: 7000000000 time: 534.8540213108063\n",
      "line number: 7100000000 time: 528.1238887310028\n",
      "line number: 7200000000 time: 533.4456119537354\n",
      "line number: 7300000000 time: 530.468136548996\n",
      "line number: 7400000000 time: 524.1260435581207\n",
      "line number: 7500000000 time: 529.7398884296417\n",
      "line number: 7600000000 time: 526.4903030395508\n",
      "line number: 7700000000 time: 528.7357978820801\n",
      "line number: 7800000000 time: 526.8363871574402\n",
      "line number: 7900000000 time: 531.9050431251526\n",
      "line number: 8000000000 time: 526.045382976532\n",
      "line number: 8100000000 time: 519.0395562648773\n",
      "line number: 8200000000 time: 518.062906742096\n",
      "line number: 8300000000 time: 527.841117143631\n",
      "line number: 8400000000 time: 528.5613451004028\n",
      "line number: 8500000000 time: 535.4544696807861\n",
      "line number: 8600000000 time: 535.8962626457214\n",
      "line number: 8700000000 time: 535.7345836162567\n",
      "line number: 8800000000 time: 530.6525514125824\n",
      "line number: 8900000000 time: 524.2467629909515\n",
      "line number: 9000000000 time: 530.8961815834045\n",
      "line number: 9100000000 time: 531.2807767391205\n",
      "line number: 9200000000 time: 531.5306079387665\n",
      "line number: 9300000000 time: 527.9507794380188\n",
      "line number: 9400000000 time: 531.096654176712\n",
      "line number: 9500000000 time: 532.7420372962952\n",
      "line number: 9600000000 time: 536.3769209384918\n",
      "line number: 9700000000 time: 536.9295508861542\n",
      "line number: 9800000000 time: 524.0252048969269\n",
      "line number: 9900000000 time: 538.5487143993378\n",
      "line number: 10000000000 time: 529.5416843891144\n",
      "line number: 10100000000 time: 539.7583878040314\n",
      "line number: 10200000000 time: 538.0591034889221\n",
      "line number: 10300000000 time: 527.653210401535\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Function to add new edge\n",
    "    PARAMETERS:\n",
    "        - graph_dict: dictionnary mapping the edge (tuple of channel indices) with the weight of that edge\n",
    "        - user_edge_channel_id: new edge to be added in graph_dict\n",
    "'''\n",
    "def add_edge(chan_id):\n",
    "    chan_index = channel_dict[chan_id]\n",
    "    if graph_dict.get(chan_index) is None:\n",
    "        graph_dict[chan_index] = 1\n",
    "    else:\n",
    "        graph_dict[chan_index] += 1\n",
    "        \n",
    "# Adjust chunk_size as necessary -- defaults to 16,384 if not specific\n",
    "reader = Zreader(\"/dlabdata1/youtube_large/youtube_comments.ndjson.zst\", chunk_size=16384)\n",
    "\n",
    "# parameters\n",
    "graph_dict = {}\n",
    "idx = 1\n",
    "begin_time = time.time()\n",
    "\n",
    "# Read each line from the reader\n",
    "for line in reader.readlines():\n",
    "    line_split = line.replace('\"', '').split(',')\n",
    "    if len(line_split) == 9:\n",
    "        if idx == 1:\n",
    "            print(line_split)\n",
    "\n",
    "        else:\n",
    "            if vid_to_channels.get(line_split[2]) in channels_id:\n",
    "                corr_channel = vid_to_channels[line_split[2]]\n",
    "                add_edge(corr_channel)\n",
    "\n",
    "    idx += 1\n",
    "    if idx % 100000000 == 0:\n",
    "        print('line number: ' + str(idx) + ' time: ' + str(time.time() - begin_time))\n",
    "        begin_time = time.time()\n",
    "    if idx % 1000000000 == 0:\n",
    "        output = open('../../../dlabdata1/youtube_large/jouven/channels_usage_'+str(idx)+'.pkl', 'wb')\n",
    "pickle.dump(graph_dict, output)\n",
    "output.close()\n",
    "\n",
    "output = open('../../../dlabdata1/youtube_large/jouven/channels_usage.pkl', 'wb')\n",
    "pickle.dump(graph_dict, output)\n",
    "output.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reduce the size of the sparse matrix in order to be able to create a networkx graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_file = open('../../../dlabdata1/youtube_large/jouven/channels_usage.pkl', 'rb')\n",
    "channel_wanted = pickle.load(pkl_file)\n",
    "pkl_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_sorted = sorted(channel_wanted.items(), key=operator.itemgetter(1), reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = []\n",
    "for val in channel_sorted:\n",
    "    channels.append(val[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "length_matrix = 1000\n",
    "channels = channels[:length_matrix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_matrix = scipy.sparse.load_npz('../../../dlabdata1/youtube_large/jouven/sparse_matrix_graph.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_keep = np.array(channels)\n",
    "m = sparse_matrix[:, cols_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_r = m[cols_to_keep, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_most_used_channels = nx.from_scipy_sparse_matrix(m_r, create_using = nx.DiGraph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'm_r' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-1e8b31055b7c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Save the final sparse matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_npz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../../../dlabdata1/youtube_large/jouven/sparse_matrix_4_most_channels_used.npz'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm_r\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'm_r' is not defined"
     ]
    }
   ],
   "source": [
    "# Save the final sparse matrix\n",
    "scipy.sparse.save_npz('../../../dlabdata1/youtube_large/jouven/sparse_matrix_4_most_channels_used.npz', m_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
